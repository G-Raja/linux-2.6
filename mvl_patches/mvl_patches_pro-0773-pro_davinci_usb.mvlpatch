#! /usr/bin/env bash
# Patch: -pro_davinci_usb
# Date: Thu Jul  6 19:20:22 2006
# Source: MontaVista Software, Inc.
# MR: 15605
# Type: Integration
# Disposition: MontaVista
# Signed-off-by: Kevin Hilman <khilman@mvista.com>
# Description:
#     Integration of TI DaVinci 0.5.2 drop from TI

PATCHNUM=773
LSPINFO=include/linux/lsppatchlevel.h
TMPFILE=/tmp/mvl_patch_$$

function dopatch() {
    patch $* >${TMPFILE} 2>&1 <<"EOF"
Source: MontaVista Software, Inc.
MR: 15605
Type: Integration
Disposition: MontaVista
Signed-off-by: Kevin Hilman <khilman@mvista.com>
Description:
    Integration of TI DaVinci 0.5.2 drop from TI
Index: linux-2.6.10/drivers/Makefile
===================================================================
--- linux-2.6.10.orig/drivers/Makefile
+++ linux-2.6.10/drivers/Makefile
@@ -50,6 +50,7 @@ obj-$(CONFIG_TC)		+= tc/
 obj-$(CONFIG_USB)		+= usb/
 obj-$(CONFIG_USB_GADGET)	+= usb/gadget/
 obj-$(CONFIG_INPUT)		+= input/
+obj-$(CONFIG_USB_MUSB_HDRC)	+= usb/musb/
 obj-$(CONFIG_GAMEPORT)		+= input/gameport/
 obj-$(CONFIG_I2O)		+= message/
 obj-$(CONFIG_W1)		+= w1/
Index: linux-2.6.10/drivers/usb/Kconfig
===================================================================
--- linux-2.6.10.orig/drivers/usb/Kconfig
+++ linux-2.6.10/drivers/usb/Kconfig
@@ -44,6 +44,8 @@ source "drivers/usb/core/Kconfig"
 
 source "drivers/usb/host/Kconfig"
 
+source "drivers/usb/musb/Kconfig"
+
 source "drivers/usb/class/Kconfig"
 
 source "drivers/usb/storage/Kconfig"
Index: linux-2.6.10/drivers/usb/core/hcd.c
===================================================================
--- linux-2.6.10.orig/drivers/usb/core/hcd.c
+++ linux-2.6.10/drivers/usb/core/hcd.c
@@ -105,6 +105,11 @@ static DEFINE_SPINLOCK(hcd_data_lock);
 /* wait queue for synchronous unlinks */
 DECLARE_WAIT_QUEUE_HEAD(usb_kill_urb_queue);
 
+/* NOTE:  exported only temporarily, until musb_hdrc driver
+ * converts over to the HCD framework.
+ */
+EXPORT_SYMBOL_GPL(usb_kill_urb_queue);
+
 /*-------------------------------------------------------------------------*/
 
 /*
Index: linux-2.6.10/drivers/usb/gadget/Kconfig
===================================================================
--- linux-2.6.10.orig/drivers/usb/gadget/Kconfig
+++ linux-2.6.10/drivers/usb/gadget/Kconfig
@@ -178,6 +178,10 @@ config USB_LH7A40X
 	depends on USB_GADGET_LH7A40X
 	default USB_GADGET
 
+config USB_GADGET_MUSB_HDRC
+	bool 'Inventra (M)HDRC USB Peripheral'
+	depends on USB_MUSB_HDRC && (USB_MUSB_PERIPHERAL || USB_MUSB_OTG)
+	select USB_GADGET_DUALSPEED
 
 config USB_GADGET_DUMMY_HCD
 	boolean "Dummy HCD (DEVELOPMENT)"
Index: linux-2.6.10/drivers/usb/musb/Kconfig
===================================================================
--- /dev/null
+++ linux-2.6.10/drivers/usb/musb/Kconfig
@@ -0,0 +1,166 @@
+#
+# USB Dual Role (OTG-ready) Controller Drivers
+# for silicon based on Mentor Graphics INVENTRA designs
+#
+
+comment "Enable Host or Gadget support to see Inventra options"
+	depends on !USB && USB_GADGET=n
+
+# (M)HDRC = (Multipoint) Highspeed Dual-Role Controller
+config USB_MUSB_HDRC
+	depends on USB || USB_GADGET
+	tristate 'Inventra USB Highspeed Dual Role Controller Support'
+	help
+	  Say Y here if your system has a dual role high speed USB
+	  controller based on the Mentor Graphics silicon IP.  Then
+	  configure options to match your silicon and the board
+	  it's being used with, including the USB peripheral role,
+	  or the USB host role, or both.
+
+	  Texas Instruments parts using this IP include DaVinci 644x,
+	  OMAP 2430, OMAP 3430, and TUSB 6010.
+
+	  If you do not know what this is, please say N.
+
+	  To compile this driver as a module, choose M here; the
+	  module will be called "musb_hdrc".
+
+config USB_MUSB_SOC
+	boolean
+	depends on USB_MUSB_HDRC
+	default y if ARCH_DAVINCI
+	default y if ARCH_OMAP2430
+	default y if ARCH_OMAP3430
+
+comment "DaVinci 644x USB support"
+	depends on USB_MUSB_HDRC && ARCH_DAVINCI
+
+comment "OMAP 2430 high speed USB support"
+	depends on USB_MUSB_HDRC && ARCH_OMAP2430
+
+comment "OMAP 3430 high speed USB support"
+	depends on USB_MUSB_HDRC && ARCH_OMAP3430
+
+config USB_TUSB_6010
+	boolean "TUSB 6010 support"
+	depends on USB_MUSB_HDRC && !USB_MUSB_SOC
+	help
+	  The TUSB 6010 chip, from Texas Instruments, connects a discrete
+	  HDRC core using a 16-bit parallel bus (NOR flash style) or
+	  VLYNQ.
+
+choice
+	prompt "Driver Mode"
+	depends on USB_MUSB_HDRC
+	help
+	  Dual-Role devices can support both host and peripheral roles,
+	  as well as a the special "OTG Device" role which can switch
+	  between both roles as needed.
+
+# use USB_MUSB_HDRC_HCD not USB_MUSB_HOST to #ifdef host side support;
+# OTG needs both roles, not just USB_MUSB_HOST.
+config USB_MUSB_HOST
+	depends on USB
+	bool "USB Host"
+	help
+	  Say Y here if your system supports the USB host role.
+	  If it has a USB "A" (rectangular), "Mini-A" (uncommon),
+	  or "Mini-AB" connector, it supports the host role.
+	  (With a "Mini-AB" connector, you should enable USB OTG.)
+
+# use USB_GADGET_MUSB_HDRC not USB_MUSB_PERIPHERAL to #ifdef peripheral
+# side support ... OTG needs both roles
+config USB_MUSB_PERIPHERAL
+	depends on USB_GADGET
+	bool "USB Peripheral (gadget stack)"
+	select USB_GADGET_MUSB_HDRC
+	help
+	  Say Y here if your system supports the USB peripheral role.
+	  If it has a USB "B" (squarish), "Mini-B", or "Mini-AB"
+	  connector, it supports the peripheral role.
+	  (With a "Mini-AB" connector, you should enable USB OTG.)
+
+config USB_MUSB_OTG
+	depends on USB && USB_GADGET && EXPERIMENTAL
+	bool "Both host and peripheral:  USB OTG (On The Go) Device"
+	select USB_GADGET_MUSB_HDRC
+	select USB_OTG
+	select PM
+	help
+	   The most notable feature of USB OTG is support for a
+	   "Dual-Role" device, which can act as either a device
+	   or a host.  The initial role choice can be changed
+	   later, when two dual-role devices talk to each other.
+
+	   At this writing, the OTG support in this driver is incomplete,
+	   omitting the mandatory HNP or SRP protocols.  However, some
+	   of the cable based role switching works.  (That is, grounding
+	   the ID pin switches the controller to host mode, while leaving
+	   it floating leaves it in peripheral mode.)
+
+	   Select this if your system has a Mini-AB connector, or
+	   to simplify certain kinds of configuration.
+
+	   To implement your OTG Targeted Peripherals List (TPL), enable
+	   USB_OTG_WHITELIST and update "drivers/usb/core/otg_whitelist.h"
+	   to match your requirements.
+
+endchoice
+
+# enable peripheral support (including with OTG)
+config USB_GADGET_MUSB_HDRC
+	bool
+	depends on USB_MUSB_HDRC && (USB_MUSB_PERIPHERAL || USB_MUSB_OTG)
+#	default y
+#	select USB_GADGET_DUALSPEED
+#	select USB_GADGET_SELECTED
+
+# enables host support (including with OTG)
+config USB_MUSB_HDRC_HCD
+	bool
+	depends on USB_MUSB_HDRC && (USB_MUSB_HOST || USB_MUSB_OTG)
+	select USB_OTG if USB_GADGET_MUSB_HDRC
+	default y
+
+
+config USB_INVENTRA_FIFO
+	bool 'Disable DMA (always use PIO)'
+	depends on USB_MUSB_HDRC
+	help
+	  All data is copied between memory and FIFO by the CPU.
+	  DMA controllers (from Mentor or otherwise) are ignored.
+
+	  When DMA is enabled at compile time, you can still disable
+	  it at run time using the "use_dma=n" module parameter.
+
+config USB_INVENTRA_DMA
+	bool
+	depends on USB_MUSB_HDRC && !USB_INVENTRA_FIFO
+	default ARCH_OMAP243X
+	help
+	  Enable DMA transfers using Mentor's engine.
+
+config USB_TI_CPPI_DMA
+	bool
+	depends on USB_MUSB_HDRC && !USB_INVENTRA_FIFO
+	default ARCH_DAVINCI
+	help
+	  Enable DMA transfers when TI CPPI DMA is available.
+
+config USB_INVENTRA_STATIC_CONFIG
+	bool
+	depends on USB_MUSB_HDRC
+	default USB_MUSB_SOC
+	help
+	  Use a static <asm/arch/hdrc_cnf.h> file to describe how the
+	  controller is configured (endpoints, mechanisms, etc).
+
+config	USB_INVENTRA_HCD_LOGGING
+	depends on USB_MUSB_HDRC
+	int  'Logging Level (0 - none / 3 - annoying / ... )'
+	default 0
+	help
+	  Set the logging level. 0 disables the debugging altogether,
+	  although when USB_DEBUG is set the value is at least 1.
+	  Starting at level 3, per-transfer (urb, usb_request, packet,
+	  or dma transfer) tracing may kick in.
Index: linux-2.6.10/drivers/usb/musb/Makefile
===================================================================
--- /dev/null
+++ linux-2.6.10/drivers/usb/musb/Makefile
@@ -0,0 +1,77 @@
+#
+# for USB OTG silicon based on Mentor Graphics INVENTRA designs
+#
+
+musb_hdrc-objs := plat_uds.o
+
+obj-$(CONFIG_USB_MUSB_HDRC)	+= musb_hdrc.o
+
+ifeq ($(CONFIG_ARCH_DAVINCI),y)
+	musb_hdrc-objs	+= davinci.o
+endif
+
+ifeq ($(CONFIG_USB_TUSB_6010),y)
+	musb_hdrc-objs	+= tusb_6010.o
+endif
+
+ifeq ($(CONFIG_USB_MUSB_OTG),y)
+	musb_hdrc-objs	+= otg.o
+endif
+
+ifeq ($(CONFIG_USB_GADGET_MUSB_HDRC),y)
+	musb_hdrc-objs		+= g_ep0.o musb_gadget.o
+endif
+
+ifeq ($(CONFIG_USB_MUSB_HDRC_HCD),y)
+	musb_hdrc-objs		+= virthub.o musb_host.o
+endif
+
+# the kconfig must guarantee that only one of the
+# possible I/O schemes will be enabled at a time ...
+# PIO (INVENTRA_FIFO), or DMA (several potential schemes).
+# though PIO is always there to back up DMA, and for ep0
+
+ifneq ($(CONFIG_USB_INVENTRA_FIFO),y)
+
+  ifeq ($(CONFIG_USB_INVENTRA_DMA),y)
+    musb_hdrc-objs		+= musbhsdma.o
+
+  else
+    ifeq ($(CONFIG_USB_TI_CPPI_DMA),y)
+      musb_hdrc-objs		+= cppi_dma.o
+
+    endif
+  endif
+endif
+
+
+################################################################################
+
+# FIXME remove all these extra "-DMUSB_* things, stick to CONFIG_*
+
+ifeq ($(CONFIG_USB_INVENTRA_MUSB_HAS_AHB_ID),y)
+	EXTRA_CFLAGS += -DMUSB_AHB_ID
+endif
+
+# Debugging
+
+MUSB_DEBUG:=$(CONFIG_USB_INVENTRA_HCD_LOGGING)
+
+ifeq ("$(strip $(MUSB_DEBUG))","")
+    ifdef CONFIG_USB_DEBUG
+	MUSB_DEBUG:=1
+    else
+	MUSB_DEBUG:=0
+    endif
+endif
+
+ifneq ($(MUSB_DEBUG),0)
+    EXTRA_CFLAGS += -DDEBUG
+
+    ifeq ($(CONFIG_PROC_FS),y)
+	musb_hdrc-objs		+= musb_procfs.o
+    endif
+
+endif
+
+EXTRA_CFLAGS += -DMUSB_DEBUG=$(MUSB_DEBUG)
Index: linux-2.6.10/drivers/usb/musb/cppi_dma.c
===================================================================
--- /dev/null
+++ linux-2.6.10/drivers/usb/musb/cppi_dma.c
@@ -0,0 +1,1450 @@
+/*
+ * Copyright (C) 2005-2006 by Texas Instruments
+ *
+ * This file implements a DMA  interface using TI's CPPI DMA.
+ * For now it's DaVinci-only, but CPPI isn't specific to DaVinci or USB.
+ */
+
+#include <linux/config.h>
+#include <linux/usb.h>
+
+#include "cppi_dma.h"
+#include "musbdefs.h"
+#include "musb_host.h"
+
+
+/* CPPI DMA status 7-mar:
+ *
+ * - See musb_{host,gadget}.c for more info
+ *
+ * - Correct RX DMA generally forces the engine into irq-per-packet mode,
+ *   which can easily saturate the CPU under non-mass-storage loads.
+ */
+
+/* REVISIT now we can avoid preallocating these descriptors; or
+ * more simply, switch to a global freelist not per-channel ones.
+ * Note: at full speed, 64 descriptors == 4K bulk data.
+ */
+#define NUM_TXCHAN_BD       64
+#define NUM_RXCHAN_BD       64
+
+static struct dma_controller *cppi_controller_new(
+		MGC_pfDmaChannelStatusChanged pfDmaChannelStatusChanged,
+		void *musb, u8 *pCoreBase);
+static void cppi_controller_destroy(struct dma_controller *pController);
+
+struct dma_controller_factory dma_controller_factory = {
+	.pfNewDmaController	= cppi_controller_new,
+	.pfDestroyDmaController	= cppi_controller_destroy,
+};
+
+static inline void cpu_drain_writebuffer(void)
+{
+	wmb();
+#ifdef	CONFIG_CPU_ARM926T
+	/* REVISIT this "should not be needed",
+	 * but lack of it sure seemed to hurt ...
+	 */
+	asm("mcr p15, 0, r0, c7, c10, 4 @ drain write buffer\n");
+#endif
+}
+
+static inline struct cppi_descriptor *
+cppi_bd_alloc(struct cppi_channel *c)
+{
+	struct cppi_descriptor	*bd = c->bdPoolHead;
+
+	if (bd)
+		c->bdPoolHead = bd->next;
+	return bd;
+}
+
+static inline void
+cppi_bd_free(struct cppi_channel *c, struct cppi_descriptor *bd)
+{
+	if (!bd)
+		return;
+	bd->next = c->bdPoolHead;
+	c->bdPoolHead = bd;
+}
+
+/*
+ *  Start Dma controller
+ *
+ *  Initialize the Dma Controller as necessary.
+ */
+
+#define	CAST (void *__force __iomem)
+
+/* zero out entire rx state RAM entry for the channel */
+static void cppi_reset_rx(struct cppi_rx_stateram *__iomem rx)
+{
+	musb_writel(CAST &rx->buffOffset, 0, 0);
+	musb_writel(CAST &rx->headPtr, 0, 0);
+	musb_writel(CAST &rx->sopDescPtr, 0, 0);
+	musb_writel(CAST &rx->currDescPtr, 0, 0);
+	musb_writel(CAST &rx->currBuffPtr, 0, 0);
+	musb_writel(CAST &rx->pktLength, 0, 0);
+	musb_writel(CAST &rx->byteCount, 0, 0);
+}
+
+static void __init cppi_pool_init(struct cppi *cppi, struct cppi_channel *c)
+{
+	int	j;
+
+	/* initialize channel fields */
+	c->activeQueueHead = NULL;
+	c->activeQueueTail = NULL;
+	c->lastHwBDProcessed = NULL;
+	c->Channel.bStatus = MGC_DMA_STATUS_UNKNOWN;
+	c->pController = cppi;
+	c->bLastModeRndis = 0;
+	c->Channel.pPrivateData = c;
+	c->bdPoolHead = NULL;
+
+	/* build the BD Free list for the channel */
+	for (j = 0; j < NUM_TXCHAN_BD + 1; j++) {
+		struct cppi_descriptor	*bd;
+		dma_addr_t		dma;
+
+		bd = dma_pool_alloc(cppi->pool, SLAB_KERNEL, &dma);
+		bd->dma = dma;
+		cppi_bd_free(c, bd);
+	}
+}
+
+static int cppi_channel_abort(struct dma_channel *);
+
+static void cppi_pool_free(struct cppi_channel *c)
+{
+	struct cppi		*cppi = c->pController;
+	struct cppi_descriptor	*bd;
+
+	(void) cppi_channel_abort(&c->Channel);
+	c->Channel.bStatus = MGC_DMA_STATUS_UNKNOWN;
+	c->pController = NULL;
+
+	/* free all its bds */
+	bd = c->lastHwBDProcessed;
+	do {
+		if (bd)
+			dma_pool_free(cppi->pool, bd, bd->dma);
+		bd = cppi_bd_alloc(c);
+	} while (bd);
+	c->lastHwBDProcessed = NULL;
+}
+
+static u8 __init cppi_controller_start(void *pPrivateData)
+{
+	struct cppi	*pController = pPrivateData;
+	void		*__iomem regBase;
+	int		i;
+
+	/* do whatever is necessary to start controller */
+	for (i = 0; i < ARRAY_SIZE(pController->txCppi); i++) {
+		pController->txCppi[i].bTransmit = TRUE;
+		pController->txCppi[i].chNo = i;
+	}
+	for (i = 0; i < ARRAY_SIZE(pController->rxCppi); i++) {
+		pController->rxCppi[i].bTransmit = FALSE;
+		pController->rxCppi[i].chNo = i;
+	}
+
+	/* setup BD list on a per channel basis */
+	for (i = 0; i < ARRAY_SIZE(pController->txCppi); i++)
+		cppi_pool_init(pController, pController->txCppi + i);
+	for (i = 0; i < ARRAY_SIZE(pController->rxCppi); i++)
+		cppi_pool_init(pController, pController->rxCppi + i);
+
+	/* Do Necessary configuartion in H/w to get started */
+	regBase =  pController->pCoreBase - DAVINCI_BASE_OFFSET;
+
+	INIT_LIST_HEAD(&pController->tx_complete);
+
+	/* initialise tx/rx channel head pointers to zero */
+	for (i = 0; i < ARRAY_SIZE(pController->txCppi); i++) {
+		struct cppi_channel	*txChannel = pController->txCppi + i;
+		struct cppi_tx_stateram *__iomem txState;
+
+		INIT_LIST_HEAD(&txChannel->tx_complete);
+
+		txState = regBase + DAVINCI_TXCPPI_STATERAM_OFFSET(i);
+		txChannel->stateRam = txState;
+		/* zero out entire state RAM entry for the channel */
+		txState->headPtr = 0;
+		txState->sopDescPtr = 0;
+		txState->currDescPtr = 0;
+		txState->currBuffPtr = 0;
+		txState->flags = 0;
+		txState->remLength = 0;
+		/*txState->dummy = 0; */
+		txState->completionPtr = 0;
+
+	}
+	for (i = 0; i < ARRAY_SIZE(pController->rxCppi); i++) {
+		struct cppi_channel	*rxChannel = pController->rxCppi + i;
+		struct cppi_rx_stateram *__iomem rxState;
+
+		INIT_LIST_HEAD(&rxChannel->tx_complete);
+
+		rxState = regBase + DAVINCI_RXCPPI_STATERAM_OFFSET(i);
+		rxChannel->stateRam = rxState;
+		cppi_reset_rx(rxChannel->stateRam);
+	}
+
+	/* enable individual cppi channels */
+	musb_writel(regBase, DAVINCI_TXCPPI_INTENAB_REG,
+			DAVINCI_DMA_ALL_CHANNELS_ENABLE);
+	musb_writel(regBase, DAVINCI_RXCPPI_INTENAB_REG,
+			DAVINCI_DMA_ALL_CHANNELS_ENABLE);
+
+	/* enable tx/rx CPPI control */
+	musb_writel(regBase, DAVINCI_TXCPPI_CTRL_REG, DAVINCI_DMA_CTRL_ENABLE);
+	musb_writel(regBase, DAVINCI_RXCPPI_CTRL_REG, DAVINCI_DMA_CTRL_ENABLE);
+
+	/* disable RNDIS mode */
+	musb_writel(regBase, DAVINCI_AUTOREQ_REG, 0);
+
+	return TRUE;
+}
+
+/*
+ *  Stop Dma controller
+ *
+ *  De-Init the Dma Controller as necessary.
+ */
+
+static u8 cppi_controller_stop(void *pPrivateData)
+{
+	struct cppi		*pController = pPrivateData;
+	void __iomem		*regBase;
+	int			i;
+
+	regBase = pController->pCoreBase - DAVINCI_BASE_OFFSET;
+	/* DISABLE INDIVIDUAL CHANNEL Interrupts */
+	musb_writel(regBase, DAVINCI_TXCPPI_INTCLR_REG,
+			DAVINCI_DMA_ALL_CHANNELS_ENABLE);
+	musb_writel(regBase, DAVINCI_RXCPPI_INTCLR_REG,
+			DAVINCI_DMA_ALL_CHANNELS_ENABLE);
+
+	DBG(1, "Tearing down RX and TX Channels\n");
+	for (i = 0; i < ARRAY_SIZE(pController->txCppi); i++) {
+		/* FIXME restructure of txdma to use bds like rxdma */
+		pController->txCppi[i].lastHwBDProcessed = NULL;
+		cppi_pool_free(pController->txCppi + i);
+	}
+	for (i = 0; i < ARRAY_SIZE(pController->rxCppi); i++)
+		cppi_pool_free(pController->rxCppi + i);
+
+	/* in Tx Case proper teardown is supported. We resort to disabling
+	 * Tx/Rx CPPI after cleanup of Tx channels. Before TX teardown is
+	 * complete TX CPPI cannot be disabled.
+	 */
+	/*disable tx/rx cppi */
+	musb_writel(regBase, DAVINCI_TXCPPI_CTRL_REG, DAVINCI_DMA_CTRL_DISABLE);
+	musb_writel(regBase, DAVINCI_RXCPPI_CTRL_REG, DAVINCI_DMA_CTRL_DISABLE);
+
+	return TRUE;
+}
+
+/*
+ * Allocate a CPPI Channel for DMA.  With CPPI, channels are bound to
+ * each transfer direction of a non-control endpoint, so allocating
+ * (and deallocating) is mostly a way to notice bad housekeeping on
+ * the software side.  We assume the irqs are always active.
+ */
+static struct dma_channel *
+cppi_channel_allocate(void *pPrivateData, u8 bLocalEnd,
+		u8 bTransmit, u8 bProtocol, u16 wMaxPacketSize)
+{
+	struct cppi		*pController = pPrivateData;
+	u8			chNum;
+	struct cppi_channel	*otgCh;
+	struct musb		*pThis = pController->musb;
+	struct musb_hw_ep	*ep = pThis->aLocalEnd + bLocalEnd;
+
+	/* remember bLocalEnd: 1..Max_EndPt, and cppi ChNum:0..Max_EndPt-1 */
+	chNum = bLocalEnd - 1;
+
+	/* as of now, just return the corresponding CPPI Channel Handle */
+	if (bTransmit) {
+		if (bLocalEnd > ARRAY_SIZE(pController->txCppi)) {
+			DBG(1, "no %cX DMA channel for ep%d\n", 'T', bLocalEnd);
+			return NULL;
+		}
+		otgCh = pController->txCppi + chNum;
+	} else {
+		if (bLocalEnd > ARRAY_SIZE(pController->rxCppi)) {
+			DBG(1, "no %cX DMA channel for ep%d\n", 'R', bLocalEnd);
+			return NULL;
+		}
+		otgCh = pController->rxCppi + chNum;
+	}
+
+	/* REVISIT make this an error later once the same driver code works
+	 * with the Mentor DMA engine too
+	 */
+	if (otgCh->pEndPt)
+		DBG(1, "re-allocating DMA%d %cX channel %p\n",
+				chNum, bTransmit ? 'T' : 'R', otgCh);
+	otgCh->pEndPt = ep;
+	otgCh->Channel.bStatus = MGC_DMA_STATUS_FREE;
+
+	DBG(4, "Allocate CPPI%d %cX\n", chNum, bTransmit ? 'T' : 'R');
+	otgCh->Channel.pPrivateData = otgCh;
+	return &otgCh->Channel;
+}
+
+/* Release a CPPI Channel.  */
+static void cppi_channel_release(struct dma_channel *channel)
+{
+	struct cppi_channel	*c;
+
+	/* REVISIT:  for paranoia, check state and abort if needed... */
+
+	c = container_of(channel, struct cppi_channel, Channel);
+	if (!c->pEndPt)
+		DBG(1, "releasing idle DMA channel %p\n", c);
+
+	/* but for now, not its IRQ */
+	c->pEndPt = NULL;
+	channel->bStatus = MGC_DMA_STATUS_UNKNOWN;
+}
+
+/* Context: controller irqlocked */
+static void
+cppi_dump_rx(int level, struct cppi_channel *c, const char *tag)
+{
+	void	*__iomem base = c->pController->pCoreBase;
+
+	MGC_SelectEnd(base, c->chNo + 1);
+
+	DBG(level, "RX DMA%d%s: %d left, csr %04x, "
+			"%08x H%08x S%08x C%08x, "
+			"B%08x L%08x %08x .. %08x"
+			"\n",
+		c->chNo, tag,
+		musb_readl(base - DAVINCI_BASE_OFFSET,
+			DAVINCI_RXCPPI_BUFCNT0_REG + 4 *c->chNo),
+		MGC_ReadCsr16(base, MGC_O_HDRC_RXCSR, c->chNo + 1),
+
+		musb_readl(c->stateRam, 0 * 4),	/* buf offset */
+		musb_readl(c->stateRam, 1 * 4),	/* head ptr */
+		musb_readl(c->stateRam, 2 * 4),	/* sop bd */
+		musb_readl(c->stateRam, 3 * 4),	/* current bd */
+
+		musb_readl(c->stateRam, 4 * 4),	/* current buf */
+		musb_readl(c->stateRam, 5 * 4),	/* pkt len */
+		musb_readl(c->stateRam, 6 * 4),	/* byte cnt */
+		musb_readl(c->stateRam, 7 * 4)	/* completion */
+		);
+}
+
+/* Context: controller irqlocked */
+static void
+cppi_dump_tx(int level, struct cppi_channel *c, const char *tag)
+{
+	void	*__iomem base = c->pController->pCoreBase;
+
+	MGC_SelectEnd(base, c->chNo + 1);
+
+	DBG(level, "TX DMA%d%s: csr %04x, "
+			"H%08x S%08x C%08x %08x, "
+			"F%08x L%08x .. %08x"
+			"\n",
+		c->chNo, tag,
+		MGC_ReadCsr16(base, MGC_O_HDRC_TXCSR, c->chNo + 1),
+
+		musb_readl(c->stateRam, 0 * 4),	/* head ptr */
+		musb_readl(c->stateRam, 1 * 4),	/* sop bd */
+		musb_readl(c->stateRam, 2 * 4),	/* current bd */
+		musb_readl(c->stateRam, 3 * 4),	/* buf offset */
+
+		musb_readl(c->stateRam, 4 * 4),	/* flags */
+		musb_readl(c->stateRam, 5 * 4),	/* len */
+		// dummy/unused word 6
+		musb_readl(c->stateRam, 7 * 4)	/* completion */
+		);
+}
+
+/* Context: controller irqlocked */
+static inline void
+cppi_rndis_update(struct cppi_channel *c, int is_rx,
+		void *__iomem tibase, int is_rndis)
+{
+	/* we may need to change the rndis flag for this cppi channel */
+	if (c->bLastModeRndis != is_rndis) {
+		u32	regVal = musb_readl(tibase, DAVINCI_RNDIS_REG);
+		u32	temp = 1 << (c->chNo);
+
+		if (is_rx)
+			temp <<= 16;
+		if (is_rndis)
+			regVal |= temp;
+		else
+			regVal &= ~temp;
+		musb_writel(tibase, DAVINCI_RNDIS_REG, regVal);
+		c->bLastModeRndis = is_rndis;
+	}
+}
+
+static void cppi_dump_rxbd(const char *tag, struct cppi_descriptor *bd)
+{
+	pr_debug("RXBD/%s %08x: "
+			"nxt %08x buf %08x off.blen %08x opt.plen %08x\n",
+			tag, bd->dma,
+			bd->hNext, bd->buffPtr, bd->bOffBLen, bd->hOptions);
+}
+
+static void cppi_dump_rxq(int level, const char *tag, struct cppi_channel *rx)
+{
+#if MUSB_DEBUG > 0
+	struct cppi_descriptor	*bd;
+
+	if (!_dbg_level(level))
+		return;
+	cppi_dump_rx(level, rx, tag);
+	if (rx->lastHwBDProcessed)
+		cppi_dump_rxbd("last", rx->lastHwBDProcessed);
+	for (bd = rx->activeQueueHead; bd; bd = bd->next)
+		cppi_dump_rxbd("active", bd);
+#endif
+}
+
+
+static inline int cppi_autoreq_update(struct cppi_channel *rx,
+		void *__iomem tibase, int onepacket, unsigned n_bds)
+{
+	u32	tmp, val;
+
+	/* assert(is_host_active(musb)) */
+
+	/* start from "AutoReq never" */
+	tmp = musb_readl(tibase, DAVINCI_AUTOREQ_REG);
+	val = tmp & ~((0x3) << (rx->chNo * 2));
+
+	/* HCD arranged reqpkt for packet #1.  we arrange int
+	 * for all but the last one, maybe in two segments.
+	 */
+	if (!onepacket) {
+#if 0
+		/* use two segments, autoreq "all" then the last "never" */
+		val |= ((0x3) << (rx->chNo * 2));
+		n_bds--;
+#else
+		/* one segment, autoreq "all-but-last" */
+		val |= ((0x2) << (rx->chNo * 2));
+#endif
+	}
+
+	if (val != tmp) {
+		int n = 100;
+
+		/* make sure that autoreq is updated before continuing */
+		musb_writel(tibase, DAVINCI_AUTOREQ_REG, val);
+		do {
+			tmp = musb_readl(tibase, DAVINCI_AUTOREQ_REG);
+			if (tmp == val)
+				break;
+			cpu_relax();
+		} while (n-- > 0);
+	}
+
+	/* REQPKT is turned off after each segment */
+	if (n_bds && rx->actualLen) {
+		val = MGC_ReadCsr16(tibase + DAVINCI_BASE_OFFSET,
+				MGC_O_HDRC_RXCSR, rx->chNo + 1);
+		if (!(val & MGC_M_RXCSR_H_REQPKT)) {
+			val |= MGC_M_RXCSR_H_REQPKT | MGC_M_RXCSR_H_WZC_BITS;
+			MGC_WriteCsr16(tibase + DAVINCI_BASE_OFFSET,
+					MGC_O_HDRC_RXCSR, rx->chNo + 1, val);
+		}
+	}
+	return n_bds;
+}
+
+
+/* Buffer enqueuing Logic:
+ *
+ *  - RX builds new queues each time, to help handle routine "early
+ *    termination" cases (faults, including errors and short reads)
+ *    more correctly.
+ *
+ *  - for now, TX reuses the same queue of BDs every time
+ *
+ * REVISIT long term, we want a normal dynamic model.
+ * ... the goal will be to append to the
+ * existing queue, processing completed "dma buffers" (segments) on the fly.
+ *
+ * Otherwise we force an IRQ latency between requests, which slows us a lot
+ * (especially in "transparent" dma).  Unfortunately that model seems to be
+ * inherent in the DMA model from the Mentor code, except in the rare case
+ * of transfers big enough (~128+ KB) that we could append "middle" segments
+ * in the TX paths.  (RX can't do this, see below.)
+ *
+ * That's true even in the CPPI- friendly iso case, where most urbs have
+ * several small segments provided in a group and where the "packet at a time"
+ * "transparent" DMA model is always correct, even on the RX side.
+ */
+
+/*
+ * CPPI TX:
+ * ========
+ * TX is a lot more reasonable than RX; it doesn't need to run in
+ * irq-per-packet mode very often.  RNDIS mode seems to behave too
+ * (other how it handles the exactly-N-packets case).  Building a
+ * txdma queue with multiple requests (urb or usb_request) looks
+ * like it would work ... but fault handling still needs testing.
+ */
+static void
+cppi_next_tx_segment(struct musb *musb, struct cppi_channel *tx, int rndis)
+{
+	unsigned		maxpacket = tx->pktSize;
+	dma_addr_t		addr = tx->startAddr + tx->currOffset;
+	size_t			length = tx->transferSize - tx->currOffset;
+	struct cppi_descriptor	*bd;
+//	struct cppi_descriptor	*tail;
+	unsigned		n_bds;
+	unsigned		i;
+	struct cppi_tx_stateram	*txState = tx->stateRam;
+
+	/* TX can use the CPPI "rndis" mode, where we can probably fit this
+	 * transfer in one BD and one IRQ; though some common cases (like
+	 * packet length not being n*64 bytes) can't work that way.
+	 *
+	 * To cppi hardware (but not the RNDIS protocol!) RNDIS is mostly a
+	 * "short packet termination" mode.  So the only time we would NOT
+	 * want to use it is to avoid sending spurious zero length packets,
+	 * or when hardware constraints prevent it.
+	 */
+	if (!rndis && (length % maxpacket) != 0)
+		rndis = 1;
+	if (rndis && (length > 0xffff
+			|| (maxpacket & 0x3f) != 0
+			/* "undocumented" rndis mode constraint on txlen */
+			|| (length & 0x3f) != 0))
+		rndis = 0;
+
+	if (rndis) {
+		maxpacket = length;
+		n_bds = 1;
+	} else {
+		n_bds = length / maxpacket;
+		if (length % maxpacket)
+			n_bds++;
+		n_bds = min(n_bds, (unsigned) NUM_TXCHAN_BD);
+		length = min(n_bds * maxpacket, length);
+	}
+
+	DBG(4, "TX DMA%d, pktSz %d %s bds %d dma 0x%x len %u\n",
+			tx->chNo,
+			maxpacket,
+			rndis ? "rndis" : "transparent",
+			n_bds,
+			addr, length);
+
+	cppi_rndis_update(tx, 0, musb->ctrl_base, rndis);
+
+	/* assuming here that DmaProgramChannel is called during
+	 * transfer initiation ... current code maintains state
+	 * for one outstanding request only (no queues, not even
+	 * the implicit ones of an iso urb).
+	 */
+
+	bd = tx->bdPoolHead;
+	tx->activeQueueHead = tx->bdPoolHead;
+	tx->lastHwBDProcessed = NULL;
+
+
+	/* Prepare queue of BDs first, then hand it to hardware.
+	 * All BDs except maybe the last should be of full packet
+	 * size; for RNDIS there _is_ only that last packet.
+	 */
+	for (i = 0; i < n_bds; ) {
+		if (++i < n_bds && bd->next)
+			bd->hNext = bd->next->dma;
+		else
+			bd->hNext = 0;
+
+		bd->buffPtr = tx->startAddr
+			+ tx->currOffset;
+
+		/* FIXME set EOP only on the last packet,
+		 * SOP only on the first ... avoid IRQs
+		 */
+		if ((tx->currOffset + maxpacket)
+				<= tx->transferSize) {
+			tx->currOffset += maxpacket;
+			bd->bOffBLen = maxpacket;
+			bd->hOptions = CPPI_SOP_SET | CPPI_EOP_SET
+				| CPPI_OWN_SET | maxpacket;
+		} else {
+			/* only this one may be a partial USB Packet */
+			u32 buffSz;
+
+			buffSz = tx->transferSize
+				- tx->currOffset;
+			tx->currOffset = tx->transferSize;
+			bd->bOffBLen = buffSz;
+
+			bd->hOptions = CPPI_SOP_SET | CPPI_EOP_SET
+				| CPPI_OWN_SET | buffSz;
+			if (buffSz == 0)
+				bd->hOptions |= CPPI_ZERO_SET;
+		}
+
+		DBG(5, "TXBD %p: nxt %08x buf %08x len %04x opt %08x\n",
+				bd, bd->hNext, bd->buffPtr,
+				bd->bOffBLen, bd->hOptions);
+
+		/* update the last BD enqueued to the list */
+		tx->activeQueueTail = bd;
+		bd = bd->next;
+	}
+
+	/* BDs live in DMA-coherent memory, but writes might be pending */
+	cpu_drain_writebuffer();
+
+	/* Write to the HeadPtr in StateRam to trigger */
+	txState->headPtr = (u32)tx->bdPoolHead->dma;
+
+	cppi_dump_tx(5, tx, "/S");
+}
+
+/*
+ * CPPI RX:
+ * ========
+ * Consider a 1KB bulk RX buffer in two scenarios:  (a) it's fed two 300 byte
+ * packets back-to-back, and (b) it's fed two 512 byte packets back-to-back.
+ * (Full speed transfers have similar scenarios.)
+ *
+ * The correct behavior for Linux is that (a) fills the buffer with 300 bytes,
+ * and the next packet goes into a buffer that's queued later; while (b) fills
+ * the buffer with 1024 bytes.  How to do that with CPPI?
+ *
+ * - CPPI RX queues in "rndis" mode -- one single BD -- handle (a) correctly,
+ *   but (b) loses _badly_ because nothing (!) happens when that second packet
+ *   fills the buffer, much less when a third one arrives.  (Which makes this
+ *   not a "true" RNDIS mode.  In the RNDIS protocol short-packet termination
+ *   is optional, and it's fine if senders pad messages out to end-of-buffer.)
+ *
+ * - CPPI RX queues in "transparent" mode -- two BDs with 512 bytes each -- have
+ *   converse problems:  (b) is handled correctly, but (a) loses badly.  CPPI RX
+ *   ignores SOP/EOP markings and processes both of those BDs; so both packets
+ *   are loaded into the buffer (with a 212 byte gap between them), and the next
+ *   buffer queued will NOT get its 300 bytes of data. (It seems like SOP/EOP
+ *   are intended as outputs for RX queues, not inputs...)
+ *
+ * - A variant of "transparent" mode -- one BD at a time -- is the only way to
+ *   reliably make both cases work, with software handling both cases correctly
+ *   and at the significant penalty of needing an IRQ per packet.  (The lack of
+ *   I/O overlap can be slightly ameliorated by enabling double buffering.)
+ *
+ * So how to get rid of IRQ-per-packet?  The transparent multi-BD case could
+ * be used in special cases like mass storage, which sets URB_SHORT_NOT_OK
+ * (or maybe its peripheral side counterpart) to flag (a) scenarios as errors
+ * with guaranteed driver level fault recovery and scrubbing out what's left
+ * of that garbaged datastream.
+ *
+ * But there seems to be no way to identify the cases where CPPI RNDIS mode
+ * is appropriate -- which do NOT include the RNDIS driver, but do include
+ * the CDC Ethernet driver! -- and the documentation is incomplete/wrong.
+ * So we can't _ever_ use RX RNDIS mode.
+ *
+ * Leaving only "transparent" mode; we avoid multi-bd modes in almost all
+ * cases other than mass storage class.  Otherwise e're correct but slow,
+ * since CPPI penalizes our need for a "true RNDIS" default mode.
+ */
+
+/**
+ * cppi_next_rx_segment - dma read for the next chunk of a buffer
+ * @musb: the controller
+ * @rx: dma channel
+ * @onepacket: true unless caller treats short reads as errors, and
+ * 	performs fault recovery above usbcore.
+ * Context: controller irqlocked
+ *
+ * See above notes about why we can't use multi-BD RX queues except in
+ * rare cases (mass storage class), and can never use the hardware "rndis"
+ * mode (since it's not a "true" RNDIS mode).
+ *
+ * It's ESSENTIAL that callers specify "onepacket" mode unless they kick in
+ * code to recover from corrupted datastreams after each short transfer.
+ */
+static void
+cppi_next_rx_segment(struct musb *musb, struct cppi_channel *rx, int onepacket)
+{
+	unsigned		maxpacket = rx->pktSize;
+	dma_addr_t		addr = rx->startAddr + rx->currOffset;
+	size_t			length = rx->transferSize - rx->currOffset;
+	struct cppi_descriptor	*bd, *tail;
+	unsigned		n_bds;
+	unsigned		i;
+	void			*__iomem tibase = musb->ctrl_base;
+
+	/*printk("st=%d off=%d sz=%d len=%d 1=%d",rx->startAddr,rx->currOffset,rx->transferSize,length,onepacket);*/
+
+	if (onepacket) {
+		n_bds = 1;
+	} else {
+		if (length > 0xffff) {
+			n_bds = 0xffff / maxpacket;
+			length = n_bds * maxpacket;
+		} else {
+			n_bds = length / maxpacket;
+			if (length % maxpacket)
+				n_bds++;
+		}
+		if (n_bds == 1)
+			onepacket = 1;
+		else
+			n_bds = min(n_bds, (unsigned) NUM_RXCHAN_BD);
+	}
+
+	/* In host mode, autorequest logic can generate some IN tokens; it's
+	 * tricky since we can't leave REQPKT set in RXCSR after the transfer
+	 * finishes. So:  multipacket transfers involve two or more segments.
+	 * And always at least two IRQs.
+	 */
+	if (is_host_active(musb))
+		n_bds = cppi_autoreq_update(rx, tibase, onepacket, n_bds);
+
+	length = min(n_bds * maxpacket, length);
+
+	/*printk("len=%d bds=%d \n",length,n_bds);*/
+
+	DBG(4, "RX DMA%d seg, maxp %d %spacket bds %d (cnt %d) "
+			"dma 0x%x len %u/%u/%u\n",
+			rx->chNo, maxpacket,
+			onepacket ? "one" : "multi",
+			n_bds,
+			musb_readl(tibase,
+				DAVINCI_RXCPPI_BUFCNT0_REG + (rx->chNo * 4))
+					& 0xffff,
+			addr, length, rx->actualLen, rx->transferSize);
+
+	/* only queue one segment at a time, since the hardware prevents
+	 * correct queue shutdown after unexpected short packets
+	 */
+	bd = cppi_bd_alloc(rx);
+	rx->activeQueueHead = bd;
+
+	/* Build BDs for all packets in this segment */
+	for (i = 0, tail = NULL; bd && i < n_bds; i++, tail = bd) {
+		u32	buffSz;
+
+		if (i) {
+			bd = cppi_bd_alloc(rx);
+			if (!bd)
+				break;
+			tail->next = bd;
+			tail->hNext = bd->dma;
+		}
+		bd->hNext = 0;
+
+		/* all but the last packet will be maxpacket size */
+		if (maxpacket < length)
+			buffSz = maxpacket;
+		else
+			buffSz = length;
+
+		bd->buffPtr = addr;
+		addr += buffSz;
+		rx->currOffset += buffSz;
+
+		bd->bOffBLen = (0 /*offset*/ << 16) + buffSz;
+		bd->enqBuffLen = buffSz;
+
+		bd->hOptions = CPPI_OWN_SET | (i == 0 ? length : 0);
+		length -= buffSz;
+	}
+
+	/* we always expect at least one reusable BD! */
+	if (!tail) {
+		WARN("rx dma%d -- no BDs? need %d\n", rx->chNo, n_bds);
+		return;
+	} else if (i < n_bds)
+		WARN("rx dma%d -- only %d of %d BDs\n", rx->chNo, i, n_bds);
+
+	tail->next = NULL;
+	tail->hNext = 0;
+
+	bd = rx->activeQueueHead;
+	rx->activeQueueTail = tail;
+
+	/* short reads and other faults should terminate this entire
+	 * dma segment.  we want one "dma packet" per dma segment, not
+	 * one per USB packet, terminating the whole queue at once...
+	 * NOTE that current hardware seems to ignore SOP and EOP.
+	 */
+	bd->hOptions |= CPPI_SOP_SET;
+	tail->hOptions |= CPPI_EOP_SET;
+
+	if (MGC_DebugLevel >= 5) {
+		struct cppi_descriptor	*d;
+
+		for (d = rx->activeQueueHead; d; d = d->next)
+			cppi_dump_rxbd("S", d);
+	}
+
+	/* in case the preceding transfer left some state... */
+	tail = rx->lastHwBDProcessed;
+	if (tail) {
+		tail->next = bd;
+		tail->hNext = bd->dma;
+	}
+
+	/* BDs live in DMA-coherent memory, but writes might be pending */
+	cpu_drain_writebuffer();
+
+	/* REVISIT specs say to write this AFTER the BUFCNT register
+	 * below ... but that loses badly.
+	 */
+	musb_writel(rx->stateRam, 4, bd->dma);
+
+	/* bufferCount must be at least 3, and zeroes on completion
+	 * unless it underflows below zero, or stops at two, or keeps
+	 * growing ... grr.
+	 */
+	i = musb_readl(tibase,
+			DAVINCI_RXCPPI_BUFCNT0_REG + (rx->chNo * 4))
+			& 0xffff;
+
+	if (!i)
+		musb_writel(tibase,
+			DAVINCI_RXCPPI_BUFCNT0_REG + (rx->chNo * 4),
+			n_bds + 2);
+	else if (n_bds > (i - 3))
+		musb_writel(tibase,
+			DAVINCI_RXCPPI_BUFCNT0_REG + (rx->chNo * 4),
+			n_bds - (i - 3));
+
+	i = musb_readl(tibase,
+			DAVINCI_RXCPPI_BUFCNT0_REG + (rx->chNo * 4))
+			& 0xffff;
+	if (i < (2 + n_bds)) {
+		DBG(2, "bufcnt%d underrun - %d (for %d)\n",
+					rx->chNo, i, n_bds);
+		musb_writel(tibase,
+			DAVINCI_RXCPPI_BUFCNT0_REG + (rx->chNo * 4),
+			n_bds + 2);
+	}
+
+	cppi_dump_rx(4, rx, "/S");
+}
+
+/**
+ * cppi_channel_program - program channel for data transfer
+ * @pChannel: the channel
+ * @wPacketSz: max packet size
+ * @mode: For RX, 1 unless the usb protocol driver promised to treat
+ * 	all short reads as errors and kick in high level fault recovery.
+ * 	For TX, 0 unless the protocol driver _requires_ short-packet
+ * 	termination mode.
+ * @dma_addr: dma address of buffer
+ * @dwLength: length of buffer
+ * Context: controller irqlocked
+ */
+static u8 cppi_channel_program(struct dma_channel *pChannel,
+		u16 wPacketSz, u8 mode,
+		dma_addr_t dma_addr, u32 dwLength)
+{
+	struct cppi_channel	*otgChannel = pChannel->pPrivateData;
+	struct cppi		*pController = otgChannel->pController;
+	struct musb		*musb = pController->musb;
+
+	switch (pChannel->bStatus) {
+	case MGC_DMA_STATUS_BUS_ABORT:
+	case MGC_DMA_STATUS_CORE_ABORT:
+		/* fault irq handler should have handled cleanup */
+		WARN("%cX DMA%d not cleaned up after abort!\n",
+				otgChannel->bTransmit ? 'T' : 'R',
+				otgChannel->chNo);
+		//WARN_ON(1);
+		break;
+	case MGC_DMA_STATUS_BUSY:
+		WARN("program active channel?  %cX DMA%d\n",
+				otgChannel->bTransmit ? 'T' : 'R',
+				otgChannel->chNo);
+		//WARN_ON(1);
+		break;
+	case MGC_DMA_STATUS_UNKNOWN:
+		DBG(1, "%cX DMA%d not allocated!\n",
+				otgChannel->bTransmit ? 'T' : 'R',
+				otgChannel->chNo);
+		/* FALLTHROUGH */
+	case MGC_DMA_STATUS_FREE:
+		break;
+	}
+
+	pChannel->bStatus = MGC_DMA_STATUS_BUSY;
+
+	/* set transfer parameters, then queue up its first segment */
+	otgChannel->startAddr = dma_addr;
+	otgChannel->currOffset = 0;
+	otgChannel->pktSize = wPacketSz;
+	otgChannel->actualLen = 0;
+	otgChannel->transferSize = dwLength;
+  	otgChannel->rxMode = mode;
+
+	/* TX channel? or RX? */
+	if (otgChannel->bTransmit)
+		cppi_next_tx_segment(musb, otgChannel, mode);
+	else
+		cppi_next_rx_segment(musb, otgChannel, mode);
+
+	return TRUE;
+}
+
+static int cppi_rx_scan(struct cppi *cppi, unsigned ch)
+{
+	struct cppi_channel		*rx = &cppi->rxCppi[ch];
+	struct cppi_rx_stateram		*state = rx->stateRam;
+	struct cppi_descriptor		*bd;
+	struct cppi_descriptor		*last = rx->lastHwBDProcessed;
+	int				completed = 0, acked = 0;
+	int				i;
+	dma_addr_t			safe2ack;
+
+	cppi_dump_rx(6, rx, "/K");
+
+	bd = last ? last->next : rx->activeQueueHead;
+	if (!bd)
+		return 0;
+
+	/* run through all completed BDs */
+	for (i = 0, safe2ack = musb_readl(CAST &state->completionPtr, 0);
+			(safe2ack || completed) && bd && i < NUM_RXCHAN_BD;
+			i++, bd = bd->next) {
+		u16	len;
+
+		rmb();
+		if (!completed && (bd->hOptions & CPPI_OWN_SET))
+			break;
+
+		DBG(5, "C/RXBD %08x: nxt %08x buf %08x "
+			"off.len %08x opt.len %08x (%d)\n",
+			 bd->dma, bd->hNext, bd->buffPtr,
+			 bd->bOffBLen, bd->hOptions,
+			 rx->actualLen);
+
+		/* actual packet received length */
+		if ((bd->hOptions & CPPI_SOP_SET) && !completed)
+			len = bd->bOffBLen & CPPI_RECV_PKTLEN_MASK;
+		else
+			len = 0;
+
+		if (bd->hOptions & CPPI_EOQ_MASK)
+			completed = 1;
+
+		if (!completed && len < bd->enqBuffLen) {
+			/* NOTE:  when we get a short packet, RXCSR_H_REQPKT
+			 * must have been cleared, and no more DMA packets may
+			 * active be in the queue... TI docs didn't say, but
+			 * CPPI ignores those BDs even though OWN is still set.
+			 */
+			completed = 1;
+			DBG(3, "rx short %d/%d (%d)\n",
+					len, bd->enqBuffLen, rx->actualLen);
+		}
+
+		/* If we got here, we expect to ack at least one BD; meanwhile
+		 * CPPI may completing other BDs while we scan this list...
+		 *
+		 * RACE: we can notice OWN cleared before CPPI raises the
+		 * matching irq by writing that BD as the completion pointer.
+		 * In such cases, stop scanning and wait for the irq, avoiding
+		 * lost acks and states where BD ownership is unclear.
+		 */
+		if (bd->dma == safe2ack) {
+			musb_writel(CAST &state->completionPtr, 0, safe2ack);
+			safe2ack = musb_readl(CAST &state->completionPtr, 0);
+			acked = 1;
+			if (bd->dma == safe2ack)
+				safe2ack = 0;
+		}
+
+		rx->actualLen += len;
+
+		cppi_bd_free(rx, last);
+		last = bd;
+
+		/* stop scanning on end-of-segment */
+		if (bd->hNext == 0)
+			completed = 1;
+	}
+	rx->lastHwBDProcessed = last;
+
+	/* dma abort, lost ack, or ... */
+	if (!acked && last) {
+		int	csr;
+
+		if (safe2ack == 0 || safe2ack == rx->lastHwBDProcessed->dma)
+			musb_writel(CAST &state->completionPtr, 0, safe2ack);
+		if (safe2ack == 0) {
+			cppi_bd_free(rx, last);
+			rx->lastHwBDProcessed = NULL;
+
+			/* if we land here on the host side, H_REQPKT will
+			 * be clear and we need to restart the queue...
+			 */
+			WARN_ON(rx->activeQueueHead);
+		}
+		MGC_SelectEnd(cppi->pCoreBase, rx->chNo + 1);
+		csr = MGC_ReadCsr16(cppi->pCoreBase,
+				MGC_O_HDRC_RXCSR, rx->chNo + 1);
+		if (csr & MGC_M_RXCSR_DMAENAB) {
+			DBG(4, "list%d %p/%p, last %08x%s, csr %04x\n",
+				rx->chNo,
+				rx->activeQueueHead, rx->activeQueueTail,
+				rx->lastHwBDProcessed
+					? rx->lastHwBDProcessed->dma
+					: 0,
+				completed ? ", completed" : "",
+				csr);
+			cppi_dump_rxq(4, "/what?", rx);
+		}
+	}
+	if (!completed) {
+		int	csr;
+
+		rx->activeQueueHead = bd;
+
+		/* REVISIT seems like "autoreq all but EOP" doesn't... */
+		csr = MGC_ReadCsr16(cppi->pCoreBase,
+				MGC_O_HDRC_RXCSR, rx->chNo + 1);
+		if (is_host_active(cppi->musb)
+				&& bd
+				&& !(csr & MGC_M_RXCSR_H_REQPKT)) {
+			csr |= MGC_M_RXCSR_H_REQPKT;
+			MGC_WriteCsr16(cppi->pCoreBase,
+					MGC_O_HDRC_RXCSR, rx->chNo + 1,
+					MGC_M_RXCSR_H_WZC_BITS | csr);
+		}
+	} else {
+		rx->activeQueueHead = NULL;
+		rx->activeQueueTail = NULL;
+	}
+
+	cppi_dump_rx(6, rx, completed ? "/completed" : "/cleaned");
+	return completed;
+}
+
+void cppi_completion(struct musb *pThis, u32 rx, u32 tx)
+{
+	void			*__iomem regBase;
+	int			i, chanNum, numCompleted;
+	u8			bReqComplete;
+	struct cppi		*cppi;
+	struct cppi_descriptor	*bdPtr;
+	struct musb_hw_ep	*pEnd = NULL;
+
+	cppi = container_of(pThis->pDmaController, struct cppi, Controller);
+
+	regBase = cppi->pCoreBase - DAVINCI_BASE_OFFSET;
+
+	chanNum = 0;
+	/* process TX channels */
+	for (chanNum = 0; tx; tx = tx >> 1, chanNum++) {
+		if (tx & 1) {
+			struct cppi_channel		*txChannel;
+			struct cppi_tx_stateram		*txState;
+
+			txChannel = cppi->txCppi + chanNum;
+			txState = txChannel->stateRam;
+
+			/* FIXME  need a cppi_tx_scan() routine, which
+			 * can also be called from abort code
+			 */
+
+			cppi_dump_tx(5, txChannel, "/E");
+
+			bdPtr = txChannel->activeQueueHead;
+
+			if (NULL == bdPtr) {
+				DBG(1, "null BD\n");
+				continue;
+			}
+
+			i = 0;
+			bReqComplete = 0;
+
+			numCompleted = 0;
+
+			/* run through all completed BDs */
+			for (i = 0;
+					!bReqComplete
+						&& bdPtr
+						&& i < NUM_TXCHAN_BD;
+					i++, bdPtr = bdPtr->next) {
+				u16	len;
+
+				rmb();
+				if (bdPtr->hOptions & CPPI_OWN_SET)
+					break;
+
+				DBG(5, "C/TXBD %p n %x b %x off %x opt %x\n",
+						bdPtr, bdPtr->hNext,
+						bdPtr->buffPtr,
+						bdPtr->bOffBLen,
+						bdPtr->hOptions);
+
+				len = bdPtr->bOffBLen & CPPI_BUFFER_LEN_MASK;
+				txChannel->actualLen += len;
+
+				numCompleted++;
+				txChannel->lastHwBDProcessed = bdPtr;
+
+				/* write completion register to acknowledge
+				 * processing of completed BDs, and possibly
+				 * release the IRQ; EOQ might not be set ...
+				 *
+				 * REVISIT use the same ack strategy as rx
+				 */
+//				if ((bdPtr->hOptions & CPPI_EOQ_MASK))
+					txState->completionPtr = bdPtr->dma;
+
+				/* stop scanning on end-of-segment */
+				if (bdPtr->hNext == 0)
+					bReqComplete = 1;
+			}
+
+			/* on end of segment, maybe go to next one */
+			if (bReqComplete) {
+				//cppi_dump_tx(4, txChannel, "/complete");
+
+				/* transfer more, or report completion */
+				if (txChannel->currOffset
+						>= txChannel->transferSize) {
+					txChannel->activeQueueHead = NULL;
+					txChannel->activeQueueTail = NULL;
+					txChannel->Channel.bStatus =
+							MGC_DMA_STATUS_FREE;
+
+					pEnd = txChannel->pEndPt;
+
+					txChannel->Channel.dwActualLength =
+						txChannel->actualLen;
+
+					/* Peripheral role never repurposes the
+					 * endpoint, so immediate completion is
+					 * save.  Host role waits for the fifo
+					 * to empty (TXPKTRDY irq) before going
+					 * to the next queued bulk transfer.
+					 */
+					if (is_peripheral_active(cppi->musb))
+						cppi->dma_completed(pThis,
+							      chanNum + 1, 1);
+
+				} else {
+					/* Bigger transfer than we could fit in
+					 * that first batch of descriptors...
+					 */
+					cppi_next_tx_segment(pThis,
+							txChannel, 0);
+				}
+			} else
+				txChannel->activeQueueHead = bdPtr;
+		}
+	}
+
+	/* Start processing the RX block */
+	for (chanNum = 0; rx; rx = rx >> 1, chanNum++) {
+
+		if (rx & 1) {
+			struct cppi_channel		*rxChannel;
+
+			rxChannel = cppi->rxCppi + chanNum;
+			bReqComplete = cppi_rx_scan(cppi, chanNum);
+
+			/* let incomplete dma segments finish */
+			if (!bReqComplete)
+				continue;
+
+			/* start another dma segment if needed */
+			if (rxChannel->actualLen != rxChannel->transferSize
+					&& rxChannel->actualLen
+						== rxChannel->currOffset) {
+				cppi_next_rx_segment(pThis, rxChannel, rxChannel->rxMode);
+				continue;
+			}
+
+			/* all segments completed! */
+			rxChannel->Channel.bStatus = MGC_DMA_STATUS_FREE;
+
+			pEnd = rxChannel->pEndPt;
+
+			rxChannel->Channel.dwActualLength =
+					rxChannel->actualLen;
+			(void) cppi->dma_completed(pThis, chanNum + 1, 0);
+		}
+	}
+
+	/* write to CPPI EOI register to re-enable interrupts */
+	musb_writel(regBase, DAVINCI_CPPI_EOI_REG, 0);
+}
+
+/* Instantiate a software object representing a DMA controller. */
+static struct dma_controller *
+cppi_controller_new(MGC_pfDmaChannelStatusChanged dma_completed,
+		void *musb, u8 *pCoreBase)
+{
+	struct dma_controller	*pResult = NULL;
+	struct cppi		*pController;
+
+	pController = kzalloc(sizeof *pController, GFP_KERNEL);
+	if (!pController)
+		return NULL;
+
+	/* Initialize the Cppi DmaController  structure */
+	pController->dma_completed = dma_completed;
+
+	pController->pCoreBase = pCoreBase;
+	pController->musb = musb;
+	pController->Controller.pPrivateData = pController;
+	pController->Controller.pfDmaStartController = cppi_controller_start;
+	pController->Controller.pfDmaStopController = cppi_controller_stop;
+	pController->Controller.pfDmaAllocateChannel = cppi_channel_allocate;
+	pController->Controller.pfDmaReleaseChannel = cppi_channel_release;
+	pController->Controller.pfDmaProgramChannel = cppi_channel_program;
+	pController->Controller.pfDmaAbortChannel = cppi_channel_abort;
+	pResult = &(pController->Controller);
+
+	/* NOTE: allocating from on-chip SRAM would give the least
+	 * contention for memory access, if that ever matters here.
+	 */
+
+	/* setup BufferPool */
+	pController->pool = dma_pool_create("cppi",
+			pController->musb->controller,
+			sizeof(struct cppi_descriptor),
+			CPPI_DESCRIPTOR_ALIGN, 0);
+	if (!pController->pool) {
+		kfree(pController);
+		pResult = NULL;
+	}
+
+	return pResult;
+}
+
+/*
+ *  Destroy a previously-instantiated DMA controller.
+ */
+static void cppi_controller_destroy(struct dma_controller *pController)
+{
+	struct cppi	*cpController = pController->pPrivateData;
+
+	/* assert:  caller stopped the controller first */
+	dma_pool_destroy(cpController->pool);
+
+	if (cpController) {
+		cpController->Controller.pPrivateData = NULL;
+		kfree(cpController);
+	}
+
+}
+
+/*
+ * Context: controller irqlocked, endpoint selected
+ */
+static int cppi_channel_abort(struct dma_channel *pChannel)
+{
+	struct cppi_channel	*otgCh = pChannel->pPrivateData;
+	struct cppi		*pController = otgCh->pController;
+	int			chNum = otgCh->chNo;
+	void			*__iomem mbase;
+	void			*__iomem regBase;
+	u32			regVal;
+	struct cppi_descriptor	*queue;
+
+	switch (pChannel->bStatus) {
+	case MGC_DMA_STATUS_BUS_ABORT:
+	case MGC_DMA_STATUS_CORE_ABORT:
+		/* from RX or TX fault irq handler */
+	case MGC_DMA_STATUS_BUSY:
+		/* the hardware needs shutting down */
+		break;
+	case MGC_DMA_STATUS_UNKNOWN:
+		DBG(8, "%cX DMA%d not allocated\n",
+				otgCh->bTransmit ? 'T' : 'R',
+				otgCh->chNo);
+		/* FALLTHROUGH */
+	case MGC_DMA_STATUS_FREE:
+		return 0;
+	}
+
+	if (chNum & ~CPPI_CHNUM_BITS_MASK)
+		return -EINVAL;
+
+	if (!otgCh->bTransmit && otgCh->activeQueueHead)
+		cppi_dump_rxq(3, "/abort", otgCh);
+
+	mbase = pController->pCoreBase;
+	regBase = mbase - DAVINCI_BASE_OFFSET;
+
+	queue = otgCh->activeQueueHead;
+	otgCh->activeQueueHead = NULL;
+	otgCh->activeQueueTail = NULL;
+
+	/* REVISIT should rely on caller having done this,
+	 * and caller should rely on us not changing it.
+	 * peripheral code is safe ... check host too.
+	 */
+	MGC_SelectEnd(mbase, chNum + 1);
+
+	if (otgCh->bTransmit) {
+		struct cppi_tx_stateram	*__iomem txState;
+		int			enabled;
+
+		/* mask interrupts raised to signal teardown complete.  */
+		enabled = musb_readl(regBase, DAVINCI_TXCPPI_INTENAB_REG)
+				& (1 << otgCh->chNo);
+		if (enabled)
+			musb_writel(regBase, DAVINCI_TXCPPI_INTCLR_REG,
+					(1 << otgCh->chNo));
+
+		// REVISIT put timeouts on these controller handshakes
+
+		cppi_dump_tx(6, otgCh, " (teardown)");
+
+		/* teardown DMA engine then usb core */
+		do {
+			regVal = musb_readl(regBase, DAVINCI_TXCPPI_TEAR_REG);
+		} while (!(regVal & CPPI_TEAR_READY));
+		musb_writel(regBase, DAVINCI_TXCPPI_TEAR_REG, chNum);
+
+		txState = otgCh->stateRam;
+		do {
+			regVal = txState->completionPtr;
+		} while (0xFFFFFFFC != regVal);
+		txState->completionPtr = 0xFFFFFFFC;
+
+		/* FIXME clean up the transfer state ... here?
+		 * the completion routine should get called with
+		 * an appropriate status code.
+		 */
+
+		regVal = MGC_ReadCsr16(mbase, MGC_O_HDRC_TXCSR, chNum + 1);
+		regVal &= ~MGC_M_TXCSR_DMAENAB;
+		regVal |= MGC_M_TXCSR_FLUSHFIFO;
+		MGC_WriteCsr16(mbase, MGC_O_HDRC_TXCSR, chNum + 1, regVal);
+		MGC_WriteCsr16(mbase, MGC_O_HDRC_TXCSR, chNum + 1, regVal);
+
+		/* re-enable interrupt */
+		if (enabled)
+			musb_writel(regBase, DAVINCI_TXCPPI_INTENAB_REG,
+					(1 << otgCh->chNo));
+
+		txState->headPtr = 0;
+		txState->sopDescPtr = 0;
+		txState->currBuffPtr = 0;
+		txState->currDescPtr = 0;
+		txState->flags = 0;
+		txState->remLength = 0;
+
+		/* Ensure that we clean up any Interrupt asserted
+		 * 1. Write to completion Ptr value 0x1(bit 0 set)
+		 *    (write back mode)
+		 * 2. Write to completion Ptr value 0x0(bit 0 cleared)
+		 *    (compare mode)
+		 * Value written is compared(for bits 31:2) and being
+		 * equal interrupt deasserted?
+		 */
+
+		/* write back mode, bit 0 set, hence completion Ptr
+		 * must be updated
+		 */
+		txState->completionPtr = 0x1;
+		/* compare mode, write back zero now */
+		txState->completionPtr = 0;
+
+		cppi_dump_tx(5, otgCh, " (done teardown)");
+
+		/* REVISIT tx side _should_ clean up the same way
+		 * as the RX side ... this does no cleanup at all!
+		 */
+
+	} else /* RX */ {
+		u16			csr;
+
+		/* NOTE: docs don't guarantee any of this works ...  we
+		 * expect that if the usb core stops telling the cppi core
+		 * to pull more data from it, then it'll be safe to flush
+		 * current RX DMA state iff any pending fifo transfer is done.
+		 */
+
+		/* for host, ensure ReqPkt is never set again */
+		if (is_host_active(otgCh->pController->musb)) {
+			regVal = musb_readl(regBase, DAVINCI_AUTOREQ_REG);
+			regVal &= ~((0x3) << (otgCh->chNo * 2));
+			musb_writel(regBase, DAVINCI_AUTOREQ_REG, regVal);
+		}
+
+		csr = MGC_ReadCsr16(mbase, MGC_O_HDRC_RXCSR, otgCh->chNo +1);
+
+		/* for host, clear (just) ReqPkt at end of current packet(s) */
+		if (is_host_active(otgCh->pController->musb)) {
+			csr |= MGC_M_RXCSR_H_WZC_BITS;
+			csr &= ~MGC_M_RXCSR_H_REQPKT;
+		} else
+			csr |= MGC_M_RXCSR_P_WZC_BITS;
+
+		/* clear dma enable */
+		csr &= ~(MGC_M_RXCSR_DMAENAB);
+		MGC_WriteCsr16(mbase, MGC_O_HDRC_RXCSR, otgCh->chNo + 1, csr);
+
+		/* quiesce: wait for current dma to finish (if not cleanup)
+		 * we can't use bit zero of stateram->sopDescPtr since that
+		 * refers to an entire "DMA packet" not just emptying the
+		 * current fifo, and most segements need multiple fifos.
+		 */
+		if (pChannel->bStatus == MGC_DMA_STATUS_BUSY)
+			udelay(50);
+
+		/* scan the current list, reporting any data that was
+		 * transferred and acking any IRQ
+		 */
+		cppi_rx_scan(pController, chNum);
+
+		/* clobber the existing state once it's idle
+		 *
+		 * NOTE:  arguably, we should also wait for all the other
+		 * RX channels to quiesce (how??) and then temporarily
+		 * disable RXCPPI_CTRL_REG ... but it seems that we can
+		 * rely on the controller restarting from state ram, with
+		 * only RXCPPI_BUFCNT state being bogus.  BUFCNT will
+		 * correct itself after the next DMA transfer though.
+		 *
+		 * REVISIT does using rndis mode change that?
+		 */
+		cppi_reset_rx(otgCh->stateRam);
+
+		/* next DMA request _should_ load cppi head ptr */
+
+		/* ... we don't "free" that list, only mutate it in place.  */
+		cppi_dump_rx(5, otgCh, " (done abort)");
+
+		/* clean up previously pending bds */
+		cppi_bd_free(otgCh, otgCh->lastHwBDProcessed);
+		otgCh->lastHwBDProcessed = NULL;
+
+		while (queue) {
+			struct cppi_descriptor	*tmp = queue->next;
+			cppi_bd_free(otgCh, queue);
+			queue = tmp;
+		}
+	}
+
+	pChannel->bStatus = MGC_DMA_STATUS_FREE;
+	otgCh->startAddr = 0;
+	otgCh->currOffset = 0;
+	otgCh->transferSize = 0;
+	otgCh->pktSize = 0;
+	return 0;
+}
+
+/* TBD Queries:
+ *
+ * Power Management ... probably turn off cppi during suspend, restart;
+ * check state ram?  Clocking is presumably shared with usb core.
+ */
Index: linux-2.6.10/drivers/usb/musb/cppi_dma.h
===================================================================
--- /dev/null
+++ linux-2.6.10/drivers/usb/musb/cppi_dma.h
@@ -0,0 +1,133 @@
+/* Copyright (C) 2005-2006 by Texas Instruments */
+
+#ifndef _CPPI_DMA_H_
+#define _CPPI_DMA_H_
+
+#include <linux/slab.h>
+#include <linux/list.h>
+#include <linux/smp_lock.h>
+#include <linux/errno.h>
+#include <linux/dmapool.h>
+
+#include "dma.h"
+#include "musbdefs.h"
+#include "davinci.h"
+
+
+/* hOptions bit masks for CPPI BDs */
+#define CPPI_SOP_SET	((u32)(1 << 31))
+#define CPPI_EOP_SET	((u32)(1 << 30))
+#define CPPI_OWN_SET	((u32)(1 << 29))	/* owned by cppi */
+#define CPPI_EOQ_MASK	((u32)(1 << 28))
+#define CPPI_ZERO_SET	((u32)(1 << 23))	/* rx saw zlp; tx issues one */
+#define CPPI_RXABT_MASK	((u32)(1 << 19))	/* need more rx buffers */
+
+#define CPPI_RECV_PKTLEN_MASK 0xFFFF
+#define CPPI_BUFFER_LEN_MASK 0xFFFF
+
+#define CPPI_TEAR_READY ((u32)(1 << 31))
+#define CPPI_CHNUM_BITS_MASK  0x3
+
+/* CPPI data structure definitions */
+
+/**
+ *  CPPI  Buffer Descriptor
+ *
+ *   Buffer Descriptor structure for USB OTG Module CPPI.Using the same across Tx/Rx
+ */
+
+#define	CPPI_DESCRIPTOR_ALIGN	16	// bytes; 5-dec docs say 4-byte align
+
+struct cppi_descriptor {
+	/* Hardware Overlay */
+	u32 hNext;     /**< Next(hardware) Buffer Descriptor Pointer */
+	u32 buffPtr;	   /**<Buffer Pointer (dma_addr_t) */
+	u32 bOffBLen;	    /**<Buffer_offset16,buffer_length16 */
+	u32 hOptions;	    /**<Option fields for SOP,EOP etc*/
+
+	struct cppi_descriptor *next; /**<Next(software) Buffer Descriptor pointer*/
+	dma_addr_t dma;		/* address of this descriptor */
+
+	/* for Rx Desc, keep track of enqueued Buffer len to detect short packets */
+	u32 enqBuffLen;
+} __attribute__ ((aligned(CPPI_DESCRIPTOR_ALIGN)));
+
+
+/* forward declaration for CppiDmaController structure */
+struct cppi;
+
+/**
+ *  Channel Control Structure
+ *
+ * CPPI  Channel Control structure. Using he same for Tx/Rx. If need be
+ * derive out of this later.
+ */
+struct cppi_channel {
+	/* First field must be dma_channel for easy type casting
+	 * FIXME just use container_of() and be typesafe instead!
+	 */
+	struct dma_channel Channel;
+
+	/* back pointer to the Dma Controller structure */
+	struct cppi		*pController;
+
+	/* which direction of which endpoint? */
+	struct musb_hw_ep	*pEndPt;
+	u8			bTransmit;
+	u8			chNo;
+
+	/* DMA modes:  RNDIS or "transparent" */
+	u8			bLastModeRndis;
+
+	/* Rx Requested mode */
+	u8 			rxMode;
+
+	/* book keeping for current transfer request */
+	dma_addr_t		startAddr;
+	u32			transferSize;
+	u32			pktSize;
+	u32			currOffset;	/* requested segments */
+	u32			actualLen;	/* completed (Channel.actual) */
+
+	void __iomem 		*stateRam;	/* CPPI state */
+
+	/* BD management fields */
+	struct cppi_descriptor	*bdPoolHead;		/* Free BD Pool head pointer */
+	struct cppi_descriptor	*activeQueueHead;
+	struct cppi_descriptor	*activeQueueTail;
+	struct cppi_descriptor	*lastHwBDProcessed;
+
+	/* use tx_complete in host role to track endpoints waiting for
+	 * FIFONOTEMPTY to clear.
+	 */
+	struct list_head	tx_complete;
+};
+
+/**
+ *  CPPI Dma Controller Object
+ *
+ *  CPPI Dma controller object.Encapsulates all bookeeping and Data
+ *  structures pertaining to the CPPI Dma Controller.
+ */
+struct cppi {
+	/* FIXME switchover to container_of() and remove the
+	 * unsafe typecasts...
+	 */
+	struct dma_controller		Controller;
+	struct musb	 		*musb;
+	void __iomem			*pCoreBase;
+
+	MGC_pfDmaChannelStatusChanged	dma_completed;
+
+	struct cppi_channel		txCppi[MUSB_C_NUM_EPT - 1];
+	struct cppi_channel		rxCppi[MUSB_C_NUM_EPR - 1];
+
+	struct dma_pool			*pool;
+
+	struct list_head		tx_complete;
+};
+
+/* irq handling hook */
+extern void cppi_completion(struct musb *, u32 rx, u32 tx);
+
+#endif				/* end of ifndef _CPPI_DMA_H_ */
Index: linux-2.6.10/drivers/usb/musb/davinci.c
===================================================================
--- /dev/null
+++ linux-2.6.10/drivers/usb/musb/davinci.c
@@ -0,0 +1,351 @@
+/*
+ * Copyright (C) 2005-2006 by Texas Instruments
+ *
+ * This file is part of the Inventra Controller Driver for Linux.
+ *
+ * The Inventra Controller Driver for Linux is free software; you
+ * can redistribute it and/or modify it under the terms of the GNU
+ * General Public License version 2 as published by the Free Software
+ * Foundation.
+ *
+ * The Inventra Controller Driver for Linux is distributed in
+ * the hope that it will be useful, but WITHOUT ANY WARRANTY;
+ * without even the implied warranty of MERCHANTABILITY or
+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public
+ * License for more details.
+ *
+ * You should have received a copy of the GNU General Public License
+ * along with The Inventra Controller Driver for Linux ; if not,
+ * write to the Free Software Foundation, Inc., 59 Temple Place,
+ * Suite 330, Boston, MA  02111-1307  USA
+ *
+ */
+
+#include <linux/config.h>
+#include <linux/module.h>
+#include <linux/pci.h>
+#include <linux/kernel.h>
+#include <linux/sched.h>
+#include <linux/slab.h>
+#include <linux/init.h>
+#include <linux/list.h>
+// #include <linux/clk.h>
+#include <asm/hardware/clock.h>
+
+#include <asm/io.h>
+#include <asm/arch/hardware.h>
+#include <asm/arch/memory.h>
+#include <asm/mach-types.h>
+
+// #ifdef CONFIG_USB_MUSB_HDRC_HCD
+#include <linux/usb.h>
+#include "../core/hcd.h"
+// #endif
+
+#include "musbdefs.h"
+// #ifdef CONFIG_USB_MUSB_HDRC_HCD
+#include "musb_host.h"
+// #endif
+
+
+#ifdef CONFIG_ARCH_DAVINCI
+
+#ifdef CONFIG_MACH_DAVINCI_EVM
+#include <asm/arch/i2c-client.h>
+#endif
+
+#include "davinci.h"
+#endif
+
+#ifdef CONFIG_USB_TI_CPPI_DMA
+#include "cppi_dma.h"
+#endif
+
+
+static inline void phy_on(void)
+{
+	/* start the on-chip PHY and its PLL */
+	__raw_writel(USBPHY_SESNDEN | USBPHY_VBDTCTEN | USBPHY_PHYPLLON,
+			IO_ADDRESS(USBPHY_CTL_PADDR));
+	while ((__raw_readl(IO_ADDRESS(USBPHY_CTL_PADDR))
+			& USBPHY_PHYCLKGD) == 0)
+		cpu_relax();
+}
+
+static inline void phy_off(void)
+{
+	/* powerdown the on-chip PHY and its oscillator */
+	__raw_writel(USBPHY_OSCPDWN | USBPHY_PHYSPDWN,
+			IO_ADDRESS(USBPHY_CTL_PADDR));
+}
+
+
+void musb_platform_enable(struct musb *musb)
+{
+	u32	tmp, old, val;
+
+	/* workaround:  setup irqs through both register sets */
+	tmp = (musb->wEndMask & DAVINCI_USB_TX_ENDPTS_MASK)
+			<< DAVINCI_USB_TXINT_SHIFT;
+	musb_writel(musb->ctrl_base, DAVINCI_USB_INT_MASK_SET_REG, tmp);
+	old = tmp;
+	tmp = (musb->wEndMask & (0xfffe & DAVINCI_USB_RX_ENDPTS_MASK))
+			<< DAVINCI_USB_RXINT_SHIFT;
+	musb_writel(musb->ctrl_base, DAVINCI_USB_INT_MASK_SET_REG, tmp);
+	tmp |= old;
+
+	val = ~MGC_M_INTR_SOF;
+	tmp |= ((val & 0x01ff) << DAVINCI_USB_USBINT_SHIFT);
+	musb_writel(musb->ctrl_base, DAVINCI_USB_INT_MASK_SET_REG, tmp);
+}
+
+/*
+ * Disable the HDRC and flush interrupts
+ */
+void musb_platform_disable(struct musb *musb)
+{
+	/* because we don't set CTRLR.UINT, "important" to:
+	 *  - not read/write INTRUSB/INTRUSBE
+	 *  - (except during initial setup, as workaround)
+	 *  - use INTSETR/INTCLRR instead
+	 */
+	musb_writel(musb->ctrl_base, DAVINCI_USB_INT_MASK_CLR_REG,
+			  DAVINCI_USB_USBINT_MASK
+			| DAVINCI_USB_TXINT_MASK
+			| DAVINCI_USB_RXINT_MASK);
+	musb_writeb(musb->pRegs, MGC_O_HDRC_DEVCTL, 0);
+	musb_writel(musb->ctrl_base, DAVINCI_USB_EOI_REG, 0);
+}
+
+
+/* REVISIT this file shouldn't modify the OTG state machine ...
+ *
+ * The OTG infrastructure needs updating, to include things like
+ * offchip DRVVBUS support and replacing MGC_OtgMachineInputs with
+ * musb struct members (so e.g. vbus_state vanishes).
+ */
+static int vbus_state = -1;
+
+static void session(struct musb *musb, int is_on)
+{
+	void	*__iomem mregs = musb->pRegs;
+	u8	devctl = musb_readb(mregs, MGC_O_HDRC_DEVCTL);
+
+	/* NOTE: after drvvbus off the state _could_ be A_IDLE;
+	 * but the silicon seems to couple vbus to "ID grounded".
+	 */
+	devctl |= MGC_M_DEVCTL_SESSION;
+	if (is_on)
+		musb->xceiv.state = OTG_STATE_A_WAIT_BCON;
+	else
+		musb->xceiv.state = OTG_STATE_B_IDLE;
+	musb_writeb(mregs, MGC_O_HDRC_DEVCTL, devctl);
+}
+
+
+/* VBUS SWITCHING IS BOARD-SPECIFIC */
+
+#ifdef CONFIG_MACH_DAVINCI_EVM
+
+/* I2C operations are always synchronous, and require a task context.
+ * With unloaded systems, using the shared workqueue seems to suffice
+ * to satisfy the 100msec A_WAIT_VRISE timeout...
+ */
+static void evm_deferred_drvvbus(void *_musb)
+{
+	struct musb	*musb = _musb;
+	int		is_on = (musb->xceiv.state == OTG_STATE_A_WAIT_VRISE);
+
+	davinci_i2c_expander_op(0x3a, USB_DRVVBUS, !is_on);
+	vbus_state = is_on;
+	session(musb, is_on);
+}
+DECLARE_WORK(evm_vbus_work, evm_deferred_drvvbus, 0);
+
+#endif
+
+static void davinci_vbus_power(struct musb *musb, int is_on, int sleeping)
+{
+	if (is_on)
+		is_on = 1;
+
+	if (vbus_state == is_on)
+		return;
+
+	if (is_on) {
+		musb->xceiv.state = OTG_STATE_A_WAIT_VRISE;
+		MUSB_HST_MODE(musb);
+	} else {
+		switch (musb->xceiv.state) {
+		case OTG_STATE_UNDEFINED:
+		case OTG_STATE_B_IDLE:
+			MUSB_DEV_MODE(musb);
+			musb->xceiv.state = OTG_STATE_B_IDLE;
+			break;
+		case OTG_STATE_A_IDLE:
+			break;
+		default:
+			musb->xceiv.state = OTG_STATE_A_WAIT_VFALL;
+			break;
+		}
+	}
+
+#ifdef CONFIG_MACH_DAVINCI_EVM
+	if (machine_is_davinci_evm()) {
+#ifdef CONFIG_MACH_DAVINCI_EVM_OTG
+		/* modified EVM board switching VBUS with GPIO(6) not I2C
+		 * NOTE:  PINMUX0.RGB888 (bit23) must be clear
+		 */
+		if (is_on)
+			gpio_set(GPIO(6));
+		else
+			gpio_clear(GPIO(6));
+#else
+#if 0
+		/* Do not turn off the USB bus.  This results in the IDE HDD
+		 * getting reset.
+		 */
+		if (sleeping)
+			davinci_i2c_expander_op(0x3a, USB_DRVVBUS, !is_on);
+		else
+			schedule_work(&evm_vbus_work);
+#endif
+		if (!sleeping)
+			schedule_work(&evm_vbus_work);
+
+#endif
+	}
+#endif
+	if (sleeping) {
+		vbus_state = is_on;
+		session(musb, is_on);
+	}
+
+	DBG(2, "VBUS power %s, %s\n", is_on ? "on" : "off",
+		sleeping ? "immediate" : "deferred");
+}
+
+static irqreturn_t davinci_interrupt(int irq, void *__hci, struct pt_regs *r)
+{
+	unsigned long	flags;
+	irqreturn_t	retval = IRQ_NONE;
+	struct musb	*musb = __hci;
+	void		*__iomem tibase = musb->ctrl_base;
+	u32		tmp;
+
+	spin_lock_irqsave(&musb->Lock, flags);
+
+#ifdef CONFIG_USB_TI_CPPI_DMA
+	/* CPPI interrupts share the same IRQ line, but have their own
+	 * mask, state, and EIO registers.
+	 */
+	{
+		u32 cppi_tx = musb_readl(tibase, DAVINCI_TXCPPI_MASKED_REG);
+		u32 cppi_rx = musb_readl(tibase, DAVINCI_RXCPPI_MASKED_REG);
+
+		if (cppi_tx || cppi_rx) {
+			DBG(4, "<== CPPI IRQ t%x r%x\n", cppi_tx, cppi_rx);
+			cppi_completion(musb, cppi_rx, cppi_tx);
+			retval = IRQ_HANDLED;
+		}
+	}
+#endif
+
+	/* NOTE: DaVinci shadows the Mentor IRQs; don't manage them through
+	 * the mentor registers (except for setup), use the TI ones and EOI.
+	 */
+
+	/* ack and handle non-CPPI interrupts */
+	tmp = musb_readl(tibase, DAVINCI_USB_INT_SRC_MASKED_REG);
+	musb_writel(tibase, DAVINCI_USB_INT_SRC_CLR_REG, tmp);
+
+	musb->int_rx = (tmp & DAVINCI_USB_RXINT_MASK)
+			>> DAVINCI_USB_RXINT_SHIFT;
+	musb->int_tx = (tmp & DAVINCI_USB_TXINT_MASK)
+			>> DAVINCI_USB_TXINT_SHIFT;
+	musb->int_usb = (tmp & DAVINCI_USB_USBINT_MASK)
+			>> DAVINCI_USB_USBINT_SHIFT;
+	musb->int_regs = r;
+
+	if (tmp & (1 << (8 + DAVINCI_USB_USBINT_SHIFT))) {
+		int	drvvbus = musb_readl(tibase, DAVINCI_USB_STAT_REG);
+
+		/* NOTE:  this must complete poweron within 100 msec */
+		davinci_vbus_power(musb, drvvbus, 0);
+		DBG(2, "DRVVBUS %d (state %d)\n", drvvbus, musb->xceiv.state);
+		retval = IRQ_HANDLED;
+	}
+
+	if (musb->int_tx || musb->int_rx || musb->int_usb)
+		retval |= musb_interrupt(musb);
+
+	/* irq stays asserted until EOI is written */
+	musb_writel(tibase, DAVINCI_USB_EOI_REG, 0);
+
+	spin_unlock_irqrestore(&musb->Lock, flags);
+
+	/* REVISIT we sometimes get unhandled IRQs with CPPI
+	 * (minimally, host TX).  not clear why...
+	 */
+	if (retval != IRQ_HANDLED)
+		DBG(5, "unhandled? %08x\n", tmp);
+	return IRQ_HANDLED;
+}
+
+int __init musb_platform_init(struct musb *musb)
+{
+	void	*__iomem tibase = musb->ctrl_base;
+	u32	revision;
+
+	musb->pRegs += DAVINCI_BASE_OFFSET;
+#if 0
+	/* REVISIT there's something odd about clocking, this
+	 * didn't appear do the job ...
+	 */
+	musb->clock = clk_get(pDevice, "usb");
+	if (IS_ERR(musb->clock))
+		return PTR_ERR(musb->clock);
+
+	status = clk_enable(musb->clock);
+	if (status < 0)
+		return -ENODEV;
+#endif
+
+	 /* returns zero if e.g. not clocked */
+	 revision = musb_readl(tibase, DAVINCI_USB_VERSION_REG);
+	 if (revision == 0)
+	 	return -ENODEV;
+
+	/* note that transceiver issues make us want to charge
+	 * VBUS only when the PHY PLL is not active.
+	 */
+#ifdef CONFIG_MACH_DAVINCI_EVM
+	evm_vbus_work.data = musb;
+#endif
+	davinci_vbus_power(musb, musb->board_mode == MUSB_HOST, 1);
+
+	/* reset the controller */
+	musb_writel(tibase, DAVINCI_USB_CTRL_REG, 0x1);
+
+	/* start the on-chip PHY and its PLL */
+	phy_on();
+
+	msleep(5);
+
+	/* NOTE:  irqs are in mixed mode, not bypass to pure-musb */
+	pr_debug("DaVinci OTG revision %08x phy %03x control %02x\n",
+		 revision,
+		 musb_readl((void *__iomem) IO_ADDRESS(
+				 USBPHY_CTL_PADDR), 0x00),
+		 musb_readb(tibase, DAVINCI_USB_CTRL_REG));
+
+	musb->isr = davinci_interrupt;
+	return 0;
+}
+
+int musb_platform_exit(struct musb *musb)
+{
+	phy_off();
+	davinci_vbus_power(musb, 0 /*off*/, 1);
+	return 0;
+}
Index: linux-2.6.10/drivers/usb/musb/davinci.h
===================================================================
--- /dev/null
+++ linux-2.6.10/drivers/usb/musb/davinci.h
@@ -0,0 +1,119 @@
+/*
+ * Copyright (C) 2005-2006 by Texas Instruments
+ *
+ * The Inventra Controller Driver for Linux is free software; you
+ * can redistribute it and/or modify it under the terms of the GNU
+ * General Public License version 2 as published by the Free Software
+ * Foundation.
+ */
+
+#ifndef __MUSB_HDRDF_H__
+#define __MUSB_HDRDF_H__
+
+/*
+ * DaVinci-specific definitions
+ */
+
+/* Integrated highspeed/otg PHY */
+#define	USBPHY_CTL_PADDR	(DAVINCI_SYSTEM_MODULE_BASE + 0x34)
+#define	USBPHY_PHYCLKGD		(1 << 8)
+#define	USBPHY_SESNDEN		(1 << 7)	/* v(sess_end) comparator */
+#define	USBPHY_VBDTCTEN		(1 << 6)	/* v(bus) comparator */
+#define	USBPHY_PHYPLLON		(1 << 4)	/* override pll suspend */
+#define	USBPHY_CLK01SEL		(1 << 3)
+#define	USBPHY_OSCPDWN		(1 << 2)
+#define	USBPHY_PHYSPDWN		(1 << 0)
+
+/* For now include usb OTG module registers here */
+#define DAVINCI_USB_VERSION_REG		0x00
+#define DAVINCI_USB_CTRL_REG		0x04
+#define DAVINCI_USB_STAT_REG		0x08
+#define DAVINCI_RNDIS_REG		0x10
+#define DAVINCI_AUTOREQ_REG		0x14
+#define DAVINCI_USB_INT_SOURCE_REG	0x20
+#define DAVINCI_USB_INT_SET_REG		0x24
+#define DAVINCI_USB_INT_SRC_CLR_REG	0x28
+#define DAVINCI_USB_INT_MASK_REG	0x2c
+#define DAVINCI_USB_INT_MASK_SET_REG	0x30
+#define DAVINCI_USB_INT_MASK_CLR_REG	0x34
+#define DAVINCI_USB_INT_SRC_MASKED_REG	0x38
+#define DAVINCI_USB_EOI_REG		0x3c
+#define DAVINCI_USB_EOI_INTVEC		0x40
+
+/* CPPI related registers */
+#define DAVINCI_TXCPPI_CTRL_REG		0x80
+#define DAVINCI_TXCPPI_TEAR_REG		0x84
+#define DAVINCI_CPPI_EOI_REG		0x88
+#define DAVINCI_CPPI_INTVEC_REG		0x8c
+#define DAVINCI_TXCPPI_MASKED_REG	0x90
+#define DAVINCI_TXCPPI_RAW_REG		0x94
+#define DAVINCI_TXCPPI_INTENAB_REG	0x98
+#define DAVINCI_TXCPPI_INTCLR_REG	0x9c
+
+#define DAVINCI_RXCPPI_CTRL_REG		0xC0
+#define DAVINCI_RXCPPI_MASKED_REG	0xD0
+#define DAVINCI_RXCPPI_RAW_REG		0xD4
+#define DAVINCI_RXCPPI_INTENAB_REG	0xD8
+#define DAVINCI_RXCPPI_INTCLR_REG	0xDC
+
+#define DAVINCI_RXCPPI_BUFCNT0_REG	0xE0
+#define DAVINCI_RXCPPI_BUFCNT1_REG	0xE4
+#define DAVINCI_RXCPPI_BUFCNT2_REG	0xE8
+#define DAVINCI_RXCPPI_BUFCNT3_REG	0xEC
+
+/* CPPI state RAM entries */
+#define DAVINCI_CPPI_STATERAM_BASE_OFFSET   0x100
+
+#define DAVINCI_TXCPPI_STATERAM_OFFSET(channelNum) \
+	(DAVINCI_CPPI_STATERAM_BASE_OFFSET +       ((channelNum)* 0x40))
+#define DAVINCI_RXCPPI_STATERAM_OFFSET(channelNum) \
+	(DAVINCI_CPPI_STATERAM_BASE_OFFSET + 0x20 +((channelNum)* 0x40))
+
+/* CPPI masks */
+#define DAVINCI_DMA_CTRL_ENABLE		1
+#define DAVINCI_DMA_CTRL_DISABLE	0
+
+#define DAVINCI_DMA_ALL_CHANNELS_ENABLE	0xF
+#define DAVINCI_DMA_ALL_CHANNELS_DISABLE 0xF
+
+/* REVISIT relying on "volatile" here is wrong ... */
+
+/* define structures of Rx/Tx stateRam entries */
+struct cppi_tx_stateram {
+	volatile u32 headPtr;
+	volatile u32 sopDescPtr;
+	volatile u32 currDescPtr;
+	volatile u32 currBuffPtr;
+	volatile u32 flags;
+	volatile u32 remLength;
+	volatile u32 dummy;
+	volatile u32 completionPtr;
+};
+
+struct cppi_rx_stateram {
+	volatile u32 buffOffset;
+	volatile u32 headPtr;
+	volatile u32 sopDescPtr;
+	volatile u32 currDescPtr;
+	volatile u32 currBuffPtr;
+	volatile u32 pktLength;
+	volatile u32 byteCount;
+	volatile u32 completionPtr;
+};
+
+#define DAVINCI_USB_TX_ENDPTS_MASK	0x1f		/* ep0 + 4 tx */
+#define DAVINCI_USB_RX_ENDPTS_MASK	0x1e		/* 4 rx */
+
+#define DAVINCI_USB_USBINT_SHIFT	16
+#define DAVINCI_USB_TXINT_SHIFT		0
+#define DAVINCI_USB_RXINT_SHIFT		8
+
+#define DAVINCI_USB_USBINT_MASK		0x01ff0000	/* 8 Mentor, DRVVBUS */
+#define DAVINCI_USB_TXINT_MASK \
+	(DAVINCI_USB_TX_ENDPTS_MASK << DAVINCI_USB_TXINT_SHIFT)
+#define DAVINCI_USB_RXINT_MASK \
+	(DAVINCI_USB_RX_ENDPTS_MASK << DAVINCI_USB_RXINT_SHIFT)
+
+#define DAVINCI_BASE_OFFSET		0x400
+
+#endif	/* __MUSB_HDRDF_H__ */
Index: linux-2.6.10/drivers/usb/musb/debug.h
===================================================================
--- /dev/null
+++ linux-2.6.10/drivers/usb/musb/debug.h
@@ -0,0 +1,80 @@
+/******************************************************************
+ * Copyright 2005 Mentor Graphics Corporation
+ * Copyright (C) 2005-2006 by Texas Instruments
+ *
+ * This file is part of the Inventra Controller Driver for Linux.
+ *
+ * The Inventra Controller Driver for Linux is free software; you
+ * can redistribute it and/or modify it under the terms of the GNU
+ * General Public License version 2 as published by the Free Software
+ * Foundation.
+ *
+ * The Inventra Controller Driver for Linux is distributed in
+ * the hope that it will be useful, but WITHOUT ANY WARRANTY;
+ * without even the implied warranty of MERCHANTABILITY or
+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public
+ * License for more details.
+ *
+ * You should have received a copy of the GNU General Public License
+ * along with The Inventra Controller Driver for Linux ; if not,
+ * write to the Free Software Foundation, Inc., 59 Temple Place,
+ * Suite 330, Boston, MA  02111-1307  USA
+ *
+ * ANY DOWNLOAD, USE, REPRODUCTION, MODIFICATION OR DISTRIBUTION
+ * OF THIS DRIVER INDICATES YOUR COMPLETE AND UNCONDITIONAL ACCEPTANCE
+ * OF THOSE TERMS.THIS DRIVER IS PROVIDED "AS IS" AND MENTOR GRAPHICS
+ * MAKES NO WARRANTIES, EXPRESS OR IMPLIED, RELATED TO THIS DRIVER.
+ * MENTOR GRAPHICS SPECIFICALLY DISCLAIMS ALL IMPLIED WARRANTIES
+ * OF MERCHANTABILITY; FITNESS FOR A PARTICULAR PURPOSE AND
+ * NON-INFRINGEMENT.  MENTOR GRAPHICS DOES NOT PROVIDE SUPPORT
+ * SERVICES OR UPDATES FOR THIS DRIVER, EVEN IF YOU ARE A MENTOR
+ * GRAPHICS SUPPORT CUSTOMER.
+ ******************************************************************/
+
+#ifndef __MUSB_LINUX_DEBUG_H__
+#define __MUSB_LINUX_DEBUG_H__
+
+/*
+ * Linux HCD (Host Controller Driver) for HDRC and/or MHDRC.
+ * Debug support routines
+ */
+
+#define yprintk(facility, format, args...) do { printk(facility "%s %d: " format , \
+	__FUNCTION__, __LINE__ , ## args); } while (0)
+#define WARN(fmt, args...) yprintk(KERN_WARNING,fmt, ## args)
+#define INFO(fmt,args...) yprintk(KERN_INFO,fmt, ## args)
+#define ERR(fmt,args...) yprintk(KERN_ERR,fmt, ## args)
+
+#if MUSB_DEBUG > 0
+
+#define MGC_GetDebugLevel()	(MGC_DebugLevel)
+#define MGC_SetDebugLevel(n)	do { MGC_DebugLevel = (n); } while(0)
+
+#define xprintk(level, facility, format, args...) do { \
+	if ( _dbg_level(level) ) { \
+		printk(facility "%s %d: " format , \
+				__FUNCTION__, __LINE__ , ## args); \
+	} } while (0)
+
+extern unsigned MGC_DebugLevel;
+
+/* debug no defined */
+
+#else
+#define MGC_GetDebugLevel()	0
+#define MGC_SetDebugLevel(n)	do {} while(0)
+
+#define MGC_DebugLevel		0
+
+#define xprintk(level, facility, format, args...) do {} while(0)
+
+#endif
+
+static inline int _dbg_level(unsigned l)
+{
+	return MGC_DebugLevel >= l;
+}
+
+#define DBG(level,fmt,args...) xprintk(level,KERN_DEBUG,fmt, ## args)
+
+#endif				//  __MUSB_LINUX_DEBUG_H__
Index: linux-2.6.10/drivers/usb/musb/dma.h
===================================================================
--- /dev/null
+++ linux-2.6.10/drivers/usb/musb/dma.h
@@ -0,0 +1,292 @@
+/******************************************************************
+ * Copyright 2005 Mentor Graphics Corporation
+ * Copyright (C) 2005-2006 by Texas Instruments
+ *
+ * This file is part of the Inventra Controller Driver for Linux.
+ *
+ * The Inventra Controller Driver for Linux is free software; you
+ * can redistribute it and/or modify it under the terms of the GNU
+ * General Public License version 2 as published by the Free Software
+ * Foundation.
+ *
+ * The Inventra Controller Driver for Linux is distributed in
+ * the hope that it will be useful, but WITHOUT ANY WARRANTY;
+ * without even the implied warranty of MERCHANTABILITY or
+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public
+ * License for more details.
+ *
+ * You should have received a copy of the GNU General Public License
+ * along with The Inventra Controller Driver for Linux ; if not,
+ * write to the Free Software Foundation, Inc., 59 Temple Place,
+ * Suite 330, Boston, MA  02111-1307  USA
+ *
+ * ANY DOWNLOAD, USE, REPRODUCTION, MODIFICATION OR DISTRIBUTION
+ * OF THIS DRIVER INDICATES YOUR COMPLETE AND UNCONDITIONAL ACCEPTANCE
+ * OF THOSE TERMS.THIS DRIVER IS PROVIDED "AS IS" AND MENTOR GRAPHICS
+ * MAKES NO WARRANTIES, EXPRESS OR IMPLIED, RELATED TO THIS DRIVER.
+ * MENTOR GRAPHICS SPECIFICALLY DISCLAIMS ALL IMPLIED WARRANTIES
+ * OF MERCHANTABILITY; FITNESS FOR A PARTICULAR PURPOSE AND
+ * NON-INFRINGEMENT.  MENTOR GRAPHICS DOES NOT PROVIDE SUPPORT
+ * SERVICES OR UPDATES FOR THIS DRIVER, EVEN IF YOU ARE A MENTOR
+ * GRAPHICS SUPPORT CUSTOMER.
+ ******************************************************************/
+
+/*
+ * DMA Controller Abstraction (DCA) for the Inventra Controller Driver (ICD).
+ */
+
+#ifndef __MUSB_DMA_H__
+#define __MUSB_DMA_H__
+
+/**
+ * Introduction.
+ * The purpose of the DMA Controller Abstraction (DCA) is to allow the ICD
+ * to use any DMA controller,
+ * since this is an option in the Inventra USB cores.
+ * The assumptions are:
+ *
+ * <li>A DMA controller will be tied to an Inventra USB core in the
+ * way specified in the Inventra core product specification.
+ * <li>A DMA controller's base address in the memory map correlates
+ * somehow to the Inventra USB core it serves.
+ * <li>Linux sets up the DMA mappings and flushes caches, so the
+ * controller doesn't need to.
+ *
+ * The responsibilities of an implementation include:
+ *
+ * <li>Handling the details of moving multiple USB packets
+ * in cooperation with the Inventra USB core.
+ * <li>Knowing the correlation between channels and the
+ * Inventra core's local endpoint resources and data direction,
+ * and maintaining a list of allocated/available channels.
+ * <li>Updating channel status on interrupts,
+ * whether shared with the Inventra core or separate.
+ * <li>If the DMA interrupt is shared with the Inventra core,
+ * handling it when called, and reporting whether it was the
+ * source of interrupt.
+ *
+ */
+
+#define	DMA_ADDR_INVALID	(~(dma_addr_t)0)
+
+#ifndef CONFIG_USB_INVENTRA_FIFO
+#define	is_dma_capable()	(1)
+#else
+#define	is_dma_capable()	(0)
+#endif
+
+/*************************** CONSTANTS ****************************/
+
+/**
+ * DMA channel status ... updated by the dma controller driver whenever that
+ * status changes, and protected by the overall controller spinlock.
+ */
+enum dma_channel_status {
+    /** A channel's status is unknown */
+	MGC_DMA_STATUS_UNKNOWN,
+    /** A channel is available (not busy and no errors) */
+	MGC_DMA_STATUS_FREE,
+    /** A channel is busy (not finished attempting its transactions) */
+	MGC_DMA_STATUS_BUSY,
+    /** A channel aborted its transactions due to a local bus error */
+	MGC_DMA_STATUS_BUS_ABORT,
+    /** A channel aborted its transactions due to a core error or USB fault */
+	MGC_DMA_STATUS_CORE_ABORT
+};
+
+/***************************** TYPES ******************************/
+
+/**
+ * struct dma_channel - A DMA channel.
+ * @field pPrivateData channel-private data; not to be interpreted by the ICD
+ * @field wMaxLength the maximum number of bytes the channel can move
+ * in one transaction (typically representing many USB maximum-sized packets)
+ * @field dwActualLength how many bytes have been transferred
+ * @field bStatus current channel status (updated e.g. on interrupt)
+ * @field bDesiredMode TRUE if mode 1 is desired; FALSE if mode 0 is desired
+ */
+struct dma_channel {
+	void			*pPrivateData;
+	size_t			dwMaxLength;
+	size_t			dwActualLength;
+	enum dma_channel_status	bStatus;
+	u8			bDesiredMode;
+};
+
+/**
+ * Start a DMA controller.
+ * @param pPrivateData private data pointer from MGC_DmaController
+ * @return TRUE on success
+ * @return FALSE on failure (e.g. no DMAC appears present)
+ */
+typedef u8(*MGC_pfDmaStartController) (void *pPrivateData);
+
+/**
+ * Stop a DMA controller.
+ * @param pPrivateData the controller's private data pointer
+ * @return TRUE on success
+ * @return FALSE on failure; the ICD may try again
+ */
+typedef u8(*MGC_pfDmaStopController) (void *pPrivateData);
+
+/**
+ * Allocate a DMA channel.
+ * Allocate a DMA channel suitable for the given conditions.
+ * @param pPrivateData the controller's private data pointer
+ * @param bLocalEnd the local endpoint index (1-15)
+ * @param bTransmit TRUE for transmit; FALSE for receive
+ * @param bProtocol the USB protocol, as per USB 2.0 chapter 9
+ * (0 => control, 1 => isochronous, 2 => bulk, 3 => interrupt)
+ * @param wMaxPacketSize maximum packet size
+ * @return a non-NULL pointer on success
+ * @return NULL on failure (no channel available)
+ */
+typedef struct dma_channel *(*MGC_pfDmaAllocateChannel) (void *pPrivateData,
+						     u8 bLocalEnd, u8 bTransmit,
+						     u8 bProtocol,
+						     u16 wMaxPacketSize);
+
+/**
+ * Release a DMA channel.
+ * Release a previously-allocated DMA channel.
+ * The ICD guarantess to no longer reference this channel.
+ * @param pChannel pointer to a channel obtained by
+ * a successful call to pController->pfDmaAllocateChannel
+ */
+typedef void (*MGC_pfDmaReleaseChannel) (struct dma_channel *pChannel);
+
+/**
+ * Program a DMA channel.
+ * Program a DMA channel to move data at the core's request.
+ * The local core endpoint and direction should already be known,
+ * since they are specified in the pfDmaAllocateChannel call.
+ * @param pChannel pointer to a channel obtained by
+ * a successful call to pController->pfDmaAllocateChannel
+ * @param wPacketSize the packet size
+ * @param bMode TRUE if mode 1; FALSE if mode 0
+ * @param dma_addr base address of data (in DMA space)
+ * @param dwLength the number of bytes to transfer;
+ * guaranteed by the ICD to be no larger than the channel's reported dwMaxLength
+ * @return TRUE on success
+ * @return FALSE on error
+ */
+typedef u8(*MGC_pfDmaProgramChannel) (struct dma_channel *pChannel,
+				      u16 wPacketSize, u8 bMode,
+				      // const u8* pBuffer,
+				      dma_addr_t dma_addr, u32 dwLength);
+
+/**
+ * dma_channel_status - return status of dma channel
+ * @c: the channel
+ *
+ * Returns the software's view of the channel status.  If that status is BUSY
+ * then it's possible that the hardware has completed (or aborted) a transfer,
+ * so the driver needs to update that status.
+ */
+static inline enum dma_channel_status
+dma_channel_status(struct dma_channel *c)
+{
+	return (is_dma_capable() && c) ? c->bStatus : MGC_DMA_STATUS_UNKNOWN;
+}
+
+/**
+ * DMA ISR.
+ * If present, this function is called by the ICD on every interrupt.
+ * This is necessary because with the built-in DMA controller
+ * (and probably some other configurations),
+ * the DMA interrupt is shared with other core interrupts.
+ * Therefore, this function should return quickly
+ * when there is no DMA interrupt.
+ * When there is a DMA interrupt, this function should
+ * perform any implementations-specific operations,
+ * and update the status of all appropriate channels.
+ * If the DMA controller has its own dedicated interrupt,
+ * this function should do nothing.
+ * This function is called BEFORE the ICD handles other interrupts.
+ * @param pPrivateData the controller's private data pointer
+ * @return TRUE if an interrupt was serviced
+ * @return FALSE if no interrupt required servicing
+ */
+typedef u8(*MGC_pfDmaControllerIsr) (void *pPrivateData);
+
+/**
+ * struct dma_controller - A DMA Controller.
+ * This is in a struct to allow the ICD to support
+ * multiple cores of different types,
+ * since each may use a different type of DMA controller.
+ * @field pPrivateData controller-private data;
+ * not to be interpreted by the ICD
+ * @field pfDmaStartController ICD calls this to start a DMA controller
+ * @field pfDmaStopController ICD calls this to stop a DMA controller
+ * @field pfDmaAllocateChannel ICD calls this to allocate a DMA channel
+ * @field pfDmaReleaseChannel ICD calls this to release a DMA channel
+ * @field pfDmaControllerIsr ICD calls this (if non-NULL) from its ISR
+ */
+struct dma_controller {
+	void *pPrivateData;
+	MGC_pfDmaStartController pfDmaStartController;
+	MGC_pfDmaStopController pfDmaStopController;
+	MGC_pfDmaAllocateChannel pfDmaAllocateChannel;
+	MGC_pfDmaReleaseChannel pfDmaReleaseChannel;
+	MGC_pfDmaProgramChannel pfDmaProgramChannel;
+	int (*pfDmaAbortChannel)(struct dma_channel *);
+	MGC_pfDmaControllerIsr pfDmaControllerIsr;
+};
+
+/*
+ * A DMA channel has new status.
+ * This may be used to notify the ICD of channel status changes asynchronously.
+ * This is useful if the DMA interrupt is different from the USB controller's
+ * interrupt, so on some systems there may be no control over the order of
+ * USB controller and DMA controller assertion.
+ * @param pPrivateData the controller's private data pointer
+ * @param bLocalEnd the local endpoint index (1-15)
+ * @param bTransmit TRUE for transmit; FALSE for receive
+ * @return zero for success, else a negative errno fault code
+ */
+typedef int (*MGC_pfDmaChannelStatusChanged)(void *pPrivateData,
+		u8 bLocalEnd, u8 bTransmit);
+
+/**
+ * Instantiate a DMA controller.
+ * Instantiate a software object representing a DMA controller.
+ * @param pfDmaChannelStatusChanged channel status change notification function.
+ * Normally, the ICD requests status in its interrupt handler.
+ * For some DMA controllers, this may not be the correct time.
+ * @param pDmaPrivate parameter for pfDmaChannelStatusChanged
+ * @param pCoreBase the base address (in kernel space) of the core
+ * It is assumed the DMA controller's registers' base address will be related
+ * to this in some way.
+ * @return non-NULL pointer on success
+ * @return NULL on failure (out of memory or exhausted
+ * a fixed number of controllers)
+ */
+typedef struct dma_controller
+    *(*MGC_pfNewDmaController) (MGC_pfDmaChannelStatusChanged
+				pfDmaChannelStatusChanged, void *pDmaPrivate,
+				u8 *pCoreBase);
+
+/**
+ * Destroy DMA controller.
+ * Destroy a previously-instantiated DMA controller.
+ */
+typedef void (*MGC_pfDestroyDmaController) (struct dma_controller *pController);
+
+/**
+ * struct dma_controller_factory: DMA controller factory
+ * @pfNewDmaController: create a DMA controller
+ * @pfDestroyDmaController: destroy a DMA controller
+ *
+ * To allow for multi-core implementations and different
+ * types of cores and DMA controllers to co-exist,
+ * (only at the source level; no runtime coexistence supported)
+ * it is necessary to create them from factories.
+ */
+struct dma_controller_factory {
+	MGC_pfNewDmaController pfNewDmaController;
+	MGC_pfDestroyDmaController pfDestroyDmaController;
+};
+
+extern struct dma_controller_factory dma_controller_factory;
+
+#endif	/* __MUSB_DMA_H__ */
Index: linux-2.6.10/drivers/usb/musb/g_ep0.c
===================================================================
--- /dev/null
+++ linux-2.6.10/drivers/usb/musb/g_ep0.c
@@ -0,0 +1,969 @@
+/******************************************************************
+ * Copyright 2005 Mentor Graphics Corporation
+ * Copyright (C) 2005-2006 by Texas Instruments
+ *
+ * This file is part of the Inventra Controller Driver for Linux.
+ *
+ * The Inventra Controller Driver for Linux is free software; you
+ * can redistribute it and/or modify it under the terms of the GNU
+ * General Public License version 2 as published by the Free Software
+ * Foundation.
+ *
+ * The Inventra Controller Driver for Linux is distributed in
+ * the hope that it will be useful, but WITHOUT ANY WARRANTY;
+ * without even the implied warranty of MERCHANTABILITY or
+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public
+ * License for more details.
+ *
+ * You should have received a copy of the GNU General Public License
+ * along with The Inventra Controller Driver for Linux ; if not,
+ * write to the Free Software Foundation, Inc., 59 Temple Place,
+ * Suite 330, Boston, MA  02111-1307  USA
+ *
+ * ANY DOWNLOAD, USE, REPRODUCTION, MODIFICATION OR DISTRIBUTION
+ * OF THIS DRIVER INDICATES YOUR COMPLETE AND UNCONDITIONAL ACCEPTANCE
+ * OF THOSE TERMS.THIS DRIVER IS PROVIDED "AS IS" AND MENTOR GRAPHICS
+ * MAKES NO WARRANTIES, EXPRESS OR IMPLIED, RELATED TO THIS DRIVER.
+ * MENTOR GRAPHICS SPECIFICALLY DISCLAIMS ALL IMPLIED WARRANTIES
+ * OF MERCHANTABILITY; FITNESS FOR A PARTICULAR PURPOSE AND
+ * NON-INFRINGEMENT.  MENTOR GRAPHICS DOES NOT PROVIDE SUPPORT
+ * SERVICES OR UPDATES FOR THIS DRIVER, EVEN IF YOU ARE A MENTOR
+ * GRAPHICS SUPPORT CUSTOMER.
+ ******************************************************************/
+
+#include <linux/kernel.h>
+#include <linux/list.h>
+#include <linux/timer.h>
+#include <linux/spinlock.h>
+#include <linux/init.h>
+#include <linux/device.h>
+#include <linux/interrupt.h>
+
+#include "musbdefs.h"
+
+/* ep0 is always musb->aLocalEnd[0].ep_in */
+#define	next_ep0_request(musb)	next_in_request(&(musb)->aLocalEnd[0])
+
+/*
+ * Locking note:  we use only the controller lock, for simpler correctness.
+ * It's always held with IRQs blocked.
+ *
+ * It protects the ep0 request queue as well as ep0_state, not just the
+ * controller and indexed registers.  And that lock stays held unless it
+ * needs to be dropped to allow reentering this driver ... like upcalls to
+ * the gadget driver, or adjusting endpoint halt status.
+ */
+
+
+#ifdef	DEBUG
+static char *decode_ep0stage(u8 stage)
+{
+	switch(stage) {
+	case MGC_END0_STAGE_SETUP:	return "idle";
+	case MGC_END0_STAGE_TX:		return "in";
+	case MGC_END0_STAGE_RX:		return "out";
+	case MGC_END0_STAGE_ACKWAIT:	return "wait";
+	case MGC_END0_STAGE_STATUSIN:	return "in/status";
+	case MGC_END0_STAGE_STATUSOUT:	return "out/status";
+	default:			return "?";
+	}
+}
+#endif
+
+
+/* handle a standard GET_STATUS request
+ * Context:  caller holds controller lock
+ */
+static int service_tx_status_request(
+	struct musb *pThis,
+	const struct usb_ctrlrequest *pControlRequest)
+{
+	void __iomem	*pBase = pThis->pRegs;
+	int handled = 1;
+	u8 bResult[2], bEnd = 0;
+	const u8 bRecip = pControlRequest->bRequestType & USB_RECIP_MASK;
+
+	bResult[1] = 0;
+
+	switch (bRecip) {
+	case USB_RECIP_DEVICE:
+		bResult[0] = pThis->bIsSelfPowered << USB_DEVICE_SELF_POWERED;
+		bResult[0] |= pThis->bMayWakeup << USB_DEVICE_REMOTE_WAKEUP;
+#ifdef CONFIG_USB_MUSB_OTG
+		if (pThis->g.is_otg) {
+			bResult[0] |= pThis->g.b_hnp_enable
+			    << USB_DEVICE_B_HNP_ENABLE;
+			bResult[0] |= pThis->g.a_alt_hnp_support
+			    << USB_DEVICE_A_ALT_HNP_SUPPORT;
+			bResult[0] |= pThis->g.a_hnp_support
+			    << USB_DEVICE_A_HNP_SUPPORT;
+		}
+#endif
+		break;
+
+	case USB_RECIP_INTERFACE:
+		bResult[0] = 0;
+		break;
+
+	case USB_RECIP_ENDPOINT: {
+		int		is_in;
+		struct musb_ep	*ep;
+		u16		tmp;
+
+		bEnd = (u8) pControlRequest->wIndex;
+		if (!bEnd) {
+			bResult[0] = 0;
+			break;
+		}
+
+		is_in = bEnd & USB_DIR_IN;
+		if (is_in) {
+			bEnd &= 0x0f;
+			ep = &pThis->aLocalEnd[bEnd].ep_in;
+		} else {
+			ep = &pThis->aLocalEnd[bEnd].ep_out;
+		}
+
+		if (bEnd >= MUSB_C_NUM_EPS || !ep->desc) {
+			handled = -EINVAL;
+			break;
+		}
+
+		MGC_SelectEnd(pBase, bEnd);
+
+		if (is_in)
+			tmp = MGC_ReadCsr16(pBase, MGC_O_HDRC_TXCSR, bEnd)
+						& MGC_M_TXCSR_P_SENDSTALL;
+		else
+			tmp = MGC_ReadCsr16(pBase, MGC_O_HDRC_RXCSR, bEnd)
+						& MGC_M_RXCSR_P_SENDSTALL;
+
+		bResult[0] = tmp ? 1 : 0;
+		} break;
+
+	default:
+		/* class, vendor, etc ... delegate */
+		handled = 0;
+		break;
+	}
+
+	/* fill up the fifo; caller updates csr0 */
+	if (handled > 0) {
+		u16	len = le16_to_cpu(pControlRequest->wLength);
+
+		if (len > 2)
+			len = 2;
+		musb_write_fifo(&pThis->aLocalEnd[0], len, bResult);
+	}
+
+	return handled;
+}
+
+/*
+ * handle a control-IN request, the end0 buffer contains the current request
+ * that is supposed to be a standard control request. Assumes the fifo to
+ * be at least 2 bytes long.
+ *
+ * @return 0 if the request was NOT HANDLED,
+ * < 0 when error
+ * > 0 when the request is processed
+ *
+ * Context:  caller holds controller lock
+ */
+static int
+service_in_request(struct musb *pThis,
+		   const struct usb_ctrlrequest *pControlRequest)
+{
+	int handled = 0;	/* not handled */
+
+	if ((pControlRequest->bRequestType & USB_TYPE_MASK)
+			== USB_TYPE_STANDARD) {
+		switch (pControlRequest->bRequest) {
+		case USB_REQ_GET_STATUS:
+			handled = service_tx_status_request(pThis,
+					pControlRequest);
+			break;
+
+		/* case USB_REQ_SYNC_FRAME: */
+
+		default:
+			break;
+		}
+	}
+	return handled;
+}
+
+/*
+ * Context:  caller holds controller lock
+ */
+static void musb_g_ep0_giveback(struct musb *pThis, struct usb_request *req)
+{
+	pThis->ep0_state = MGC_END0_STAGE_SETUP;
+	musb_g_giveback(&pThis->aLocalEnd[0].ep_in, req, 0);
+}
+
+
+/* for high speed test mode; see USB 2.0 spec */
+static const u8 musb_test_packet[53] = {
+	0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,
+	0x00, 0xaa, 0xaa, 0xaa, 0xaa, 0xaa, 0xaa, 0xaa,
+	0xaa, 0xee, 0xee, 0xee, 0xee, 0xee, 0xee, 0xee,
+	0xee, 0xfe, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
+	0xff, 0xff, 0xff, 0xff, 0xff, 0x7f, 0xbf, 0xdf,
+	0xef, 0xf7, 0xfb, 0xfd, 0xfc, 0x7e, 0xbf, 0xdf,
+	0xef, 0xf7, 0xfb, 0xfd, 0x7e
+};
+
+/*
+ * Handle all control requests with no DATA stage, including standard
+ * requests such as:
+ * USB_REQ_SET_CONFIGURATION, USB_REQ_SET_INTERFACE, unrecognized
+ *	always delegated to the gadget driver
+ * USB_REQ_SET_ADDRESS, USB_REQ_CLEAR_FEATURE, USB_REQ_SET_FEATURE
+ *	always handled here, except for class/vendor/... features
+ *
+ * Context:  caller holds controller lock
+ */
+static int
+service_zero_data_request(struct musb *pThis,
+		struct usb_ctrlrequest *pControlRequest)
+__releases(pThis->Lock)
+__acquires(pThis->Lock)
+{
+	int handled = -EINVAL;
+	void __iomem *pBase = pThis->pRegs;
+	const u8 bRecip = pControlRequest->bRequestType & USB_RECIP_MASK;
+
+	/* the gadget driver handles everything except what we MUST handle */
+	if ((pControlRequest->bRequestType & USB_TYPE_MASK)
+			== USB_TYPE_STANDARD) {
+		switch (pControlRequest->bRequest) {
+		case USB_REQ_SET_ADDRESS:
+			/* change it after the status stage */
+			pThis->bSetAddress = TRUE;
+			pThis->bAddress = (u8) (pControlRequest->wValue & 0x7f);
+			handled = 1;
+			break;
+
+		case USB_REQ_CLEAR_FEATURE:
+			switch (bRecip) {
+			case USB_RECIP_DEVICE:
+				if (pControlRequest->wValue
+						!= USB_DEVICE_REMOTE_WAKEUP)
+					break;
+				pThis->bMayWakeup = 0;
+				handled = 1;
+				break;
+			case USB_RECIP_INTERFACE:
+				break;
+			case USB_RECIP_ENDPOINT:{
+				const u8 bEnd = pControlRequest->wIndex & 0x0f;
+				struct musb_ep *pEnd;
+
+				if (bEnd == 0
+						|| bEnd >= MUSB_C_NUM_EPS
+						|| pControlRequest->wValue
+							!= USB_ENDPOINT_HALT)
+					break;
+
+				if (pControlRequest->wIndex & USB_DIR_IN)
+					pEnd = &pThis->aLocalEnd[bEnd].ep_in;
+				else
+					pEnd = &pThis->aLocalEnd[bEnd].ep_out;
+				if (!pEnd->desc)
+					break;
+
+				/* REVISIT do it directly, no locking games */
+				spin_unlock(&pThis->Lock);
+				musb_gadget_set_halt(&pEnd->end_point, 0);
+				spin_lock(&pThis->Lock);
+
+				/* select ep0 again */
+				MGC_SelectEnd(pBase, 0);
+				handled = 1;
+				} break;
+			default:
+				/* class, vendor, etc ... delegate */
+				handled = 0;
+				break;
+			}
+			break;
+
+		case USB_REQ_SET_FEATURE:
+			switch (bRecip) {
+			case USB_RECIP_DEVICE:
+				handled = 1;
+				switch (pControlRequest->wValue) {
+				case USB_DEVICE_REMOTE_WAKEUP:
+					pThis->bMayWakeup = 1;
+					break;
+				case USB_DEVICE_TEST_MODE:
+					if (pThis->g.speed != USB_SPEED_HIGH)
+						goto stall;
+					if (pControlRequest->wIndex & 0xff)
+						goto stall;
+
+					switch (pControlRequest->wIndex >> 8) {
+					case 1:
+						pr_debug("TEST_J\n");
+						/* TEST_J */
+						pThis->bTestModeValue =
+							MGC_M_TEST_J;
+						break;
+					case 2:
+						/* TEST_K */
+						pr_debug("TEST_K\n");
+						pThis->bTestModeValue =
+							MGC_M_TEST_K;
+						break;
+					case 3:
+						/* TEST_SE0_NAK */
+						pr_debug("TEST_SE0_NAK\n");
+						pThis->bTestModeValue =
+							MGC_M_TEST_SE0_NAK;
+						break;
+					case 4:
+						/* TEST_PACKET */
+						pr_debug("TEST_PACKET\n");
+						pThis->bTestModeValue =
+							MGC_M_TEST_PACKET;
+						break;
+					default:
+						goto stall;
+					}
+
+					/* enter test mode after irq */
+					if (handled > 0)
+						pThis->bTestMode = TRUE;
+					break;
+#ifdef CONFIG_USB_MUSB_OTG
+				case USB_DEVICE_B_HNP_ENABLE:
+					if (!pThis->g.is_otg)
+						goto stall;
+					{ u8 devctl;
+					pThis->g.b_hnp_enable = 1;
+					devctl = musb_readb(pBase,
+							MGC_O_HDRC_DEVCTL);
+					/* REVISIT after roleswitch, HR will
+					 * have been cleared ... reset it
+					 */
+					musb_writeb(pBase, MGC_O_HDRC_DEVCTL,
+						devctl | MGC_M_DEVCTL_HR);
+					}
+					break;
+				case USB_DEVICE_A_HNP_SUPPORT:
+					if (!pThis->g.is_otg)
+						goto stall;
+					pThis->g.a_hnp_support = 1;
+					break;
+				case USB_DEVICE_A_ALT_HNP_SUPPORT:
+					if (!pThis->g.is_otg)
+						goto stall;
+					pThis->g.a_alt_hnp_support = 1;
+					break;
+#endif
+stall:
+				default:
+					handled = -EINVAL;
+					break;
+				}
+				break;
+
+			case USB_RECIP_INTERFACE:
+				break;
+
+			case USB_RECIP_ENDPOINT:{
+				const u8 bEnd = (u8)
+					pControlRequest->wIndex & 0x0f;
+				struct musb_ep *pEnd;
+				int is_in;
+				u16 csr;
+
+				if (bEnd == 0
+						|| bEnd >= MUSB_C_NUM_EPS
+						|| pControlRequest->wValue
+							!= USB_ENDPOINT_HALT)
+					break;
+
+				is_in = pControlRequest->wIndex & USB_DIR_IN;
+				if (is_in)
+					pEnd = &pThis->aLocalEnd[bEnd].ep_in;
+				else
+					pEnd = &pThis->aLocalEnd[bEnd].ep_out;
+				if (!pEnd->desc)
+					break;
+
+				MGC_SelectEnd(pBase, bEnd);
+				if (is_in) {
+					csr = MGC_ReadCsr16(pBase,
+							MGC_O_HDRC_TXCSR, bEnd);
+					csr |= MGC_M_TXCSR_P_SENDSTALL
+						| MGC_M_TXCSR_P_WZC_BITS;
+					MGC_WriteCsr16(pBase, MGC_O_HDRC_TXCSR,
+							bEnd, csr);
+				} else {
+					csr = MGC_ReadCsr16(pBase,
+							MGC_O_HDRC_RXCSR, bEnd);
+					csr |= MGC_M_RXCSR_P_SENDSTALL
+						| MGC_M_TXCSR_P_WZC_BITS;
+					MGC_WriteCsr16(pBase, MGC_O_HDRC_RXCSR,
+							bEnd, csr);
+				}
+
+				/* select ep0 again */
+				MGC_SelectEnd(pBase, 0);
+				handled = 1;
+				} break;
+
+			default:
+				/* class, vendor, etc ... delegate */
+				handled = 0;
+				break;
+			}
+			break;
+		default:
+			/* delegate SET_CONFIGURATION, etc */
+			handled = 0;
+		}
+	} else
+		handled = 0;
+	return handled;
+}
+
+/* we have an ep0out data packet
+ * Context:  caller holds controller lock
+ */
+static void ep0_rxstate(struct musb *this)
+{
+	void __iomem		*pBase = this->pRegs;
+	struct usb_request	*req;
+	u16			tmp;
+
+	req = next_ep0_request(this);
+
+	/* read packet and ack; or stall because of gadget driver bug:
+	 * should have provided the rx buffer before setup() returned.
+	 */
+	if (req) {
+		void		*buf = req->buf + req->actual;
+		unsigned	len = req->length - req->actual;
+
+		/* read the buffer */
+		tmp = MGC_ReadCsr8(pBase, MGC_O_HDRC_COUNT0, 0);
+		if (tmp > len) {
+			req->status = -EOVERFLOW;
+			tmp = len;
+		}
+		musb_read_fifo(&this->aLocalEnd[0], tmp, buf);
+		req->actual += tmp;
+		tmp = MGC_M_CSR0_P_SVDRXPKTRDY;
+		if (tmp < 64 || req->actual == req->length) {
+			this->ep0_state = MGC_END0_STAGE_STATUSIN;
+			tmp |= MGC_M_CSR0_P_DATAEND;
+		} else
+			req = NULL;
+	} else
+		tmp = MGC_M_CSR0_P_SVDRXPKTRDY | MGC_M_CSR0_P_SENDSTALL;
+	MGC_WriteCsr16(pBase, MGC_O_HDRC_CSR0, 0, tmp);
+
+
+	/* NOTE:  we "should" hold off reporting DATAEND and going to
+	 * STATUSIN until after the completion handler decides whether
+	 * to issue a stall instead, since this hardware can do that.
+	 */
+	if (req)
+		musb_g_ep0_giveback(this, req);
+}
+
+/*
+ * transmitting to the host (IN), this code might be called from IRQ
+ * and from kernel thread.
+ *
+ * Context:  caller holds controller lock
+ */
+static void ep0_txstate(struct musb *pThis)
+{
+	void __iomem		*pBase = pThis->pRegs;
+	struct usb_request	*pRequest = next_ep0_request(pThis);
+	u16			wCsrVal = MGC_M_CSR0_TXPKTRDY;
+	u8			*pFifoSource;
+	u8			wFifoCount;
+
+	if (!pRequest) {
+		// WARN_ON(1);
+		DBG(2, "odd, csr %04x\n", MGC_ReadCsr16(pBase, MGC_O_HDRC_CSR0, 0));
+		return;
+	}
+
+	/* load the data */
+	pFifoSource = (u8 *) pRequest->buf + pRequest->actual;
+	wFifoCount = min((unsigned) MGC_END0_FIFOSIZE,
+		pRequest->length - pRequest->actual);
+	musb_write_fifo(&pThis->aLocalEnd[0], wFifoCount, pFifoSource);
+	pRequest->actual += wFifoCount;
+
+	/* update the flags */
+	if (wFifoCount < MUSB_MAX_END0_PACKET
+			|| pRequest->actual == pRequest->length) {
+		pThis->ep0_state = MGC_END0_STAGE_STATUSOUT;
+		wCsrVal |= MGC_M_CSR0_P_DATAEND;
+	} else
+		pRequest = NULL;
+
+	/* send it out, triggering a "txpktrdy cleared" irq */
+	MGC_WriteCsr16(pBase, MGC_O_HDRC_CSR0, 0, wCsrVal);
+
+	/* report completions as soon as the fifo's loaded; there's no
+	 * win in waiting till this last packet gets acked.  (other than
+	 * very precise fault reporting, needed by USB TMC; possible with
+	 * this hardware, but not usable from portable gadget drivers.)
+	 */
+	if (pRequest)
+		musb_g_ep0_giveback(pThis, pRequest);
+}
+
+/*
+ * Read a SETUP packet (struct usb_ctrlrequest) from the hardware.
+ * Fields are left in USB byte-order.
+ *
+ * Context:  caller holds controller lock.
+ */
+static void
+musb_read_setup(struct musb *pThis, struct usb_ctrlrequest *req)
+{
+	void __iomem		*pBase = pThis->pRegs;
+	struct usb_request	*r;
+
+	musb_read_fifo(&pThis->aLocalEnd[0], sizeof *req, (u8 *)req);
+
+	/* NOTE:  earlier 2.6 versions changed setup packets to host
+	 * order, but now USB packets always stay in USB byte order.
+	 */
+	DBG(3, "SETUP req%02x.%02x v%04x i%04x l%d\n",
+		 req->bRequestType,
+		 req->bRequest,
+		 le16_to_cpu(req->wValue),
+		 le16_to_cpu(req->wIndex),
+		 le16_to_cpu(req->wLength));
+
+	/* clean up any leftover transfers */
+	r = next_ep0_request(pThis);
+	if (r)
+		musb_g_ep0_giveback(pThis, r);
+
+	/* For zero-data requests we want to delay the STATUS stage to
+	 * avoid SETUPEND errors.  If we read data (OUT), delay accepting
+	 * packets until there's a buffer to store them in.
+	 *
+	 * If we write data, the controller acts happier if we enable
+	 * the TX FIFO right away, and give the controller a moment
+	 * to switch modes...
+	 */
+	pThis->bSetAddress = FALSE;
+	pThis->ackpend = MGC_M_CSR0_P_SVDRXPKTRDY;
+	if (req->wLength == 0)
+		pThis->ep0_state = MGC_END0_STAGE_ACKWAIT;
+	else if (req->bRequestType & USB_DIR_IN) {
+		pThis->ep0_state = MGC_END0_STAGE_TX;
+		MGC_WriteCsr16(pBase, MGC_O_HDRC_CSR0, 0,
+				MGC_M_CSR0_P_SVDRXPKTRDY);
+		while ((MGC_ReadCsr16(pBase, MGC_O_HDRC_CSR0, 0)
+				& MGC_M_CSR0_RXPKTRDY) != 0)
+			cpu_relax();
+		pThis->ackpend = 0;
+	} else
+		pThis->ep0_state = MGC_END0_STAGE_RX;
+}
+
+static int
+forward_to_driver(struct musb *musb,
+		  const struct usb_ctrlrequest *pControlRequest)
+__releases(musb->Lock)
+__acquires(musb->Lock)
+{
+	int retval;
+	if (!musb->pGadgetDriver)
+		return -EOPNOTSUPP;
+	spin_unlock(&musb->Lock);
+	retval = musb->pGadgetDriver->setup(&musb->g, pControlRequest);
+	spin_lock(&musb->Lock);
+	return retval;
+}
+
+/*
+ * Handle peripheral ep0 interrupt
+ * @param pThis this
+ *
+ * Context: irq handler; we won't re-enter the driver that way.
+ */
+irqreturn_t musb_g_ep0_irq(struct musb *pThis)
+{
+	u16		wCsrVal;
+	u16		wCount;
+	void __iomem	*pBase = pThis->pRegs;
+	irqreturn_t	retval = IRQ_NONE;
+
+	MGC_SelectEnd(pBase, 0);	/* select ep0 */
+	wCsrVal = MGC_ReadCsr16(pBase, MGC_O_HDRC_CSR0, 0);
+	wCount = MGC_ReadCsr8(pBase, MGC_O_HDRC_COUNT0, 0);
+
+	DBG(4, "csr %04x, count %d, myaddr %d, ep0stage %s\n",
+			wCsrVal, wCount,
+			musb_readb(pBase, MGC_O_HDRC_FADDR),
+			decode_ep0stage(pThis->ep0_state));
+
+	/* I sent a stall.. need to acknowledge it now.. */
+	if (wCsrVal & MGC_M_CSR0_P_SENTSTALL) {
+		MGC_WriteCsr16(pBase, MGC_O_HDRC_CSR0, 0,
+			       wCsrVal & ~MGC_M_CSR0_P_SENTSTALL);
+		retval = IRQ_HANDLED;
+		pThis->ep0_state = MGC_END0_STAGE_SETUP;
+	}
+
+	/* request ended "early" */
+	if (wCsrVal & MGC_M_CSR0_P_SETUPEND) {
+		MGC_WriteCsr16(pBase, MGC_O_HDRC_CSR0, 0,
+			       MGC_M_CSR0_P_SVDSETUPEND);
+		retval = IRQ_HANDLED;
+		pThis->ep0_state = MGC_END0_STAGE_SETUP;
+		/* NOTE:  request may need completion */
+	}
+
+	/* docs from Mentor only describe tx, rx, and idle/setup states.
+	 * we need to handle nuances around status stages, and also the
+	 * case where status and setup stages come back-to-back ...
+	 */
+	switch (pThis->ep0_state) {
+
+	case MGC_END0_STAGE_TX:
+		/* irq on clearing txpktrdy */
+		if ((wCsrVal & MGC_M_CSR0_TXPKTRDY) == 0) {
+			ep0_txstate(pThis);
+			retval = IRQ_HANDLED;
+		}
+		break;
+
+	case MGC_END0_STAGE_RX:
+		/* irq on set rxpktrdy */
+		if (wCsrVal & MGC_M_CSR0_RXPKTRDY) {
+			ep0_rxstate(pThis);
+			retval = IRQ_HANDLED;
+		}
+		break;
+
+	case MGC_END0_STAGE_STATUSIN:
+		/* end of sequence #2 (OUT/RX state) or #3 (no data) */
+
+		/* update address (if needed) only @ the end of the
+		 * status phase per usb spec, which also guarantees
+		 * we get 10 msec to receive this irq... until this
+		 * is done we won't see the next packet.
+		 */
+		if (pThis->bSetAddress) {
+			pThis->bSetAddress = FALSE;
+			musb_writeb(pBase, MGC_O_HDRC_FADDR, pThis->bAddress);
+		}
+
+		/* enter test mode if needed (exit by reset) */
+		else if (pThis->bTestMode) {
+			DBG(1, "entering TESTMODE\n");
+
+			if (MGC_M_TEST_PACKET == pThis->bTestModeValue) {
+				musb_write_fifo(&pThis->aLocalEnd[0],
+						 sizeof(musb_test_packet),
+						 musb_test_packet);
+			}
+
+			musb_writeb(pBase, MGC_O_HDRC_TESTMODE,
+				   pThis->bTestModeValue);
+		}
+		/* FALLTHROUGH */
+
+	case MGC_END0_STAGE_STATUSOUT:
+		/* end of sequence #1: write to host (TX state) */
+		{
+			struct usb_request	*req;
+
+			req = next_ep0_request(pThis);
+			if (req)
+				musb_g_ep0_giveback(pThis, req);
+		}
+		retval = IRQ_HANDLED;
+		pThis->ep0_state = MGC_END0_STAGE_SETUP;
+		/* FALLTHROUGH */
+
+	case MGC_END0_STAGE_SETUP:
+		if (wCsrVal & MGC_M_CSR0_RXPKTRDY) {
+			struct usb_ctrlrequest	setup;
+			int			handled = 0;
+
+			if (wCount != 8) {
+				ERR("SETUP packet len %d != 8 ?\n", wCount);
+				break;
+			}
+			musb_read_setup(pThis, &setup);
+			retval = IRQ_HANDLED;
+
+			/* sometimes the RESET won't be reported */
+			if (unlikely(pThis->g.speed == USB_SPEED_UNKNOWN)) {
+				u8	power;
+
+				printk(KERN_NOTICE "%s: peripheral reset "
+						"irq lost!\n",
+						musb_driver_name);
+				power = musb_readb(pBase, MGC_O_HDRC_POWER);
+				pThis->g.speed = (power & MGC_M_POWER_HSMODE)
+				    ? USB_SPEED_HIGH : USB_SPEED_FULL;
+
+			}
+
+			switch (pThis->ep0_state) {
+
+			/* sequence #3 (no data stage), includes requests
+			 * we can't forward (notably SET_ADDRESS and the
+			 * device/endpoint feature set/clear operations)
+			 * plus SET_CONFIGURATION and others we must
+			 */
+			case MGC_END0_STAGE_ACKWAIT:
+				handled = service_zero_data_request(
+						pThis, &setup);
+
+				/* status stage might be immediate */
+				if (handled > 0) {
+					pThis->ackpend |= MGC_M_CSR0_P_DATAEND;
+					pThis->ep0_state =
+						MGC_END0_STAGE_STATUSIN;
+				}
+				break;
+
+			/* sequence #1 (IN to host), includes GET_STATUS
+			 * requests that we can't forward, GET_DESCRIPTOR
+			 * and others that we must
+			 */
+			case MGC_END0_STAGE_TX:
+				handled = service_in_request(pThis, &setup);
+				if (handled > 0) {
+					pThis->ackpend = MGC_M_CSR0_TXPKTRDY
+						| MGC_M_CSR0_P_DATAEND;
+					pThis->ep0_state =
+						MGC_END0_STAGE_STATUSOUT;
+				}
+				break;
+
+			/* sequence #2 (OUT from host), always forward */
+			default:		/* MGC_END0_STAGE_RX */
+				break;
+			}
+
+			DBG(3, "handled %d, csr %04x, ep0stage %s\n",
+				handled, wCsrVal,
+				decode_ep0stage(pThis->ep0_state));
+
+			/* unless we need to delegate this to the gadget
+			 * driver, we know how to wrap this up:  csr0 has
+			 * not yet been written.
+			 */
+			if (handled < 0)
+				goto stall;
+			else if (handled > 0)
+				goto finish;
+
+			handled = forward_to_driver(pThis, &setup);
+			if (handled < 0) {
+				MGC_SelectEnd(pBase, 0);
+stall:
+				DBG(3, "stall (%d)\n", handled);
+				pThis->ackpend |= MGC_M_CSR0_P_SENDSTALL;
+finish:
+				MGC_WriteCsr16(pBase, MGC_O_HDRC_CSR0, 0,
+						pThis->ackpend);
+				pThis->ackpend = 0;
+			}
+		}
+		break;
+
+	default:
+		/* "can't happen" */
+		WARN_ON(1);
+		MGC_WriteCsr16(pBase, MGC_O_HDRC_CSR0, 0,
+				MGC_M_CSR0_P_SENDSTALL);
+		pThis->ep0_state = MGC_END0_STAGE_SETUP;
+		break;
+	}
+
+	return retval;
+}
+
+
+static int
+musb_g_ep0_enable(struct usb_ep *ep, const struct usb_endpoint_descriptor *desc)
+{
+	/* always enabled */
+	return -EINVAL;
+}
+
+static int musb_g_ep0_disable(struct usb_ep *e)
+{
+	/* always enabled */
+	return -EINVAL;
+}
+
+static void *musb_g_ep0_alloc_buffer(struct usb_ep *ep, unsigned bytes,
+			    dma_addr_t * dma, gfp_t gfp_flags)
+{
+	*dma = DMA_ADDR_INVALID;
+	return kmalloc(bytes, gfp_flags);
+}
+
+static void musb_g_ep0_free_buffer(struct usb_ep *ep, void *address, dma_addr_t dma,
+			  unsigned bytes)
+{
+	kfree(address);
+}
+
+static int
+musb_g_ep0_queue(struct usb_ep *e, struct usb_request *r, gfp_t gfp_flags)
+{
+	struct musb_ep		*ep;
+	struct musb_request	*req;
+	struct musb		*musb;
+	int			status;
+	unsigned long		lockflags;
+
+	if (!e || !r)
+		return -EINVAL;
+
+	ep = to_musb_ep(e);
+	musb = ep->pThis;
+
+	req = to_musb_request(r);
+	req->musb = musb;
+	req->request.actual = 0;
+	req->request.status = -EINPROGRESS;
+	req->bTx = ep->is_in;
+
+	spin_lock_irqsave(&musb->Lock, lockflags);
+
+	if (!list_empty(&ep->req_list)) {
+		status = -EBUSY;
+		goto cleanup;
+	}
+
+	switch (musb->ep0_state) {
+	case MGC_END0_STAGE_RX:		/* control-OUT data */
+	case MGC_END0_STAGE_TX:		/* control-IN data */
+	case MGC_END0_STAGE_ACKWAIT:	/* zero-length data */
+		status = 0;
+		break;
+	default:
+		DBG(1, "ep0 request queued in state %d\n",
+				musb->ep0_state);
+		status = -EINVAL;
+		goto cleanup;
+	}
+
+	/* add request to the list */
+	list_add_tail(&(req->request.list), &(ep->req_list));
+
+	DBG(3, "queue to %s (%s), length=%d\n",
+			ep->name, ep->is_in ? "IN/TX" : "OUT/RX",
+			req->request.length);
+
+	MGC_SelectEnd(musb->pRegs, 0);
+
+	/* sequence #1, IN ... start writing the data */
+	if (musb->ep0_state == MGC_END0_STAGE_TX)
+		ep0_txstate(musb);
+
+	/* sequence #3, no-data ... issue IN status */
+	else if (musb->ep0_state == MGC_END0_STAGE_ACKWAIT) {
+		if (req->request.length)
+			status = -EINVAL;
+		else {
+			musb->ep0_state = MGC_END0_STAGE_STATUSIN;
+			MGC_WriteCsr16(musb->pRegs, MGC_O_HDRC_CSR0, 0,
+				       musb->ackpend | MGC_M_CSR0_P_DATAEND);
+			musb->ackpend = 0;
+			musb_g_ep0_giveback(ep->pThis, r);
+		}
+
+	/* else for sequence #2 (OUT), caller provides a buffer
+	 * before the next packet arrives.  deferred responses
+	 * (after SETUP is acked) are racey.
+	 */
+	} else if (musb->ackpend) {
+		MGC_WriteCsr16(musb->pRegs, MGC_O_HDRC_CSR0, 0,
+			       musb->ackpend);
+		musb->ackpend = 0;
+	}
+
+cleanup:
+	spin_unlock_irqrestore(&musb->Lock, lockflags);
+	return status;
+}
+
+static int
+musb_g_ep0_dequeue(struct usb_ep *ep, struct usb_request *req)
+{
+	/* we just won't support this */
+	return -EINVAL;
+}
+
+static int musb_g_ep0_halt(struct usb_ep *e, int value)
+{
+	struct musb_ep		*ep;
+	struct musb		*musb;
+	void __iomem		*base;
+	unsigned long		flags;
+	int			status;
+	u16			csr;
+
+	if (!e || !value)
+		return -EINVAL;
+
+	ep = to_musb_ep(e);
+	musb = ep->pThis;
+	base = musb->pRegs;
+
+	spin_lock_irqsave(&musb->Lock, flags);
+
+	if (!list_empty(&ep->req_list)) {
+		status = -EBUSY;
+		goto cleanup;
+	}
+
+	switch (musb->ep0_state) {
+	case MGC_END0_STAGE_TX:		/* control-IN data */
+	case MGC_END0_STAGE_ACKWAIT:	/* STALL for zero-length data */
+	case MGC_END0_STAGE_RX:		/* control-OUT data */
+		status = 0;
+
+		MGC_SelectEnd(base, 0);
+		csr = MGC_ReadCsr16(base, MGC_O_HDRC_CSR0, 0);
+		csr |= MGC_M_CSR0_P_SENDSTALL;
+		MGC_WriteCsr16(base, MGC_O_HDRC_CSR0, 0, csr);
+		musb->ep0_state = MGC_END0_STAGE_SETUP;
+		break;
+	default:
+		DBG(1, "ep0 can't halt in state %d\n", musb->ep0_state);
+		status = -EINVAL;
+	}
+
+cleanup:
+	spin_unlock_irqrestore(&musb->Lock, flags);
+	return status;
+}
+
+struct usb_ep_ops musb_g_ep0_ops = {
+	.enable		= musb_g_ep0_enable,
+	.disable	= musb_g_ep0_disable,
+	.alloc_request	= musb_alloc_request,
+	.free_request	= musb_free_request,
+	.alloc_buffer	= musb_g_ep0_alloc_buffer,
+	.free_buffer	= musb_g_ep0_free_buffer,
+	.queue		= musb_g_ep0_queue,
+	.dequeue	= musb_g_ep0_dequeue,
+	.set_halt	= musb_g_ep0_halt,
+	.fifo_status	= NULL,
+	.fifo_flush	= NULL,
+};
Index: linux-2.6.10/drivers/usb/musb/musb_gadget.c
===================================================================
--- /dev/null
+++ linux-2.6.10/drivers/usb/musb/musb_gadget.c
@@ -0,0 +1,1743 @@
+/******************************************************************
+ * Copyright 2005 Mentor Graphics Corporation
+ * Copyright (C) 2005-2006 by Texas Instruments
+ *
+ * This file is part of the Inventra Controller Driver for Linux.
+ *
+ * The Inventra Controller Driver for Linux is free software; you
+ * can redistribute it and/or modify it under the terms of the GNU
+ * General Public License version 2 as published by the Free Software
+ * Foundation.
+ *
+ * The Inventra Controller Driver for Linux is distributed in
+ * the hope that it will be useful, but WITHOUT ANY WARRANTY;
+ * without even the implied warranty of MERCHANTABILITY or
+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public
+ * License for more details.
+ *
+ * You should have received a copy of the GNU General Public License
+ * along with The Inventra Controller Driver for Linux ; if not,
+ * write to the Free Software Foundation, Inc., 59 Temple Place,
+ * Suite 330, Boston, MA  02111-1307  USA
+ *
+ * ANY DOWNLOAD, USE, REPRODUCTION, MODIFICATION OR DISTRIBUTION
+ * OF THIS DRIVER INDICATES YOUR COMPLETE AND UNCONDITIONAL ACCEPTANCE
+ * OF THOSE TERMS.THIS DRIVER IS PROVIDED "AS IS" AND MENTOR GRAPHICS
+ * MAKES NO WARRANTIES, EXPRESS OR IMPLIED, RELATED TO THIS DRIVER.
+ * MENTOR GRAPHICS SPECIFICALLY DISCLAIMS ALL IMPLIED WARRANTIES
+ * OF MERCHANTABILITY; FITNESS FOR A PARTICULAR PURPOSE AND
+ * NON-INFRINGEMENT.  MENTOR GRAPHICS DOES NOT PROVIDE SUPPORT
+ * SERVICES OR UPDATES FOR THIS DRIVER, EVEN IF YOU ARE A MENTOR
+ * GRAPHICS SUPPORT CUSTOMER.
+ ******************************************************************/
+
+#include <linux/kernel.h>
+#include <linux/list.h>
+#include <linux/timer.h>
+#include <linux/module.h>
+#include <linux/smp.h>
+#include <linux/spinlock.h>
+#include <linux/delay.h>
+#include <linux/device.h>
+#include <linux/moduleparam.h>
+#include <linux/stat.h>
+#include <linux/dma-mapping.h>
+
+#include "musbdefs.h"
+
+
+/* MUSB PERIPHERAL status 3-mar:
+ *
+ * - EP0 seems solid.  It passes both USBCV and usbtest control cases.
+ *   (Minor glitches running the remote wakeup tests, which seem to live
+ *   in USBCV; wakeup of Linux hosts works.)
+ *
+ * - Mass storage behaved ok when last tested.  Network traffic patterns
+ *   (with lots of short transfers etc) aren't yet reliable
+ *
+ * - TEMPORARY STATUS:
+ *     + RXDMA broke recently
+ *     + still didn't test DMA with double buffering
+ *
+ * - TX/IN
+ *     + both pio and dma behave in with network and g_zero tests
+ *     + no dma throughput issues other than no-hw-queueing
+ *     + failed with FLAT_REG
+ *     + seems to behave with double buffering
+ *     + with gadgetfs + AIO, requests got lost?
+ *
+ * - RX/OUT
+ *     + both pio and dma behave in with network and g_zero tests
+ *     + dma is slow in typical case (short_not_ok is clear)
+ *     + double buffering ok with PIO
+ *     + double buffering *FAILS* with DMA, wrong data bytes sometimes
+ *     + request lossage observed with gadgetfs
+ *
+ * - ISO not tested ... might work, but only weakly isochronous
+ *
+ * - Gadget driver disabling of softconnect during bind() is ignored; so
+ *   drivers can't hold off host requests until userspace is ready.
+ *   (Workaround:  they can turn it off later.)
+ */
+
+// #define	DISABLE_RXDMA
+
+/**************************************************************************
+Handling completion
+**************************************************************************/
+
+/*
+ * Immediately complete a request.
+ *
+ * @param pRequest the request to complete
+ * @param status the status to complete the request with
+ * Context: controller locked, IRQs blocked.
+ */
+void musb_g_giveback(
+	struct musb_ep		*ep,
+	struct usb_request	*pRequest,
+	int status)
+__releases(ep->musb->Lock)
+__acquires(ep->musb->Lock)
+{
+	struct musb_request	*req;
+	struct musb		*musb;
+	int			busy = ep->busy;
+
+	req = to_musb_request(pRequest);
+
+	list_del(&pRequest->list);
+	if (req->request.status == -EINPROGRESS)
+		req->request.status = status;
+	musb = req->musb;
+
+	ep->busy = 1;
+	spin_unlock(&musb->Lock);
+	if (is_dma_capable() && req->mapped) {
+		dma_unmap_single(musb->controller,
+				req->request.dma,
+				req->request.length,
+				req->bTx
+					? DMA_TO_DEVICE
+					: DMA_FROM_DEVICE);
+		req->request.dma = DMA_ADDR_INVALID;
+		req->mapped = 0;
+	}
+	if (pRequest->status == 0)
+		DBG(5, "%s done request %p,  %d/%d\n",
+				ep->end_point.name, pRequest,
+				req->request.actual, req->request.length);
+	else
+		DBG(2, "%s request %p, %d/%d fault %d\n",
+				ep->end_point.name, pRequest,
+				req->request.actual, req->request.length,
+				pRequest->status);
+	req->request.complete(&req->ep->end_point, &req->request);
+	spin_lock(&musb->Lock);
+	ep->busy = busy;
+}
+
+/* ----------------------------------------------------------------------- */
+
+/*
+ * Abort requests queued to an endpoint using the status. Synchronous.
+ * caller locked controller and blocked irqs, and selected this ep.
+ */
+static void nuke(struct musb_ep *ep, const int status)
+{
+	struct musb_request	*req = NULL;
+
+	ep->busy = 1;
+
+	if (is_dma_capable() && ep->dma) {
+		struct dma_controller	*c = ep->pThis->pDmaController;
+		int value;
+
+		value = c->pfDmaAbortChannel(ep->dma);
+		DBG(value ? 1 : 6, "%s: abort DMA --> %d\n", ep->name, value);
+		c->pfDmaReleaseChannel(ep->dma);
+		ep->dma = NULL;
+	}
+
+	while (!list_empty(&(ep->req_list))) {
+		req = container_of(ep->req_list.next, struct musb_request,
+				request.list);
+		musb_g_giveback(ep, &req->request, status);
+	}
+}
+
+/**************************************************************************
+ * TX/IN and RX/OUT Data transfers
+ **************************************************************************/
+
+/*
+ * This assumes the separate CPPI engine is responding to DMA requests
+ * from the usb core ... sequenced a bit differently from mentor dma.
+ */
+
+static inline int max_ep_writesize(struct musb *pThis, struct musb_ep *ep)
+{
+#ifdef	C_MP_TX
+	if ((USB_ENDPOINT_XFER_BULK == ep->type) && pThis->bBulkSplit)
+		return pThis->aLocalEnd[bEnd].wMaxPacketSizeTx;
+	else
+#endif
+		return ep->wPacketSize;
+}
+
+/*
+ * An endpoint is transmitting data. This can be called either from
+ * the IRQ routine or from GadgetQueue to kickstart a request on an
+ * endpoint.
+ *
+ * Context: controller locked, IRQs blocked, endpoint selected
+ */
+static void txstate(struct musb *pThis, struct musb_request *req)
+{
+	u8			bEnd;
+	struct musb_ep		*pEnd;
+	struct usb_request	*pRequest;
+	void __iomem		*pBase = pThis->pRegs;
+	u16			wFifoCount = 0, wCsrVal;
+	int			use_dma = 0;
+
+	bEnd = req->bEnd;
+	pEnd = req->ep;
+
+	/* we shouldn't get here while DMA is active ... but we do ... */
+	if (dma_channel_status(pEnd->dma) == MGC_DMA_STATUS_BUSY) {
+		DBG(4, "dma pending...\n");
+		return;
+	}
+
+	/* read TXCSR before */
+	wCsrVal = MGC_ReadCsr16(pBase, MGC_O_HDRC_TXCSR, bEnd);
+
+	pRequest = &req->request;
+	wFifoCount = min(max_ep_writesize(pThis, pEnd),
+			 (int)(pRequest->length - pRequest->actual));
+
+	if (wCsrVal & MGC_M_TXCSR_TXPKTRDY) {
+		DBG(5, "%s old packet still ready , txcsr %03x\n",
+				pEnd->end_point.name, wCsrVal);
+		return;
+	}
+
+	DBG(4, "hw_ep%d, maxpacket %d, fifo count %d, txcsr %03x\n",
+			bEnd, pEnd->wPacketSize, wFifoCount,
+			wCsrVal);
+
+	/* stalled?? */
+	if (wCsrVal & MGC_M_TXCSR_P_SENTSTALL) {
+		musb_g_giveback(pEnd, pRequest, -EPIPE);
+		return;
+	}
+
+	if (is_dma_capable() && pEnd->dma) {
+		struct dma_controller	*c;
+
+		c = pThis->pDmaController;
+		use_dma = (pRequest->dma != DMA_ADDR_INVALID);
+
+		/* MGC_M_TXCSR_ISO is still set correctly */
+
+#ifdef CONFIG_USB_INVENTRA_DMA
+		/* setup DMA, then program endpoint CSR */
+		dma->dwActualLength = 0L;
+		pEnd->dwRequestSize = min(pRequest->length,
+					  dma->dwMaxLength);
+		use_dma = use_dma && c->pfDmaProgramChannel(
+				pEnd->dma, pEnd->wPacketSize,
+				pDmaChannel->bDesiredMode,
+				pRequest->dma, pEnd->dwRequestSize);
+		if (use_dma) {
+			wCsrVal |= MGC_M_TXCSR_AUTOSET
+				| MGC_M_TXCSR_DMAENAB
+				| (pDmaChannel->bDesiredMode
+				    ? MGC_M_TXCSR_DMAMODE : 0);
+			MGC_WriteCsr16(pBase, MGC_O_HDRC_TXCSR, bEnd, wCsrVal);
+		}
+
+#elif defined(CONFIG_USB_TI_CPPI_DMA)
+		/* program endpoint CSR first, then setup DMA */
+		wCsrVal &= ~(MGC_M_TXCSR_AUTOSET
+				| MGC_M_TXCSR_DMAMODE
+				| MGC_M_TXCSR_TXPKTRDY);
+		wCsrVal |= MGC_M_TXCSR_MODE | MGC_M_TXCSR_DMAENAB;
+		MGC_WriteCsr16(pBase, MGC_O_HDRC_TXCSR, bEnd,
+				MGC_M_TXCSR_P_WZC_BITS | wCsrVal);
+
+// REVISIT host side sets DMAENAB later than this ...
+
+		/* prefer 'rndis' mode whenever the last
+		 * tx packet will be short
+		 */
+		use_dma = use_dma && c->pfDmaProgramChannel(
+				pEnd->dma, pEnd->wPacketSize,
+				pRequest->zero,
+				pRequest->dma,
+				pRequest->length);
+		if (!use_dma) {
+			c->pfDmaReleaseChannel(pEnd->dma);
+			pEnd->dma = NULL;
+			wCsrVal &= ~(MGC_M_TXCSR_DMAMODE | MGC_M_TXCSR_MODE);
+			/* invariant: prequest->buf is non-null */
+		}
+#endif
+	}
+
+	if (!use_dma) {
+		musb_write_fifo(pEnd->hw_ep, wFifoCount,
+				 (u8 *) (pRequest->buf + pRequest->actual));
+		pRequest->actual += wFifoCount;
+		wCsrVal |= MGC_M_TXCSR_TXPKTRDY;
+		MGC_WriteCsr16(pBase, MGC_O_HDRC_TXCSR, bEnd, wCsrVal);
+	}
+
+	/* host may already have the data when this message shows... */
+	DBG(3, "%s TX/IN %s len %d/%d, txcsr %04x, fifo %d/%d\n",
+			pEnd->end_point.name, use_dma ? "dma" : "pio",
+			pRequest->actual, pRequest->length,
+			MGC_ReadCsr16(pBase, MGC_O_HDRC_TXCSR, bEnd),
+			wFifoCount,
+			MGC_ReadCsr16(pBase, MGC_O_HDRC_TXMAXP, bEnd));
+}
+
+/*
+ * FIFO state update (e.g. data ready).
+ * Called from IRQ,  with controller locked.
+ */
+void musb_g_tx(struct musb *pThis, u8 bEnd)
+{
+	u16			wCsrVal;
+	struct usb_request	*pRequest;
+	u8 __iomem		*pBase = pThis->pRegs;
+	struct musb_ep		*pEnd;
+	struct dma_channel	*dma;
+
+	MGC_SelectEnd(pBase, bEnd);
+	pEnd = &pThis->aLocalEnd[bEnd].ep_in;
+	pRequest = next_request(pEnd);
+
+	wCsrVal = MGC_ReadCsr16(pBase, MGC_O_HDRC_TXCSR, bEnd);
+	DBG(4, "<== %s, txcsr %04x\n", pEnd->end_point.name, wCsrVal);
+
+	dma = is_dma_capable() ? pEnd->dma : NULL;
+	do {
+		/* REVISIT for high bandwidth, MGC_M_TXCSR_P_INCOMPTX
+		 * probably rates reporting as a host error
+		 */
+		if (wCsrVal & MGC_M_TXCSR_P_SENTSTALL) {
+			wCsrVal &= ~MGC_M_TXCSR_P_SENTSTALL;
+			MGC_WriteCsr16(pBase, MGC_O_HDRC_TXCSR, bEnd, wCsrVal);
+			if (dma_channel_status(dma) == MGC_DMA_STATUS_BUSY) {
+				dma->bStatus = MGC_DMA_STATUS_CORE_ABORT;
+				pThis->pDmaController->pfDmaAbortChannel(dma);
+			}
+
+			if (pRequest)
+				musb_g_giveback(pEnd, pRequest, -EPIPE);
+
+			break;
+		}
+
+		if (wCsrVal & MGC_M_TXCSR_P_UNDERRUN) {
+			/* we NAKed, no big deal ... little reason to care */
+			wCsrVal &= ~(MGC_M_TXCSR_P_UNDERRUN
+					| MGC_M_TXCSR_TXPKTRDY);
+			MGC_WriteCsr16(pBase, MGC_O_HDRC_TXCSR, bEnd, wCsrVal);
+			DBG(7, "underrun on ep%d, req %p\n", bEnd, pRequest);
+		}
+
+		if (dma_channel_status(dma) == MGC_DMA_STATUS_BUSY) {
+			/* SHOULD NOT HAPPEN (but does) */
+			DBG(3, "%s busy\n", pEnd->end_point.name);
+			break;
+		}
+
+		if (pRequest) {
+			u8	is_dma = 0;
+
+			if (dma && (wCsrVal & MGC_M_TXCSR_DMAENAB)) {
+				is_dma = 1;
+				wCsrVal &= ~(MGC_M_TXCSR_DMAENAB
+						| MGC_M_TXCSR_TXPKTRDY);
+				MGC_WriteCsr16(pBase, MGC_O_HDRC_TXCSR, bEnd,
+					MGC_M_TXCSR_P_WZC_BITS | wCsrVal);
+				DBG(4, "TXCSR%d %04x, dma off, %04x, "
+						"len %Zd, req %p\n",
+					bEnd, wCsrVal,
+					MGC_ReadCsr16(pBase, MGC_O_HDRC_TXCSR,
+						bEnd),
+					pEnd->dma->dwActualLength,
+					pRequest);
+				pRequest->actual += pEnd->dma->dwActualLength;
+			}
+
+			if (is_dma || pRequest->actual == pRequest->length) {
+
+				/* first, maybe a terminating short packet */
+				if (pRequest->zero
+						&& pRequest->length
+						&& (pRequest->length
+							% pEnd->wPacketSize)
+							== 0) {
+					const u16 wCsrVal = MGC_M_TXCSR_MODE
+							| MGC_M_TXCSR_TXPKTRDY;
+
+					/* REVISIT cppi dma would do this for
+					 * us. for pio, don't loop...
+					 */
+					DBG(3, "sending zero pkt\n");
+
+					MGC_WriteCsr16(pBase, MGC_O_HDRC_TXCSR,
+						       bEnd, wCsrVal);
+					break;
+				}
+
+				/* ... or if not, then complete it */
+				musb_g_giveback(pEnd, pRequest, 0);
+
+				/* kickstart next transfer if appropriate;
+				 * the packet that just completed might not
+				 * be transmitted for hours or days.
+				 * REVISIT for double buffering...
+				 * FIXME revisit for stalls too...
+				 */
+				MGC_SelectEnd(pBase, bEnd);
+				wCsrVal = MGC_ReadCsr16(pBase,
+						MGC_O_HDRC_TXCSR, bEnd);
+				if (wCsrVal & MGC_M_TXCSR_FIFONOTEMPTY)
+					break;
+				pRequest = pEnd->desc
+						? next_request(pEnd)
+						: NULL;
+				if (!pRequest) {
+					DBG(4, "bEnd=0x%x idle now\n", bEnd);
+					break;
+				}
+			}
+
+			txstate(pThis, to_musb_request(pRequest));
+		}
+
+	} while (0);
+}
+
+/* ------------------------------------------------------------ */
+
+/*
+ * Context: controller locked, IRQs blocked, endpoint selected
+ */
+static void rxstate(struct musb *pThis, struct musb_request *req)
+{
+	u16			wCsrVal = 0;
+	const u8		bEnd = req->bEnd;
+	struct usb_request	*pRequest = &req->request;
+	void __iomem		*pBase = pThis->pRegs;
+	struct musb_ep		*pEnd = &pThis->aLocalEnd[bEnd].ep_out;
+	u16			wFifoCount = 0;
+	u16			wCount = pEnd->wPacketSize;
+
+	wCsrVal = MGC_ReadCsr16(pBase, MGC_O_HDRC_RXCSR, bEnd);
+
+#ifdef	CONFIG_USB_TI_CPPI_DMA
+	if (is_dma_capable() && pEnd->dma) {
+		struct dma_controller	*c = pThis->pDmaController;
+		struct dma_channel	*channel = pEnd->dma;
+
+		/* NOTE:  CPPI won't actually stop advancing the DMA
+		 * queue after short packet transfers, so this is almost
+		 * always going to run as IRQ-per-packet DMA so that
+		 * faults will be handled correctly.
+		 */
+		if (c->pfDmaProgramChannel(channel,
+				pEnd->wPacketSize,
+				!pRequest->short_not_ok,
+				pRequest->dma + pRequest->actual,
+				pRequest->length - pRequest->actual)) {
+
+			/* make sure that if an rxpkt arrived after the irq,
+			 * the cppi engine will be ready to take it as soon
+			 * as DMA is enabled
+			 */
+			wCsrVal &= ~(MGC_M_RXCSR_AUTOCLEAR | MGC_M_RXCSR_DMAMODE);
+			wCsrVal |= MGC_M_RXCSR_DMAENAB | MGC_M_RXCSR_P_WZC_BITS;
+			MGC_WriteCsr16(pBase, MGC_O_HDRC_RXCSR, bEnd, wCsrVal);
+			return;
+		}
+	}
+#endif
+
+	if (wCsrVal & MGC_M_RXCSR_RXPKTRDY) {
+		wCount = MGC_ReadCsr16(pBase, MGC_O_HDRC_RXCOUNT, bEnd);
+		if (pRequest->actual < pRequest->length) {
+#ifdef CONFIG_USB_INVENTRA_DMA
+			if (is_dma_capable() && pEnd->dma) {
+				struct dma_controller	*c;
+				struct dma_channel	*channel;
+				int			use_dma = 0;
+
+				c = pThis->pDmaController;
+				channel = pEnd->dma;
+				/* see if we need to continue transfer */
+				switch (c->pfDmaGetChannelStatus(channel)) {
+				case MGC_DMA_STATUS_FREE:
+					pRequest->actual =
+					    channel->dwActualLength;
+					if (pRequest->actual
+							< pRequest->length) {
+						channel->dwActualLength = 0L;
+						pEnd->dwRequestSize =
+						    min(pRequest->length,
+							channel->
+							dwMaxLength);
+						use_dma =
+						    c->pfDmaProgramChannel
+						    (channel,
+						     pEnd->wPacketSize,
+						     channel->bDesiredMode,
+						     channel->dma +
+						     channel->actual,
+						     pEnd->dwRequestSize);
+					}
+					break;
+				case MGC_DMA_STATUS_BUSY:
+					return;
+				default:
+					/* TODO: say what? */
+					pRequest->status = -ECONNRESET;
+				}
+				if (use_dma && !pRequest->actual) {
+					wCsrVal |= MGC_M_RXCSR_AUTOCLEAR
+						| MGC_M_RXCSR_DMAENAB
+						| MGC_M_RXCSR_P_WZC_BITS;
+
+					/* this special sequence is required to
+					 * get DMAReq to activate
+					 * */
+					MGC_WriteCsr16(pBase, MGC_O_HDRC_RXCSR,
+						       bEnd, wCsrVal |
+						       MGC_M_RXCSR_DMAMODE);
+					MGC_WriteCsr16(pBase,
+						       MGC_O_HDRC_RXCSR,
+						       bEnd, wCsrVal);
+				}
+				if (use_dma)
+					return;
+			}
+#endif
+
+			wFifoCount = pRequest->length - pRequest->actual;
+			DBG(3, "%s OUT/RX pio fifo %d/%d, maxpacket %d\n",
+					pEnd->end_point.name,
+					wCount, wFifoCount,
+					pEnd->wPacketSize);
+
+			wFifoCount = min(wCount, wFifoCount);
+			musb_read_fifo(pEnd->hw_ep, wFifoCount,
+				   (u8 *) (pRequest->buf +
+					   pRequest->actual));
+			pRequest->actual += wFifoCount;
+
+			/* REVISIT if we left anything in the fifo, flush
+			 * it and report -EOVERFLOW
+			 */
+
+			/* ack the read! */
+			wCsrVal |= MGC_M_RXCSR_P_WZC_BITS;
+			wCsrVal &= ~MGC_M_RXCSR_RXPKTRDY;
+			MGC_WriteCsr16(pBase, MGC_O_HDRC_RXCSR, bEnd, wCsrVal);
+		}
+	}
+
+	/* reach the end or short packet detected */
+	if (pRequest->actual == pRequest->length || wCount < pEnd->wPacketSize)
+		musb_g_giveback(pEnd, pRequest, 0);
+}
+
+/*
+ * Data ready for a request; called from IRQ
+ * @param pThis the controller
+ * @param req the request
+ */
+void musb_g_rx(struct musb *pThis, u8 bEnd)
+{
+	u16			wCsrVal;
+	struct usb_request	*pRequest;
+	void __iomem		*pBase = pThis->pRegs;
+	struct musb_ep		*pEnd;
+	struct dma_channel	*dma;
+
+	MGC_SelectEnd(pBase, bEnd);
+
+	pEnd = &pThis->aLocalEnd[bEnd].ep_out;
+	pRequest = next_request(pEnd);
+
+	wCsrVal = MGC_ReadCsr16(pBase, MGC_O_HDRC_RXCSR, bEnd);
+	DBG(4, "<== %s, rxcsr %04x\n", pEnd->end_point.name, wCsrVal);
+
+	dma = is_dma_capable() ? pEnd->dma : NULL;
+
+	if (wCsrVal & MGC_M_RXCSR_P_SENTSTALL) {
+		if (dma_channel_status(dma) == MGC_DMA_STATUS_BUSY) {
+			dma->bStatus = MGC_DMA_STATUS_CORE_ABORT;
+			(void) pThis->pDmaController->pfDmaAbortChannel(dma);
+			pRequest->actual += pEnd->dma->dwActualLength;
+		}
+
+		wCsrVal |= MGC_M_RXCSR_P_WZC_BITS;
+		wCsrVal &= ~MGC_M_RXCSR_P_SENTSTALL;
+		MGC_WriteCsr16(pBase, MGC_O_HDRC_RXCSR, bEnd, wCsrVal);
+
+		if (pRequest)
+			musb_g_giveback(pEnd, pRequest, -EPIPE);
+		goto done;
+	}
+
+	if (wCsrVal & MGC_M_RXCSR_P_OVERRUN) {
+		// wCsrVal |= MGC_M_RXCSR_P_WZC_BITS;
+		wCsrVal &= ~MGC_M_RXCSR_P_OVERRUN;
+		MGC_WriteCsr16(pBase, MGC_O_HDRC_RXCSR, bEnd, wCsrVal);
+
+		DBG(3, "%s iso overrun on %p\n", pEnd->name, pRequest);
+		if (pRequest && pRequest->status == -EINPROGRESS)
+			pRequest->status = -EOVERFLOW;
+	}
+	if (wCsrVal & MGC_M_RXCSR_INCOMPRX) {
+		/* REVISIT not necessarily an error */
+		DBG(4, "%s, incomprx\n", pEnd->end_point.name);
+	}
+
+	if (dma_channel_status(dma) == MGC_DMA_STATUS_BUSY) {
+		/* "should not happen"; likely RXPKTRDY pending for DMA */
+		DBG(4, "%s busy, csr %04x\n", pEnd->end_point.name, wCsrVal);
+		goto done;
+	}
+
+	if (dma && (wCsrVal & MGC_M_RXCSR_DMAENAB)) {
+		wCsrVal &= ~MGC_M_RXCSR_DMAENAB;
+		MGC_WriteCsr16(pBase, MGC_O_HDRC_RXCSR, bEnd,
+			MGC_M_RXCSR_P_WZC_BITS | wCsrVal);
+
+		DBG(4, "RXCSR%d %04x, dma off, %04x, len %Zd, req %p\n",
+			bEnd, wCsrVal,
+			MGC_ReadCsr16(pBase, MGC_O_HDRC_RXCSR, bEnd),
+			pEnd->dma->dwActualLength, pRequest);
+		pRequest->actual += pEnd->dma->dwActualLength;
+		musb_g_giveback(pEnd, pRequest, 0);
+
+		pRequest = next_request(pEnd);
+		if (!pRequest)
+			goto done;
+
+		/* don't start more i/o till the stall clears */
+		MGC_SelectEnd(pBase, bEnd);
+		wCsrVal = MGC_ReadCsr16(pBase, MGC_O_HDRC_RXCSR, bEnd);
+		if (wCsrVal & MGC_M_RXCSR_P_SENDSTALL)
+			goto done;
+	}
+
+
+	/* analyze request if the ep is hot */
+	if (pRequest)
+		rxstate(pThis, to_musb_request(pRequest));
+	else
+		DBG(3, "Rx: bytes waiting on %sep=0x%x\n",
+				pEnd->desc ? "" : "inactive ",
+				bEnd);
+
+done:
+	return;
+}
+
+/* ------------------------------------------------------------ */
+
+static int musb_gadget_enable(struct usb_ep *ep,
+			       const struct usb_endpoint_descriptor *desc)
+{
+	unsigned long flags;
+	struct musb_ep	*pEnd;
+	struct musb	*pThis;
+	void __iomem	*pBase;
+	u8		bEnd;
+	u16		csr;
+	unsigned	tmp;
+	int		status = -EINVAL;
+
+	if (!ep || !desc)
+		return -EINVAL;
+
+	pEnd = to_musb_ep(ep);
+	pThis = pEnd->pThis;
+	pBase = pThis->pRegs;
+	bEnd = pEnd->bEndNumber;
+
+	spin_lock_irqsave(&pThis->Lock, flags);
+
+	if (pEnd->desc) {
+		status = -EBUSY;
+		goto fail;
+	}
+	pEnd->type = desc->bmAttributes & USB_ENDPOINT_XFERTYPE_MASK;
+
+	/* check direction and (later) maxpacket size against endpoint */
+	if ((desc->bEndpointAddress & USB_ENDPOINT_NUMBER_MASK) != bEnd)
+		goto fail;
+
+	/* REVISIT this rules out high bandwidth periodic transfers */
+	tmp = le16_to_cpu(desc->wMaxPacketSize);
+	if (tmp & ~0x07ff)
+		goto fail;
+	pEnd->wPacketSize = tmp;
+
+	/* enable the interrupts for the endpoint, set the endpoint
+	 * packet size (or fail), set the mode, clear the fifo
+	 */
+	MGC_SelectEnd(pBase, bEnd);
+	if (desc->bEndpointAddress & USB_DIR_IN) {
+		u16 wIntrTxE = musb_readw(pBase, MGC_O_HDRC_INTRTXE);
+
+		if (pEnd->hw_ep->bIsSharedFifo)
+			pEnd->is_in = 1;
+		if (!pEnd->is_in)
+			goto fail;
+		if (tmp > pEnd->hw_ep->wMaxPacketSizeTx)
+			goto fail;
+
+		wIntrTxE |= (1 << bEnd);
+		musb_writew(pBase, MGC_O_HDRC_INTRTXE, wIntrTxE);
+
+		/* REVISIT if pThis->bBulkSplit, use by updating "tmp";
+		 * likewise high bandwidth periodic tx
+		 */
+		MGC_WriteCsr16(pBase, MGC_O_HDRC_TXMAXP, bEnd, tmp);
+
+		csr = MGC_M_TXCSR_MODE | MGC_M_TXCSR_CLRDATATOG
+				| MGC_M_TXCSR_FLUSHFIFO;
+		if (pEnd->type == USB_ENDPOINT_XFER_ISOC)
+			csr |= MGC_M_TXCSR_ISO;
+
+		/* set twice in case of double buffering */
+		MGC_WriteCsr16(pBase, MGC_O_HDRC_TXCSR, bEnd, csr);
+		MGC_WriteCsr16(pBase, MGC_O_HDRC_TXCSR, bEnd, csr);
+
+	} else {
+		u16 wIntrRxE = musb_readw(pBase, MGC_O_HDRC_INTRRXE);
+
+		if (pEnd->hw_ep->bIsSharedFifo)
+			pEnd->is_in = 0;
+		if (pEnd->is_in)
+			goto fail;
+		if (tmp > pEnd->hw_ep->wMaxPacketSizeRx)
+			goto fail;
+
+		wIntrRxE |= (1 << bEnd);
+		musb_writew(pBase, MGC_O_HDRC_INTRRXE, wIntrRxE);
+
+		/* REVISIT if pThis->bBulkCombine, use by updating "tmp"
+		 * likewise high bandwidth periodic rx
+		 */
+		MGC_WriteCsr16(pBase, MGC_O_HDRC_RXMAXP, bEnd, tmp);
+
+		/* force shared fifo to OUT-only mode */
+		if (pEnd->hw_ep->bIsSharedFifo) {
+			csr = musb_readw(pBase, MGC_O_HDRC_TXCSR);
+			csr &= ~(MGC_M_TXCSR_MODE | MGC_M_TXCSR_TXPKTRDY);
+			MGC_WriteCsr16(pBase, MGC_O_HDRC_TXCSR, bEnd, csr);
+		}
+
+		csr = MGC_M_RXCSR_FLUSHFIFO | MGC_M_RXCSR_CLRDATATOG;
+		if (pEnd->type == USB_ENDPOINT_XFER_ISOC)
+			csr |= MGC_M_RXCSR_P_ISO;
+		else if (pEnd->type == USB_ENDPOINT_XFER_INT)
+			csr |= MGC_M_RXCSR_DISNYET;
+
+		/* set twice in case of double buffering */
+		MGC_WriteCsr16(pBase, MGC_O_HDRC_RXCSR, bEnd, csr);
+		MGC_WriteCsr16(pBase, MGC_O_HDRC_RXCSR, bEnd, csr);
+	}
+
+	/* NOTE:  all the I/O code _should_ work fine without DMA, in case
+	 * for some reason you run out of channels here.
+	 */
+	if (is_dma_capable() && pThis->pDmaController) {
+		struct dma_controller	*c = pThis->pDmaController;
+
+#ifdef	DISABLE_RXDMA
+if (desc->bEndpointAddress & USB_DIR_IN) pEnd->dma = NULL; else
+#endif
+		pEnd->dma = c->pfDmaAllocateChannel(
+				c->pPrivateData,
+				bEnd, (desc->bEndpointAddress & USB_DIR_IN),
+				pEnd->type, pEnd->wPacketSize);
+	} else
+		pEnd->dma = NULL;
+
+	pEnd->desc = desc;
+	pEnd->busy = 0;
+	status = 0;
+
+	pr_debug("%s periph: enabled %s for %s %s, %smaxpacket %d\n",
+			musb_driver_name, pEnd->end_point.name,
+			({ char *s; switch (pEnd->type) {
+			 case USB_ENDPOINT_XFER_BULK:	s = "bulk"; break;
+			 case USB_ENDPOINT_XFER_INT:	s = "int"; break;
+			 default:			s = "iso"; break;
+			 }; s; }),
+			 pEnd->is_in ? "IN" : "OUT",
+			 pEnd->dma ? "dma, " : "",
+			 pEnd->wPacketSize);
+
+fail:
+	spin_unlock_irqrestore(&pThis->Lock, flags);
+	return status;
+}
+
+/*
+ * Disable an endpoint flushing all requests queued.
+ */
+static int musb_gadget_disable(struct usb_ep *ep)
+{
+	unsigned long	flags;
+	struct musb	*pThis;
+	u8		bEnd;
+	struct musb_ep	*pEnd;
+	int		status = 0;
+
+	pEnd = to_musb_ep(ep);
+	pThis = pEnd->pThis;
+	bEnd = pEnd->bEndNumber;
+
+	spin_lock_irqsave(&pThis->Lock, flags);
+	MGC_SelectEnd(pThis->pRegs, bEnd);
+
+	/* zero the endpoint sizes */
+	if (pEnd->is_in) {
+		u16 wIntrTxE = musb_readw(pThis->pRegs, MGC_O_HDRC_INTRTXE);
+		wIntrTxE &= ~(1 << bEnd);
+		musb_writew(pThis->pRegs, MGC_O_HDRC_INTRTXE, wIntrTxE);
+		MGC_WriteCsr16(pThis->pRegs, MGC_O_HDRC_TXMAXP, bEnd, 0);
+	} else {
+		u16 wIntrRxE = musb_readw(pThis->pRegs, MGC_O_HDRC_INTRRXE);
+		wIntrRxE &= ~(1 << bEnd);
+		musb_writew(pThis->pRegs, MGC_O_HDRC_INTRRXE, wIntrRxE);
+		MGC_WriteCsr16(pThis->pRegs, MGC_O_HDRC_RXMAXP, bEnd, 0);
+	}
+
+	pEnd->desc = NULL;
+
+	/* abort all pending DMA and requests */
+	nuke(pEnd, -ESHUTDOWN);
+
+	spin_unlock_irqrestore(&(pThis->Lock), flags);
+
+	DBG(2, "%s\n", pEnd->end_point.name);
+
+	return status;
+}
+
+/*
+ * Allocate a request for an endpoint.
+ * Reused by ep0 code.
+ */
+struct usb_request *musb_alloc_request(struct usb_ep *ep, gfp_t gfp_flags)
+{
+	struct musb_ep		*musb_ep = to_musb_ep(ep);
+	struct musb_request	*pRequest = NULL;
+
+	pRequest = kzalloc(sizeof *pRequest, gfp_flags);
+	if (pRequest) {
+		INIT_LIST_HEAD(&pRequest->request.list);
+		pRequest->request.dma = DMA_ADDR_INVALID;
+		pRequest->bEnd = musb_ep->bEndNumber;
+		pRequest->ep = musb_ep;
+	}
+
+	return &pRequest->request;
+}
+
+/*
+ * Free a request
+ * Reused by ep0 code.
+ */
+void musb_free_request(struct usb_ep *ep, struct usb_request *req)
+{
+	kfree(to_musb_request(req));
+}
+
+/*
+ * dma-coherent memory allocation (for dma-capable endpoints)
+ */
+static void *musb_gadget_alloc_buffer(struct usb_ep *ep, unsigned bytes,
+			    dma_addr_t * dma, gfp_t gfp_flags)
+{
+	struct musb_ep *musb_ep = to_musb_ep(ep);
+
+	return musb_alloc_buffer(musb_ep->pThis, bytes, gfp_flags, dma);
+}
+
+static void musb_gadget_free_buffer(struct usb_ep *ep,
+		void *address, dma_addr_t dma, unsigned bytes)
+{
+	struct musb_ep *musb_ep = to_musb_ep(ep);
+
+	musb_free_buffer(musb_ep->pThis, bytes, address, dma);
+}
+
+/*
+ * Context: controller locked, IRQs blocked.
+ */
+static void musb_ep_restart(struct musb *pThis, struct musb_request *req)
+{
+	DBG(3, "<== %s request %p on hw_ep%d\n",
+		req->bTx ? "TX/IN" : "RX/OUT",
+		&req->request, req->bEnd);
+
+	MGC_SelectEnd(pThis->pRegs, req->bEnd);
+	if (req->bTx) {
+		txstate(pThis, req);
+	} else {
+		rxstate(pThis, req);
+	}
+}
+
+static int musb_gadget_queue(struct usb_ep *ep, struct usb_request *req,
+			   gfp_t gfp_flags)
+{
+	struct musb_ep		*pEnd;
+	struct musb_request	*pRequest;
+	struct musb		*pThis;
+	int			status = 0;
+	unsigned long		lockflags;
+
+	if (!ep || !req)
+		return -EINVAL;
+
+	pEnd = to_musb_ep(ep);
+	pThis = pEnd->pThis;
+
+	pRequest = to_musb_request(req);
+	pRequest->musb = pThis;
+
+	if (pRequest->ep != pEnd)
+		return -EINVAL;
+
+	DBG(4, "<== to %s request=%p\n", ep->name, req);
+
+	/* request is mine now... */
+	pRequest->request.actual = 0;
+	pRequest->request.status = -EINPROGRESS;
+	pRequest->bEnd = pEnd->bEndNumber;
+	pRequest->bTx = pEnd->is_in;
+
+	if (is_dma_capable()
+			&& pRequest->request.dma == DMA_ADDR_INVALID
+			&& pRequest->request.length >= MIN_DMA_REQUEST
+			&& pEnd->dma) {
+		pRequest->request.dma = dma_map_single(pThis->controller,
+				pRequest->request.buf,
+				pRequest->request.length,
+				pRequest->bTx
+					? DMA_TO_DEVICE
+					: DMA_FROM_DEVICE);
+		pRequest->mapped = 1;
+	} else if (!req->buf) {
+		return -ENODATA;
+	} else
+		pRequest->mapped = 0;
+
+	spin_lock_irqsave(&pThis->Lock, lockflags);
+
+	/* don't queue if the ep is down */
+	if (!pEnd->desc) {
+		DBG(4, "req %p queued to %s while ep %s\n",
+				req, ep->name, "disabled");
+		status = -ESHUTDOWN;
+		goto cleanup;
+	}
+
+	/* add pRequest to the list */
+	list_add_tail(&(pRequest->request.list), &(pEnd->req_list));
+
+	/* it this is the head of the queue, start i/o ... */
+	if (!pEnd->busy && &pRequest->request.list == pEnd->req_list.next)
+		musb_ep_restart(pThis, pRequest);
+
+cleanup:
+	spin_unlock_irqrestore(&pThis->Lock, lockflags);
+	return status;
+}
+
+static int musb_gadget_dequeue(struct usb_ep *ep, struct usb_request *pRequest)
+{
+	struct musb_ep		*pEnd = to_musb_ep(ep);
+	struct usb_request	*r;
+	unsigned long		flags;
+	int			status = 0;
+
+	if (!ep || !pRequest || to_musb_request(pRequest)->ep != pEnd)
+		return -EINVAL;
+
+	spin_lock_irqsave(&pEnd->pThis->Lock, flags);
+
+	list_for_each_entry(r, &pEnd->req_list, list) {
+		if (r == pRequest)
+			break;
+	}
+	if (r != pRequest) {
+		DBG(3, "request %p not queued to %s\n", pRequest, ep->name);
+		status = -EINVAL;
+		goto done;
+	}
+
+	/* if the hardware doesn't have the request, easy ... */
+	if (pEnd->req_list.next != &pRequest->list || pEnd->busy)
+		musb_g_giveback(pEnd, pRequest, -ECONNRESET);
+
+	/* ... else abort the dma transfer ... */
+	else if (is_dma_capable() && pEnd->dma) {
+		struct dma_controller	*c = pEnd->pThis->pDmaController;
+
+		MGC_SelectEnd(pEnd->pThis->pRegs, pEnd->bEndNumber);
+		if (c->pfDmaAbortChannel)
+			status = c->pfDmaAbortChannel(pEnd->dma);
+		else
+			status = -EBUSY;
+		if (status == 0)
+			musb_g_giveback(pEnd, pRequest, -ECONNRESET);
+	} else {
+		/* NOTE: by sticking to easily tested hardware/driver states,
+		 * we leave counting of in-flight packets imprecise.
+		 */
+		musb_g_giveback(pEnd, pRequest, -ECONNRESET);
+	}
+
+done:
+	spin_unlock_irqrestore(&pEnd->pThis->Lock, flags);
+	return status;
+}
+
+/*
+ * Set or clear the halt bit of an endpoint. A halted enpoint won't tx/rx any
+ * data but will queue requests.
+ *
+ * exported to ep0 code
+ */
+int musb_gadget_set_halt(struct usb_ep *ep, int value)
+{
+	struct musb_ep		*pEnd;
+	u8			bEnd;
+	struct musb		*pThis;
+	void __iomem		*pBase;
+	unsigned long		flags;
+	u16			wCsr;
+	struct musb_request	*pRequest = NULL;
+	int			status = 0;
+
+	if (!ep)
+		return -EINVAL;
+
+	pEnd = to_musb_ep(ep);
+	bEnd = pEnd->bEndNumber;
+	pThis = pEnd->pThis;
+	pBase = pThis->pRegs;
+
+	spin_lock_irqsave(&pThis->Lock, flags);
+
+	if ((USB_ENDPOINT_XFER_ISOC == pEnd->type)) {
+		status = -EINVAL;
+		goto done;
+	}
+
+	MGC_SelectEnd(pBase, bEnd);
+
+	/* cannot portably stall with non-empty FIFO */
+	pRequest = to_musb_request(next_request(pEnd));
+	if (value && pEnd->is_in) {
+		wCsr = MGC_ReadCsr16(pBase, MGC_O_HDRC_TXCSR, bEnd);
+		if (wCsr & MGC_M_TXCSR_FIFONOTEMPTY) {
+			DBG(3, "%s fifo busy, cannot halt\n", ep->name);
+			spin_unlock_irqrestore(&pThis->Lock, flags);
+			return -EAGAIN;
+		}
+
+	}
+
+	/* set/clear the stall bit */
+	DBG(2, "%s: %s stall\n", ep->name, value ? "set" : "clear");
+	if (pEnd->is_in) {
+		wCsr = MGC_ReadCsr16(pBase, MGC_O_HDRC_TXCSR, bEnd);
+		if (value) {
+			wCsr |= MGC_M_TXCSR_P_SENDSTALL;
+		} else {
+			wCsr &= ~MGC_M_TXCSR_P_SENDSTALL;
+		}
+		wCsr &= ~MGC_M_TXCSR_TXPKTRDY;
+		MGC_WriteCsr16(pBase, MGC_O_HDRC_TXCSR, bEnd, wCsr);
+	} else {
+		wCsr = MGC_ReadCsr16(pBase, MGC_O_HDRC_RXCSR, bEnd);
+		if (value) {
+			wCsr |= MGC_M_RXCSR_P_SENDSTALL;
+		} else {
+			wCsr &= ~MGC_M_RXCSR_P_SENDSTALL;
+		}
+
+		MGC_WriteCsr16(pBase, MGC_O_HDRC_RXCSR, bEnd, wCsr);
+	}
+
+done:
+
+	/* maybe start the first request in the queue */
+	if (!pEnd->busy && !value && pRequest) {
+		DBG(3, "restarting the request\n");
+		musb_ep_restart(pThis, pRequest);
+	}
+
+	spin_unlock_irqrestore(&pThis->Lock, flags);
+	return status;
+}
+
+static int musb_gadget_fifo_status(struct usb_ep *ep)
+{
+	struct musb_ep		*musb_ep = to_musb_ep(ep);
+	int			retval = -EINVAL;
+
+	if (musb_ep->desc && !musb_ep->is_in) {
+		struct musb		*musb = musb_ep->pThis;
+		int			bEnd = musb_ep->bEndNumber;
+		void __iomem		*mbase = musb->pRegs;
+		unsigned long		flags;
+
+		spin_lock_irqsave(&musb->Lock, flags);
+
+		MGC_SelectEnd(mbase, bEnd);
+		/* FIXME return zero unless RXPKTRDY is set */
+		retval = MGC_ReadCsr16(mbase, MGC_O_HDRC_RXCOUNT, bEnd);
+
+		spin_unlock_irqrestore(&musb->Lock, flags);
+	}
+	return retval;
+}
+
+static void musb_gadget_fifo_flush(struct usb_ep *ep)
+{
+	struct musb_ep	*musb_ep = to_musb_ep(ep);
+	struct musb	*musb;
+	void __iomem	*mbase;
+	u8		nEnd;
+	unsigned long	flags;
+	u16		wCsr, wIntrTxE;
+
+	musb = musb_ep->pThis;
+	mbase = musb->pRegs;
+	nEnd = musb_ep->bEndNumber;
+
+	spin_lock_irqsave(&musb->Lock, flags);
+	MGC_SelectEnd(mbase, (u8) nEnd);
+
+	/* disable interrupts */
+	wIntrTxE = musb_readw(mbase, MGC_O_HDRC_INTRTXE);
+	musb_writew(mbase, MGC_O_HDRC_INTRTXE, wIntrTxE & ~(1 << nEnd));
+
+	if (musb_ep->is_in) {
+		wCsr = MGC_ReadCsr16(mbase, MGC_O_HDRC_TXCSR, nEnd);
+		wCsr |= MGC_M_TXCSR_FLUSHFIFO | MGC_M_TXCSR_P_WZC_BITS;
+		MGC_WriteCsr16(mbase, MGC_O_HDRC_TXCSR, nEnd, wCsr);
+		MGC_WriteCsr16(mbase, MGC_O_HDRC_TXCSR, nEnd, wCsr);
+	} else {
+		wCsr = MGC_ReadCsr16(mbase, MGC_O_HDRC_RXCSR, nEnd);
+		wCsr |= MGC_M_RXCSR_FLUSHFIFO | MGC_M_RXCSR_P_WZC_BITS;
+		MGC_WriteCsr16(mbase, MGC_O_HDRC_RXCSR, nEnd, wCsr);
+		MGC_WriteCsr16(mbase, MGC_O_HDRC_RXCSR, nEnd, wCsr);
+	}
+
+	/* re-enable interrupt */
+	musb_writew(mbase, MGC_O_HDRC_INTRTXE, wIntrTxE);
+	spin_unlock_irqrestore(&musb->Lock, flags);
+}
+
+static struct usb_ep_ops musb_ep_ops = {
+	.enable		= musb_gadget_enable,
+	.disable	= musb_gadget_disable,
+	.alloc_request	= musb_alloc_request,
+	.free_request	= musb_free_request,
+	.alloc_buffer	= musb_gadget_alloc_buffer,
+	.free_buffer	= musb_gadget_free_buffer,
+	.queue		= musb_gadget_queue,
+	.dequeue	= musb_gadget_dequeue,
+	.set_halt	= musb_gadget_set_halt,
+	.fifo_status	= musb_gadget_fifo_status,
+	.fifo_flush	= musb_gadget_fifo_flush
+};
+
+/***********************************************************************/
+
+static int musb_gadget_get_frame(struct usb_gadget *gadget)
+{
+	struct musb	*pThis = gadget_to_musb(gadget);
+
+	return (int)musb_readw(pThis->pRegs, MGC_O_HDRC_FRAME);
+}
+
+static int musb_gadget_wakeup(struct usb_gadget *gadget)
+{
+	struct musb	*musb = gadget_to_musb(gadget);
+	unsigned long	flags;
+	int		status = 0;
+	u8		power;
+
+	spin_lock_irqsave(&musb->Lock, flags);
+
+	switch (musb->xceiv.state) {
+	case OTG_STATE_B_PERIPHERAL:
+		/* FIXME if not suspended, fail */
+		if (musb->bMayWakeup)
+			break;
+		goto fail;
+	case OTG_STATE_B_IDLE:
+		/* REVISIT we might be able to do SRP even without OTG,
+		 * though Linux doesn't yet expose that capability
+		 */
+		if (is_otg_enabled(musb)) {
+			musb->xceiv.state = OTG_STATE_B_SRP_INIT;
+			break;
+		}
+		/* FALLTHROUGH */
+	default:
+fail:
+		status = -EINVAL;
+		goto done;
+	}
+
+	power = musb_readb(musb->pRegs, MGC_O_HDRC_POWER);
+	power |= MGC_M_POWER_RESUME;
+	musb_writeb(musb->pRegs, MGC_O_HDRC_POWER, power);
+
+	/* FIXME do this next chunk in a timer callback, no udelay */
+	mdelay(10);
+
+	power = musb_readb(musb->pRegs, MGC_O_HDRC_POWER);
+	power &= ~MGC_M_POWER_RESUME;
+	musb_writeb(musb->pRegs, MGC_O_HDRC_POWER, power);
+
+done:
+	spin_unlock_irqrestore(&musb->Lock, flags);
+	return status;
+}
+
+static int
+musb_gadget_set_self_powered(struct usb_gadget *gadget, int is_selfpowered)
+{
+	struct musb	*pThis = gadget_to_musb(gadget);
+
+	pThis->bIsSelfPowered = !!is_selfpowered;
+	return 0;
+}
+
+static void musb_pullup(struct musb *musb, int is_on)
+{
+	u8 power;
+
+	power = musb_readb(musb->pRegs, MGC_O_HDRC_POWER);
+	if (is_on)
+		power |= MGC_M_POWER_SOFTCONN;
+	else
+		power &= ~MGC_M_POWER_SOFTCONN;
+
+	/* FIXME if on, HdrcStart; if off, HdrcStop */
+
+	DBG(3, "gadget %s D+ pullup %s\n",
+	    musb->pGadgetDriver->function, is_on ? "on" : "off");
+	musb_writeb(musb->pRegs, MGC_O_HDRC_POWER, power);
+}
+
+#if 0
+static int musb_gadget_vbus_session(struct usb_gadget *gadget, int is_active)
+{
+	DBG(2, "<= %s =>\n", __FUNCTION__);
+
+	// FIXME iff driver's softconnect flag is set (as it is during probe,
+	// though that can clear it), just musb_pullup().
+
+	return -EINVAL;
+}
+
+static int musb_gadget_vbus_draw(struct usb_gadget *gadget, unsigned mA)
+{
+	/* FIXME -- delegate to otg_transciever logic */
+
+	DBG(2, "<= vbus_draw %u =>\n", mA);
+	return 0;
+}
+#endif
+
+static int musb_gadget_pullup(struct usb_gadget *gadget, int is_on)
+{
+	struct musb	*musb = gadget_to_musb(gadget);
+	unsigned long	flags;
+
+	is_on = !!is_on;
+
+	/* NOTE: this assumes we are sensing vbus; we'd rather
+	 * not pullup unless the B-session is active.
+	 */
+	spin_lock_irqsave(&musb->Lock, flags);
+	if (is_on != musb->softconnect) {
+		musb->softconnect = is_on;
+		musb_pullup(musb, is_on);
+	}
+	spin_unlock_irqrestore(&musb->Lock, flags);
+	return 0;
+}
+
+static struct usb_gadget_ops musb_gadget_operations = {
+	.get_frame		= musb_gadget_get_frame,
+	.wakeup			= musb_gadget_wakeup,
+	.set_selfpowered	= musb_gadget_set_self_powered,
+	//.vbus_session		= musb_gadget_vbus_session,
+	//.vbus_draw		= musb_gadget_vbus_draw,
+	.pullup			= musb_gadget_pullup,
+};
+
+/****************************************************************
+ * Registration operations
+ ****************************************************************/
+
+/* Only this registration code "knows" the rule (from USB standards)
+ * about there being only one external upstream port.  It assumes
+ * all peripheral ports are external...
+ */
+static struct musb *the_gadget;
+
+static void musb_gadget_release(struct device *dev)
+{
+	// kref_put(WHAT)
+	dev_dbg(dev, "%s\n", __FUNCTION__);
+}
+
+
+static void __init
+init_peripheral_ep(struct musb *musb, struct musb_ep *ep, u8 bEnd, int is_in)
+{
+	struct musb_hw_ep	*hw_ep = musb->aLocalEnd + bEnd;
+
+	memset(ep, 0, sizeof *ep);
+
+	ep->bEndNumber = bEnd;
+	ep->pThis = musb;
+	ep->hw_ep = hw_ep;
+	ep->is_in = is_in;
+
+	INIT_LIST_HEAD(&ep->req_list);
+
+	sprintf(ep->name, "ep%d%s", bEnd,
+			(!bEnd || hw_ep->bIsSharedFifo) ? "" : (
+				is_in ? "in" : "out"));
+	ep->end_point.name = ep->name;
+	INIT_LIST_HEAD(&ep->end_point.ep_list);
+	if (!bEnd) {
+		ep->end_point.maxpacket = 64;
+		ep->end_point.ops = &musb_g_ep0_ops;
+		musb->g.ep0 = &ep->end_point;
+	} else {
+		if (is_in)
+			ep->end_point.maxpacket = hw_ep->wMaxPacketSizeTx;
+		else
+			ep->end_point.maxpacket = hw_ep->wMaxPacketSizeRx;
+		ep->end_point.ops = &musb_ep_ops;
+		list_add_tail(&ep->end_point.ep_list, &musb->g.ep_list);
+	}
+	DBG(4, "periph: %s, maxpacket %d\n", ep->end_point.name,
+			ep->end_point.maxpacket);
+}
+
+/*
+ * Initialize the endpoints exposed to peripheral drivers, with backlinks
+ * to the rest of the driver state.
+ */
+static inline void __init musb_g_init_endpoints(struct musb *pThis)
+{
+	u8			bEnd;
+	struct musb_hw_ep	*hw_ep;
+	unsigned		count = 0;
+
+	/* intialize endpoint list just once */
+	INIT_LIST_HEAD(&(pThis->g.ep_list));
+
+	for (bEnd = 0, hw_ep = pThis->aLocalEnd;
+			bEnd < pThis->bEndCount;
+			bEnd++, hw_ep++) {
+		if (hw_ep->bIsSharedFifo /* || !bEnd */) {
+			init_peripheral_ep(pThis, &hw_ep->ep_in, bEnd, 0);
+			count++;
+		} else {
+			if (hw_ep->wMaxPacketSizeTx) {
+				init_peripheral_ep(pThis, &hw_ep->ep_in, bEnd, 1);
+				count++;
+			}
+			if (hw_ep->wMaxPacketSizeRx) {
+				init_peripheral_ep(pThis, &hw_ep->ep_out, bEnd, 0);
+				count++;
+			}
+		}
+	}
+	DBG(2, "initialized %d (max %d) endpoints\n", count,
+			pThis->bEndCount * 2 - 1);
+}
+
+/* called once during driver setup to initialize and link into
+ * the driver model; memory is zeroed.
+ */
+int __init musb_gadget_setup(struct musb *pThis)
+{
+	int status;
+
+	/* REVISIT minor race:  if (erroneously) setting up two
+	 * musb peripherals at the same time, only the bus lock
+	 * is probably held.
+	 */
+	if (the_gadget)
+		return -EBUSY;
+	the_gadget = pThis;
+
+	pThis->g.ops = &musb_gadget_operations;
+	pThis->g.is_dualspeed = 1;
+	pThis->g.speed = USB_SPEED_UNKNOWN;
+#ifdef CONFIG_USB_MUSB_OTG
+	if (pThis->board_mode == MUSB_OTG)
+		pThis->g.is_otg = 1;
+#endif
+
+	/* this "gadget" abstracts/virtualizes the controller */
+	strcpy(pThis->g.dev.bus_id, "gadget");
+	pThis->g.dev.parent = pThis->controller;
+	pThis->g.dev.dma_mask = pThis->controller->dma_mask;
+	pThis->g.dev.release = musb_gadget_release;
+	pThis->g.name = musb_driver_name;
+
+	musb_g_init_endpoints(pThis);
+
+	status = device_register(&pThis->g.dev);
+	if (status != 0)
+		the_gadget = NULL;
+	return status;
+}
+
+void musb_gadget_cleanup(struct musb *pThis)
+{
+	if (pThis != the_gadget)
+		return;
+
+	device_unregister(&pThis->g.dev);
+	the_gadget = NULL;
+}
+
+/*
+ * Register the gadget driver. Used by gadget drivers when
+ * registering themselves with the controller.
+ *
+ * -EINVAL something went wrong (not driver)
+ * -EBUSY another gadget is already using the controller
+ * -ENOMEM no memeory to perform the operation
+ *
+ * @param driver the gadget driver
+ * @return <0 if error, 0 if everything is fine
+ */
+int usb_gadget_register_driver(struct usb_gadget_driver *driver)
+{
+	int retval;
+	unsigned long flags;
+	struct musb *pThis = the_gadget;
+
+	if (!driver
+			|| driver->speed != USB_SPEED_HIGH
+	    		|| !driver->bind
+			|| !driver->unbind
+			|| !driver->setup)
+		return -EINVAL;
+
+	/* driver must be initialized to support peripheral mode */
+	if (!pThis || !(pThis->board_mode == MUSB_OTG
+				|| pThis->board_mode != MUSB_OTG)) {
+		DBG(1,"%s, no dev??\n", __FUNCTION__);
+		return -ENODEV;
+	}
+
+	DBG(3, "registering driver %s\n", driver->function);
+	spin_lock_irqsave(&pThis->Lock, flags);
+
+	if (pThis->pGadgetDriver) {
+		DBG(1, "%s is already bound to %s\n",
+				musb_driver_name,
+				pThis->pGadgetDriver->driver.name);
+		retval = -EBUSY;
+	} else {
+		pThis->pGadgetDriver = driver;
+		pThis->g.dev.driver = &driver->driver;
+		driver->driver.bus = NULL;
+		pThis->softconnect = 1;
+		retval = 0;
+	}
+
+	spin_unlock_irqrestore(&pThis->Lock, flags);
+
+	if (retval == 0)
+		retval = driver->bind(&pThis->g);
+	if (retval != 0) {
+		DBG(3, "bind to driver %s failed --> %d\n",
+		    driver->driver.name, retval);
+		pThis->pGadgetDriver = NULL;
+		pThis->g.dev.driver = NULL;
+	}
+
+	/* start peripheral and/or OTG engines */
+	if (retval == 0) {
+		spin_lock_irqsave(&pThis->Lock, flags);
+
+		/* REVISIT always use otg_set_peripheral(), handling
+		 * issues including the root hub one below ...
+		 */
+		pThis->xceiv.gadget = &pThis->g;
+		pThis->xceiv.state = OTG_STATE_B_IDLE;
+
+		/* FIXME this ignores the softconnect flag.  Drivers are
+		 * allowed hold the peripheral inactive until for example
+		 * userspace hooks up printer hardware or DSP codecs, so
+		 * hosts only see fully functional devices.
+		 */
+
+		musb_start(pThis);
+		spin_unlock_irqrestore(&pThis->Lock, flags);
+
+#ifdef CONFIG_USB_MUSB_OTG
+		if (pThis->board_mode == MUSB_OTG) {
+			DBG(3, "OTG startup...\n");
+
+			/* REVISIT:  funcall to other code, which also
+			 * handles power budgeting ... this way also
+			 * ensures HdrcStart is indirectly called.
+			 */
+			retval = usb_register_root_hub(
+					pThis->RootHub.pDevice,
+					pThis->g.dev.parent);
+			if (retval < 0) {
+				spin_lock_irqsave(&pThis->Lock, flags);
+				pThis->xceiv.gadget = NULL;
+				pThis->xceiv.state = OTG_STATE_UNDEFINED;
+				pThis->pGadgetDriver = NULL;
+				pThis->g.dev.driver = NULL;
+				spin_unlock_irqrestore(&pThis->Lock, flags);
+			}
+		}
+#endif
+	}
+
+	return retval;
+}
+EXPORT_SYMBOL(usb_gadget_register_driver);
+
+static void
+stop_activity(struct musb *musb, struct usb_gadget_driver *driver)
+{
+	int			i;
+	struct musb_hw_ep	*hw_ep;
+
+	/* don't disconnect if it's not connected */
+	if (musb->g.speed == USB_SPEED_UNKNOWN)
+		driver = NULL;
+	else
+		musb->g.speed = USB_SPEED_UNKNOWN;
+
+	/* deactivate the hardware */
+	if (musb->softconnect) {
+		musb->softconnect = 0;
+		musb_pullup(musb, 0);
+	}
+	musb_stop(musb);
+
+	/* killing any outstanding requests will quiesce the driver;
+	 * then report disconnect
+	 */
+	if (driver) {
+		for (i = 0, hw_ep = musb->aLocalEnd;
+				i < musb->bEndCount;
+				i++, hw_ep++) {
+			MGC_SelectEnd(musb->pRegs, i);
+			if (hw_ep->bIsSharedFifo /* || !bEnd */) {
+				nuke(&hw_ep->ep_in, -ESHUTDOWN);
+			} else {
+				if (hw_ep->wMaxPacketSizeTx)
+					nuke(&hw_ep->ep_in, -ESHUTDOWN);
+				if (hw_ep->wMaxPacketSizeRx)
+					nuke(&hw_ep->ep_out, -ESHUTDOWN);
+			}
+		}
+
+		spin_unlock(&musb->Lock);
+		driver->disconnect (&musb->g);
+		spin_lock(&musb->Lock);
+	}
+}
+
+/*
+ * Unregister the gadget driver. Used by gadget drivers when
+ * unregistering themselves from the controller.
+ *
+ * @param driver the gadget driver to unregister
+ */
+int usb_gadget_unregister_driver(struct usb_gadget_driver *driver)
+{
+	unsigned long	flags;
+	int		retval = 0;
+	struct musb	*pThis = the_gadget;
+
+	if (!driver || !pThis)
+		return -EINVAL;
+
+	/* REVISIT always use otg_set_peripheral() here too;
+	 * this needs to shut down the OTG engine.
+	 */
+
+	spin_lock_irqsave(&pThis->Lock, flags);
+	if (pThis->pGadgetDriver == driver) {
+		stop_activity(pThis, driver);
+
+		DBG(3, "unregistering driver %s\n", driver->function);
+		spin_unlock_irqrestore(&pThis->Lock, flags);
+		driver->unbind(&pThis->g);
+		spin_lock_irqsave(&pThis->Lock, flags);
+
+		pThis->pGadgetDriver = NULL;
+		pThis->g.dev.driver = NULL;
+	} else
+		retval = -EINVAL;
+
+	spin_unlock_irqrestore(&pThis->Lock, flags);
+	return retval;
+}
+EXPORT_SYMBOL(usb_gadget_unregister_driver);
+
+
+/***********************************************************************/
+
+/* lifecycle operations called through plat_uds.c */
+
+void musb_g_resume(struct musb *pThis)
+{
+	DBG(4, "<==\n");
+	if (pThis->pGadgetDriver && pThis->pGadgetDriver->resume) {
+		spin_unlock(&pThis->Lock);
+		pThis->pGadgetDriver->resume(&pThis->g);
+		spin_lock(&pThis->Lock);
+	}
+}
+
+/* called when SOF packets stop for 3+ msec */
+void musb_g_suspend(struct musb *pThis)
+{
+	u8	devctl;
+
+	devctl = musb_readb(pThis->pRegs, MGC_O_HDRC_DEVCTL);
+	DBG(3, "devctl %02x\n", devctl);
+
+	switch (pThis->xceiv.state) {
+	case OTG_STATE_B_IDLE:
+		if ((devctl & MGC_M_DEVCTL_VBUS) == MGC_M_DEVCTL_VBUS)
+			pThis->xceiv.state = OTG_STATE_B_PERIPHERAL;
+		break;
+	case OTG_STATE_B_PERIPHERAL:
+		if (pThis->pGadgetDriver && pThis->pGadgetDriver->suspend) {
+			spin_unlock(&pThis->Lock);
+			pThis->pGadgetDriver->suspend(&pThis->g);
+			spin_lock(&pThis->Lock);
+		}
+		break;
+	default:
+		/* REVISIT if B_HOST, clear DEVCTL.HOSTREQ;
+		 * A_PERIPHERAL may need care too
+		 */
+		WARN("unhandled SUSPEND transition (%d)\n", pThis->xceiv.state);
+	}
+}
+
+/* called when VBUS drops below session threshold, and in other cases */
+void musb_g_disconnect(struct musb *pThis)
+{
+	DBG(3, "devctl %02x\n", musb_readb(pThis->pRegs, MGC_O_HDRC_DEVCTL));
+
+	pThis->g.speed = USB_SPEED_UNKNOWN;
+	if (pThis->pGadgetDriver && pThis->pGadgetDriver->disconnect) {
+		spin_unlock(&pThis->Lock);
+		pThis->pGadgetDriver->disconnect(&pThis->g);
+		spin_lock(&pThis->Lock);
+	}
+
+	switch (pThis->xceiv.state) {
+	default:
+#ifdef	CONFIG_USB_MUSB_OTG
+		pThis->xceiv.state = OTG_STATE_A_IDLE;
+		break;
+	case OTG_STATE_B_WAIT_ACON:
+	case OTG_STATE_B_HOST:
+#endif
+	case OTG_STATE_B_PERIPHERAL:
+		pThis->xceiv.state = OTG_STATE_B_IDLE;
+		break;
+	case OTG_STATE_B_SRP_INIT:
+		break;
+	}
+}
+
+void musb_g_reset(struct musb *pThis)
+__releases(pThis->Lock)
+__acquires(pThis->Lock)
+{
+	void __iomem	*pBase = pThis->pRegs;
+	u8		devctl = musb_readb(pBase, MGC_O_HDRC_DEVCTL);
+	u8		power;
+
+	DBG(3, "<== %s addr=%x driver '%s'\n",
+			(devctl & MGC_M_DEVCTL_BDEVICE)
+				? "B-Device" : "A-Device",
+			musb_readb(pBase, MGC_O_HDRC_FADDR),
+			pThis->pGadgetDriver
+				? pThis->pGadgetDriver->driver.name
+				: NULL
+			);
+
+	/* HR does NOT clear itself */
+	if (devctl & MGC_M_DEVCTL_HR)
+		musb_writeb(pBase, MGC_O_HDRC_DEVCTL, MGC_M_DEVCTL_SESSION);
+
+	/* report disconnect, if we didn't already (flushing EP state) */
+	if (pThis->g.speed != USB_SPEED_UNKNOWN)
+		 musb_g_disconnect(pThis);
+
+	/* what speed did we negotiate? */
+	power = musb_readb(pBase, MGC_O_HDRC_POWER);
+	pThis->g.speed = (power & MGC_M_POWER_HSMODE)
+			? USB_SPEED_HIGH : USB_SPEED_FULL;
+
+	/* start in USB_STATE_DEFAULT */
+	MUSB_DEV_MODE(pThis);
+	pThis->bAddress = 0;
+	pThis->ep0_state = MGC_END0_STAGE_SETUP;
+
+	pThis->bMayWakeup = 0;
+	pThis->g.b_hnp_enable = 0;
+	pThis->g.a_alt_hnp_support = 0;
+	pThis->g.a_hnp_support = 0;
+
+	/* Normal reset, as B-Device;
+	 * or else after HNP, as A-Device
+	 */
+	if (devctl & MGC_M_DEVCTL_BDEVICE) {
+		pThis->xceiv.state = OTG_STATE_B_PERIPHERAL;
+		pThis->g.is_a_peripheral = 0;
+	} else if (is_otg_enabled(pThis) && pThis->board_mode == MUSB_OTG) {
+		pThis->xceiv.state = OTG_STATE_A_PERIPHERAL;
+		pThis->g.is_a_peripheral = 1;
+	} else
+		WARN_ON(1);
+}
Index: linux-2.6.10/drivers/usb/musb/musb_gadget.h
===================================================================
--- /dev/null
+++ linux-2.6.10/drivers/usb/musb/musb_gadget.h
@@ -0,0 +1,106 @@
+/******************************************************************
+ * Copyright 2005 Mentor Graphics Corporation
+ * Copyright (C) 2005-2006 by Texas Instruments
+ *
+ * This file is part of the Inventra Controller Driver for Linux.
+ *
+ * The Inventra Controller Driver for Linux is free software; you
+ * can redistribute it and/or modify it under the terms of the GNU
+ * General Public License version 2 as published by the Free Software
+ * Foundation.
+ *
+ * The Inventra Controller Driver for Linux is distributed in
+ * the hope that it will be useful, but WITHOUT ANY WARRANTY;
+ * without even the implied warranty of MERCHANTABILITY or
+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public
+ * License for more details.
+ *
+ * You should have received a copy of the GNU General Public License
+ * along with The Inventra Controller Driver for Linux ; if not,
+ * write to the Free Software Foundation, Inc., 59 Temple Place,
+ * Suite 330, Boston, MA  02111-1307  USA
+ *
+ * ANY DOWNLOAD, USE, REPRODUCTION, MODIFICATION OR DISTRIBUTION
+ * OF THIS DRIVER INDICATES YOUR COMPLETE AND UNCONDITIONAL ACCEPTANCE
+ * OF THOSE TERMS.THIS DRIVER IS PROVIDED "AS IS" AND MENTOR GRAPHICS
+ * MAKES NO WARRANTIES, EXPRESS OR IMPLIED, RELATED TO THIS DRIVER.
+ * MENTOR GRAPHICS SPECIFICALLY DISCLAIMS ALL IMPLIED WARRANTIES
+ * OF MERCHANTABILITY; FITNESS FOR A PARTICULAR PURPOSE AND
+ * NON-INFRINGEMENT.  MENTOR GRAPHICS DOES NOT PROVIDE SUPPORT
+ * SERVICES OR UPDATES FOR THIS DRIVER, EVEN IF YOU ARE A MENTOR
+ * GRAPHICS SUPPORT CUSTOMER.
+ ******************************************************************/
+
+#ifndef __MUSB_GADGET_H
+#define __MUSB_GADGET_H
+
+struct musb_request {
+	struct usb_request	request;
+	struct musb_ep		*ep;
+	struct musb		*musb;
+	u8 bTx;			/* endpoint direction */
+	u8 bEnd;
+	u8 mapped;
+};
+
+static inline struct musb_request *to_musb_request(struct usb_request *req)
+{
+	return req ? container_of(req, struct musb_request, request) : NULL;
+}
+
+extern struct usb_request *
+musb_alloc_request(struct usb_ep *ep, gfp_t gfp_flags);
+extern void musb_free_request(struct usb_ep *ep, struct usb_request *req);
+
+
+/*
+ * struct musb_ep - peripheral side view of endpoint rx or tx side
+ */
+struct musb_ep {
+	/* stuff towards the head is basically write-once. */
+	struct usb_ep			end_point;
+	char				name[12];
+	struct musb_hw_ep		*hw_ep;
+	struct musb			*pThis;
+	u8				bEndNumber;
+
+	/* ... when enabled/disabled ... */
+	u8				type;
+	u8				is_in;
+	u16				wPacketSize;
+	const struct usb_endpoint_descriptor	*desc;
+	struct dma_channel		*dma;
+
+	/* later things are modified based on usage */
+	struct list_head		req_list;
+
+	u8				busy;
+};
+
+static inline struct musb_ep *to_musb_ep(struct usb_ep *ep)
+{
+	return ep ? container_of(ep, struct musb_ep, end_point) : NULL;
+}
+
+static inline struct usb_request *next_request(struct musb_ep *ep)
+{
+	struct list_head	*queue = &ep->req_list;
+
+	if (list_empty(queue))
+		return NULL;
+	return container_of(queue->next, struct usb_request, list);
+}
+
+extern void musb_g_tx(struct musb *pThis, u8 bEnd);
+extern void musb_g_rx(struct musb *pThis, u8 bEnd);
+
+extern struct usb_ep_ops musb_g_ep0_ops;
+
+extern int musb_gadget_setup(struct musb *);
+extern void musb_gadget_cleanup(struct musb *);
+
+extern void musb_g_giveback(struct musb_ep *, struct usb_request *, int);
+
+extern int musb_gadget_set_halt(struct usb_ep *ep, int value);
+
+#endif		/* __MUSB_GADGET_H */
Index: linux-2.6.10/drivers/usb/musb/musb_host.c
===================================================================
--- /dev/null
+++ linux-2.6.10/drivers/usb/musb/musb_host.c
@@ -0,0 +1,2146 @@
+/******************************************************************
+ * Copyright 2005 Mentor Graphics Corporation
+ * Copyright (C) 2005-2006 by Texas Instruments
+ *
+ * This file is part of the Inventra Controller Driver for Linux.
+ *
+ * The Inventra Controller Driver for Linux is free software; you
+ * can redistribute it and/or modify it under the terms of the GNU
+ * General Public License version 2 as published by the Free Software
+ * Foundation.
+ *
+ * The Inventra Controller Driver for Linux is distributed in
+ * the hope that it will be useful, but WITHOUT ANY WARRANTY;
+ * without even the implied warranty of MERCHANTABILITY or
+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public
+ * License for more details.
+ *
+ * You should have received a copy of the GNU General Public License
+ * along with The Inventra Controller Driver for Linux ; if not,
+ * write to the Free Software Foundation, Inc., 59 Temple Place,
+ * Suite 330, Boston, MA  02111-1307  USA
+ *
+ * ANY DOWNLOAD, USE, REPRODUCTION, MODIFICATION OR DISTRIBUTION
+ * OF THIS DRIVER INDICATES YOUR COMPLETE AND UNCONDITIONAL ACCEPTANCE
+ * OF THOSE TERMS.THIS DRIVER IS PROVIDED "AS IS" AND MENTOR GRAPHICS
+ * MAKES NO WARRANTIES, EXPRESS OR IMPLIED, RELATED TO THIS DRIVER.
+ * MENTOR GRAPHICS SPECIFICALLY DISCLAIMS ALL IMPLIED WARRANTIES
+ * OF MERCHANTABILITY; FITNESS FOR A PARTICULAR PURPOSE AND
+ * NON-INFRINGEMENT.  MENTOR GRAPHICS DOES NOT PROVIDE SUPPORT
+ * SERVICES OR UPDATES FOR THIS DRIVER, EVEN IF YOU ARE A MENTOR
+ * GRAPHICS SUPPORT CUSTOMER.
+ ******************************************************************/
+
+#include <linux/config.h>
+#include <linux/module.h>
+#include <linux/pci.h>
+#include <linux/kernel.h>
+#include <linux/delay.h>
+#include <linux/sched.h>
+#include <linux/slab.h>
+#include <linux/errno.h>
+#include <linux/init.h>
+#include <linux/list.h>
+#include <linux/usb.h>
+
+#include "../core/hcd.h"
+
+#include "musbdefs.h"
+#include "musb_host.h"
+
+
+/* MUSB HOST status 9-mar-2006
+ *
+ * - PIO mostly behaved when last tested.  Error paths are all over the map
+ *   though, there's lots of partially duplicated code ... the cleanup code
+ *   itself needs to be cleaned up!
+ *
+ * - DMA (CPPI) ... mostly behaves, but not as quickly as expected by
+ *   comparison with other high speed hosts.
+ *     + RX, sometimes reqpkt seems to misbehave so that a packet from
+ *	 a second URB (e.g. mass storage status) gets read too early
+ *     + TX, no known issues
+ *
+ * - Still no traffic scheduling code to make NAKing for bulk or control
+ *   transfers unable to starve other requests; or to make efficient use
+ *   of hardware with periodic transfers.  (Note that network drivers
+ *   commonly post bulk reads that stay pending for a long time; these
+ *   would make very visible trouble.)
+ *
+ * - Host side doesn't understand that endpoint hardware has two directions.
+ */
+
+
+/*
+ * NOTE on endpoint usage:
+ *
+ * CONTROL transfers all go through ep0.  BULK ones go through dedicated IN
+ * and OUT endpoints ... hardware is dedicated for those "async" queue(s).
+ *
+ * (Yes, bulk _could_ use more of the endpoints than that, and would even
+ * benefit from it ... one remote device may easily be NAKing while others
+ * need to perform transfers in that same direction.)
+ *
+ * INTERUPPT and ISOCHRONOUS transfers are scheduled to the other endpoints.
+ * So far that scheduling is both dumb and optimistic:  the endpoint will be
+ * "claimed" until its software queue is no longer refilled.  No multiplexing
+ * of transfers between endpoints, or anything clever.
+ */
+
+
+/*************************** Forwards ***************************/
+
+static void musb_ep_program(struct musb *pThis, u8 bEnd,
+			       struct urb *pUrb, unsigned int nOut,
+			       u8 * pBuffer, u32 dwLength);
+
+/*
+ * Start transmit. Caller is responsible for locking shared resources.
+ * pThis must be locked.
+ *
+ * @param pThis instance pointer
+ * @param bEnd local endpoint
+ */
+void MGC_HdrcStartTx(struct musb *pThis, u8 bEnd)
+{
+	u16 wCsr;
+	void __iomem *pBase = pThis->pRegs;
+
+	/* NOTE: no locks here; caller should lock */
+	MGC_SelectEnd(pBase, bEnd);
+	if (bEnd) {
+		wCsr = MGC_ReadCsr16(pBase, MGC_O_HDRC_TXCSR, bEnd);
+		wCsr |= MGC_M_TXCSR_TXPKTRDY | MGC_M_TXCSR_H_WZC_BITS;
+		DBG(5, "Writing TXCSR%d = %x\n", bEnd, wCsr);
+		MGC_WriteCsr16(pBase, MGC_O_HDRC_TXCSR, bEnd, wCsr);
+	} else {
+		wCsr = MGC_M_CSR0_H_SETUPPKT | MGC_M_CSR0_TXPKTRDY;
+		MGC_WriteCsr16(pBase, MGC_O_HDRC_CSR0, 0, wCsr);
+	}
+
+}
+
+/*
+ *   Enable DmareqEnab in TxCSr
+ *
+ *   @param pThis instance pointer
+ *   @param bEnd  local endpoint
+ */
+void MGC_HdrcEnableTXDMA(struct musb *pThis, u8 bEnd)
+{
+	void __iomem *pBase = pThis->pRegs;
+	u16 txCsr;
+
+	/* NOTE: no locks here; caller should lock */
+	MGC_SelectEnd(pBase, bEnd);
+	txCsr = MGC_ReadCsr16(pBase, MGC_O_HDRC_TXCSR, bEnd);
+	txCsr |= MGC_M_TXCSR_DMAENAB | MGC_M_TXCSR_H_WZC_BITS;
+	MGC_WriteCsr16(pBase, MGC_O_HDRC_TXCSR, bEnd, txCsr);
+}
+
+/*
+ * Start the URB at the front of an endpoint's queue
+ * end must be claimed from the caller.
+ *
+ * Context: controller locked, irqs blocked
+ *
+ * FIXME caller should specify rx or tx
+ */
+static void musb_start_urb(struct musb *pThis, struct musb_hw_ep *pEnd)
+{
+	u16			wFrame;
+	u32			dwLength;
+	void			*pBuffer;
+	void __iomem		*pBase =  pThis->pRegs;
+	struct urb		*pUrb = MGC_GetCurrentUrb(pEnd);
+	unsigned 		nPipe = pUrb->pipe;
+	unsigned 		is_out = usb_pipeout(nPipe);
+	u8			bAddress = usb_pipedevice(nPipe);
+	u8			bRemoteEnd = usb_pipeendpoint(nPipe);
+	u16			wPacketSize;
+	int			bEnd = pEnd->bLocalEnd;
+
+	wPacketSize = usb_maxpacket(pUrb->dev, nPipe, is_out);
+
+	/* remember software state */
+	pEnd->dwOffset = 0;
+	pEnd->dwRequestSize = 0;
+	pEnd->dwIsoPacket = 0;
+	pEnd->dwWaitFrame = 0;
+
+	/* REVISIT distinguish tx and rx sides properly */
+	pEnd->wPacketSize = wPacketSize;
+	pEnd->bAddress = bAddress;
+	pEnd->bEnd = bRemoteEnd;
+	pEnd->bTrafficType = (u8) usb_pipetype(nPipe);
+
+	/* end must be claimed from my caller */
+
+	if (usb_pipecontrol(nPipe)) {
+		/* control transfers always start with an OUT */
+		is_out = 1;
+		pThis->bEnd0Stage = MGC_END0_START;
+	}
+
+	/* gather right source of data */
+	if (usb_pipeisoc(nPipe)) {
+		pBuffer =
+		    pUrb->transfer_buffer + pUrb->iso_frame_desc[0].offset;
+		dwLength = pUrb->iso_frame_desc[0].length;
+	} else if (usb_pipecontrol(nPipe)) {
+		pBuffer = pUrb->setup_packet;
+		dwLength = 8;
+	} else {
+		/* - */
+		pBuffer = pUrb->transfer_buffer;
+		dwLength = pUrb->transfer_buffer_length;
+	}
+
+	DBG(4, "urb %p: ep%d%s, type %d, max %d, addr %d, buffer %p len %u\n",
+			pUrb, bRemoteEnd, (is_out) ? "out" : "in",
+			usb_pipetype(nPipe), wPacketSize, bAddress,
+			pBuffer, dwLength);
+
+	/* Configure endpoint */
+	musb_ep_program(pThis, bEnd, pUrb, is_out, pBuffer, dwLength);
+
+	/* transmit may have more work: start it when it is time */
+	if (!is_out)
+		return;
+
+	/* TODO: with CPPI DMA, once DMA is setup and DmaReqEnable in TxCSR
+	 * is set (which is the case) transfer is initiated. For periodic
+	 * transfer support, add another field in pEnd struct which will
+	 * serve as a flag. If CPPI DMA is programmed for the transfer set
+	 * this flag and disable DMAReqEnab while programming TxCSR in
+	 * programEnd() Once we reach the appropriate time, enable DMA Req
+	 * instead of calling StartTx() function
+	 */
+
+	/* FIXME split out dma and non-dma paths properly ...
+	 * need a good test for "using dma"; dma enable in csr SHOULD be clear
+	 * here though we might have fallen back to PIO.
+	 */
+
+	/* determine if the time is right for a periodic transfer */
+	if (usb_pipeisoc(nPipe) || usb_pipeint(nPipe)) {
+		DBG(3, "check whether there's still time for periodic Tx\n");
+		pEnd->dwIsoPacket = 0;
+		wFrame = musb_readw(pBase, MGC_O_HDRC_FRAME);
+		/* FIXME this doesn't implement that scheduling policy ...
+		 * or handle framecounter wrapping
+		 */
+		if ((pUrb->transfer_flags & URB_ISO_ASAP)
+				|| (wFrame >= pUrb->start_frame)) {
+			/* REVISIT the SOF irq handler shouldn't duplicate
+			 * this code... or the branch below...
+			 */
+			pEnd->dwWaitFrame = 0;
+			printk("Start --> periodic TX%s on %d\n",
+				pEnd->pDmaChannel ? " DMA" : "",
+				bEnd);
+			if (!pEnd->pDmaChannel)
+				MGC_HdrcStartTx(pThis, bEnd);
+			else
+				MGC_HdrcEnableTXDMA(pThis, bEnd);
+		} else {
+			pEnd->dwWaitFrame = pUrb->start_frame;
+			/* enable SOF interrupt so we can count down */
+DBG(1,"SOF for %d\n", bEnd);
+#if 1 // ifndef	CONFIG_ARCH_DAVINCI
+			musb_writeb(pBase, MGC_O_HDRC_INTRUSBE, 0xff);
+#endif
+		}
+	} else {
+		DBG(4, "Start TX%d %s\n", bEnd,
+			pEnd->pDmaChannel ? "dma" : "pio");
+
+		if (!pEnd->pDmaChannel)
+			MGC_HdrcStartTx(pThis, bEnd);
+		else
+			MGC_HdrcEnableTXDMA(pThis, bEnd);
+	}
+}
+
+/* caller owns no controller locks, irqs are blocked */
+static inline void
+__musb_giveback(struct urb *urb, int status)
+{
+	const struct musb_hw_ep		*hw_ep = urb->hcpriv;
+
+	if ((urb->transfer_flags & URB_SHORT_NOT_OK)
+			&& (urb->actual_length < urb->transfer_buffer_length)
+			&& status == 0
+			&& usb_pipein(urb->pipe))
+		status = -EREMOTEIO;
+
+	spin_lock(&urb->lock);
+	//list_del(&urb->urb_list);
+	list_del_init(&urb->urb_list);
+	urb->hcpriv = NULL;
+	if (urb->status == -EINPROGRESS)
+		urb->status = status;
+	spin_unlock(&urb->lock);
+
+	DBG(({ int level; switch (urb->status) {
+				case 0:
+					level = 4;
+					break;
+				/* common/boring faults */
+				case -EREMOTEIO:
+				case -ESHUTDOWN:
+				case -EPIPE:
+					level = 3;
+					break;
+				default:
+					level = 2;
+					break;
+				}; level; }),
+			"complete %p (%d), dev%d ep%d%s, %d/%d\n",
+			urb, urb->status,
+			usb_pipedevice(urb->pipe),
+			usb_pipeendpoint(urb->pipe),
+			usb_pipein(urb->pipe) ? "in" : "out",
+			urb->actual_length, urb->transfer_buffer_length
+			);
+
+	/* teardown DMA mapping, if needed (does dcache sync) */
+	if (is_dma_capable()
+			&& hw_ep->musb->controller->dma_mask
+			&& urb->transfer_buffer_length != 0
+			&& !(urb->transfer_flags & URB_NO_TRANSFER_DMA_MAP)) {
+		dma_unmap_single(hw_ep->musb->controller, urb->transfer_dma,
+				urb->transfer_buffer_length,
+				usb_pipein(urb->pipe)
+					? DMA_FROM_DEVICE
+					: DMA_TO_DEVICE);
+		/* REVISIT record whether we mapped it;
+		 * and if we did, on pio fallback paths
+		 * it might be good to unmap it EARLY
+		 * (lest our writes to dcache get lost)
+		 */
+	}
+
+	/* completion handler may reenter this hcd; periodic transfers
+	 * are normally resubmitted during the callback.
+	 *
+	 * FIXME: make this use hcd framework giveback, so we don't use
+	 * the usbcore-internal wakeup queue...
+	 */
+	usb_put_dev(urb->dev);
+	urb->complete(urb, hw_ep->musb->int_regs);
+	atomic_dec(&urb->use_count);
+	if (urb->reject)
+		wake_up(&usb_kill_urb_queue);
+	usb_put_urb(urb);
+}
+
+/* for non-iso endpoints only */
+static inline void musb_save_toggle(struct musb_hw_ep *ep, struct urb *urb)
+{
+	struct usb_device	*udev = urb->dev;
+	u16			csr;
+	void __iomem		*hw = ep->musb->pRegs;
+
+	ep->bIsReady = FALSE;
+	if (usb_pipeout(urb->pipe)) {
+		csr = MGC_ReadCsr16(hw, MGC_O_HDRC_TXCSR,
+				ep->bLocalEnd);
+		usb_settoggle(udev, ep->bEnd, 1,
+			(csr & MGC_M_TXCSR_H_DATATOGGLE)
+				? 1 : 0);
+	} else {
+		csr = MGC_ReadCsr16(hw, MGC_O_HDRC_RXCSR,
+				ep->bLocalEnd);
+		usb_settoggle(udev, ep->bEnd, 0,
+			(csr & MGC_M_RXCSR_H_DATATOGGLE)
+				? 1 : 0);
+	}
+}
+
+// REVISIT need to handle both rx and tx paths for each hw_ep...
+
+/* caller owns controller lock, irqs are blocked */
+static void musb_giveback(struct musb_hw_ep *ep, struct urb *urb, int status)
+__releases(ep->musb->Lock)
+__acquires(ep->musb->Lock)
+{
+	int			is_in;
+	u8			busy;
+	u8			type;
+
+	if (ep->bIsSharedFifo)
+		is_in = 1;
+	else
+		is_in = usb_pipein(urb->pipe);
+	type = is_in ? ep->in_traffic_type : ep->out_traffic_type;
+
+	/* save toggle eagerly, for paranoia */
+	switch (type) {
+	case PIPE_BULK:
+	case PIPE_INTERRUPT:
+		musb_save_toggle(ep, urb);
+	}
+
+	if (is_in) {
+		busy = ep->in_busy;
+		ep->in_busy = 1;
+	} else {
+		busy = ep->out_busy;
+		ep->out_busy = 1;
+	}
+	spin_unlock(&ep->musb->Lock);
+
+	__musb_giveback(urb, status);
+
+	spin_lock(&ep->musb->Lock);
+	if (is_in)
+		ep->in_busy = busy;
+	else
+		ep->out_busy = busy;
+
+	/* reclaim resources (and bandwidth) ASAP */
+	if (list_empty(&ep->urb_list)) {
+		switch (type) {
+		case PIPE_ISOCHRONOUS:
+		case PIPE_INTERRUPT:
+			/* this is where periodic bandwidth should be
+			 * de-allocated if its tracked and allocated.
+			 */
+			ep->bIsClaimed = FALSE;
+			ep->bIsReady = FALSE;
+			break;
+		}
+	}
+}
+
+/*
+ * Advance this endpoint's queue, completing the URB at list head.
+ * Then start the next URB, if there is one.
+ *
+ * @pThis: instance pointer
+ * @bEnd: local endpoint
+ * Context: caller owns controller lock, irqs are blocked
+ */
+static void
+musb_advance_urb_queue(struct musb *pThis, struct urb *urb,
+		struct musb_hw_ep *pEnd, int is_in)
+{
+	if (urb)
+		musb_giveback(pEnd, urb, 0);
+	if (!list_empty(&pEnd->urb_list)) {
+		DBG(4, "... next ep%d %cX urb %p\n",
+				pEnd->bLocalEnd, is_in ? 'R' : 'T',
+				// next_in_urb() or next_out_urb()
+				MGC_GetCurrentUrb(pEnd));
+		musb_start_urb(pThis, pEnd);
+	}
+}
+
+
+/*
+ * Receive a packet (or part of it).
+ * @requires pThis->Lock locked
+ * @return TRUE if URB is complete
+ */
+static u8 musb_host_packet_rx(struct musb *pThis, struct urb *pUrb,
+		u8 bEnd, u8 bIsochError)
+{
+	u16 wRxCount;
+	u16 wLength;
+	u8 *pBuffer;
+	u16 wCsr;
+	u8 bDone = FALSE;
+	void __iomem		*pBase = pThis->pRegs;
+	struct musb_hw_ep	*pEnd = &(pThis->aLocalEnd[bEnd]);
+	int			nPipe = pUrb->pipe;
+	void			*buffer = pUrb->transfer_buffer;
+
+	// MGC_SelectEnd(pBase, bEnd);
+	wRxCount = MGC_ReadCsr16(pBase, MGC_O_HDRC_RXCOUNT, bEnd);
+	DBG(3, "RX%d count %d, buffer %p len %d/%d\n", bEnd, wRxCount,
+			pUrb->transfer_buffer, pEnd->dwOffset,
+			pUrb->transfer_buffer_length);
+
+	/* unload FIFO */
+	if (usb_pipeisoc(nPipe)) {
+		/* isoch case */
+		pBuffer =
+		    buffer + pUrb->iso_frame_desc[pEnd->dwIsoPacket].offset;
+		wLength =
+		    min((unsigned int)wRxCount,
+			pUrb->iso_frame_desc[pEnd->dwIsoPacket].length);
+		pUrb->actual_length += wLength;
+		/* update actual & status */
+		pUrb->iso_frame_desc[pEnd->dwIsoPacket].actual_length = wLength;
+		if (bIsochError) {
+			pUrb->iso_frame_desc[pEnd->dwIsoPacket].status =
+			    -EILSEQ;
+			pUrb->error_count++;
+		} else {
+			pUrb->iso_frame_desc[pEnd->dwIsoPacket].status = 0;
+		}
+
+		/* see if we are done */
+		bDone = (++pEnd->dwIsoPacket >= pUrb->number_of_packets);
+	} else {
+		/* non-isoch */
+		pBuffer = buffer + pEnd->dwOffset;
+		wLength = min((unsigned int)wRxCount,
+			      pUrb->transfer_buffer_length - pEnd->dwOffset);
+		pUrb->actual_length += wLength;
+		pEnd->dwOffset += wLength;
+
+		/* see if we are done */
+		bDone = (pEnd->dwOffset >= pUrb->transfer_buffer_length) ||
+		    (wRxCount < pEnd->wPacketSize);
+	}
+
+	musb_read_fifo(pEnd, wLength, pBuffer);
+
+	if (wRxCount <= wLength) {
+		wCsr = MGC_ReadCsr16(pBase, MGC_O_HDRC_RXCSR, bEnd);
+		wCsr |= MGC_M_RXCSR_H_WZC_BITS;
+		MGC_WriteCsr16(pBase, MGC_O_HDRC_RXCSR, bEnd,
+			       wCsr & ~MGC_M_RXCSR_RXPKTRDY);
+	}
+
+	return bDone;
+}
+
+
+/*
+ * Program an HDRC endpoint as per the given URB
+ * @pThis: instance pointer
+ * @bEnd: local endpoint
+ * @pURB: URB pointer
+ * @is_out: zero for Rx; non-zero for Tx
+ * @pBuffer: buffer pointer
+ * @dwLength: how many bytes to transmit or expect to receive
+ * Context: irqs blocked, controller lock held
+ */
+static void musb_ep_program(struct musb *pThis, u8 bEnd,
+			       struct urb *pUrb, unsigned int is_out,
+			       u8 * pBuffer, u32 dwLength)
+{
+	u16 wCsr, wLoadCount, wIntrTxE;
+	struct usb_device *pParent;
+#ifndef	CONFIG_USB_INVENTRA_FIFO
+	struct dma_controller *pDmaController;
+	struct dma_channel *pDmaChannel;
+	u8 bDmaOk;
+#endif
+	void __iomem *pBase = pThis->pRegs;
+	unsigned int nPipe = pUrb->pipe;
+	u16 wPacketSize = usb_maxpacket(pUrb->dev, nPipe, is_out);
+	u8 bIsBulk = usb_pipebulk(nPipe);
+	u8 bAddress = (u8) usb_pipedevice(nPipe);
+	u8 bRemoteEnd = (u8) usb_pipeendpoint(nPipe);
+	u8 bSpeed = (u8) pUrb->dev->speed;
+	u8 bInterval = (u8) pUrb->interval;
+	struct musb_hw_ep *pEnd = &(pThis->aLocalEnd[bEnd]);
+	u8 bStdType = 0;
+	u8 bHubAddr = 0;
+	u8 bHubPort = 0;
+	u8 reg = 0;
+	u8 bIsMulti = FALSE;
+
+	pParent = pUrb->dev->parent;
+	if (pParent != pThis->RootHub.pDevice)
+		bHubAddr = (u8) pParent->devnum;
+
+	/* set up tt info if needed */
+	if (pUrb->dev->tt) {
+		bHubPort = (u8) pUrb->dev->ttport;
+		bIsMulti = (u8) pUrb->dev->tt->multi;
+	}
+
+	DBG(3, "%s hw%d, urb %p, spd%d dev%d ep%d%s, "
+				"hub%d port%d%s, bytes %d\n",
+			is_out ? "-->" : "<--",
+			bEnd, pUrb, pUrb->dev->speed,
+			bAddress, bRemoteEnd, is_out ? "out" : "in",
+	    		bHubAddr, bHubPort + 1,
+			bIsMulti ? " multi" : "",
+			dwLength);
+
+	/* prepare endpoint registers according to flags */
+	if (usb_pipeisoc(nPipe)) {
+		bStdType = USB_ENDPOINT_XFER_ISOC;
+		/* both speeds use log encoding */
+		bInterval = 1 + fls(pUrb->interval);
+	} else if (usb_pipeint(nPipe)) {
+		bStdType = USB_ENDPOINT_XFER_INT;
+		/* only highspeed uses log encoding */
+		if (USB_SPEED_HIGH == bSpeed)
+			bInterval = 1 + fls(pUrb->interval);
+		else if (bInterval == 0)
+			bInterval = 1;
+	} else if (bIsBulk) {
+		bStdType = USB_ENDPOINT_XFER_BULK;
+		bInterval = 0;	/* ignoring bulk NAK limits for now */
+	} else {
+		// is_out = 1;
+		bInterval = 0;
+		bStdType = USB_ENDPOINT_XFER_CONTROL;
+	}
+
+	reg = bStdType << 4;
+#if 0
+	/* REVISIT we actually want to use NAK limits, as a hint to the
+	 * transfer scheduling logic to try some other peripheral endpoint.
+	 *
+	 * The downside of disabling this is that transfer scheduling gets
+	 * VERY unfair for nonperiodic transfers, and a misbehaving driver
+	 * could make that hurt.  Or for reads, one that acts perfectly
+	 * normally:  network and other drivers keep reads posted at all
+	 * times, having one pending for a week should be perfectly safe.
+	 *
+	 * The downside of enabling it is needing transfer scheduling that
+	 * can put this aside for while ... NAKing is **NOT AN ERROR** but
+	 * some device drivers will want to time out requests.  The current
+	 * scheduler treats these as errors though.
+	 */
+	if (bInterval == 0) {
+		bInterval = 16;
+	}
+#endif
+
+	reg |= (bRemoteEnd & 0xf);
+	/* REVISIT:  test multipoint/not at compiletime ... */
+	if (pThis->bIsMultipoint) {
+		switch (bSpeed) {
+		case USB_SPEED_LOW:
+			reg |= 0xc0;
+			break;
+		case USB_SPEED_FULL:
+			reg |= 0x80;
+			break;
+		default:
+			reg |= 0x40;
+		}
+	}
+
+	if (bIsBulk && pThis->bBulkSplit) {
+		wLoadCount = min((u32) pEnd->wMaxPacketSizeTx, dwLength);
+	} else {
+		wLoadCount = min((u32) wPacketSize, dwLength);
+	}
+
+	MGC_SelectEnd(pBase, bEnd);
+
+#ifndef	CONFIG_USB_INVENTRA_FIFO
+	pDmaChannel = pEnd->pDmaChannel;
+	pDmaController = pThis->pDmaController;
+
+	/* candidate for DMA */
+	if (is_dma_capable()
+			&& !usb_pipecontrol(nPipe)
+			&& pDmaController
+			) {
+		bDmaOk = 1;
+		if (bDmaOk && !pDmaChannel)
+			pDmaChannel = pEnd->pDmaChannel =
+				pDmaController->pfDmaAllocateChannel(
+					    pDmaController->pPrivateData,
+					    bEnd, is_out ? TRUE : FALSE,
+					    bStdType, wPacketSize);
+
+		/* CPPI configures DMA later, and has no channel shortage */
+
+#ifdef CONFIG_USB_INVENTRA_DMA
+		if (bDmaOk && pDmaChannel) {
+			pDmaChannel->dwActualLength = 0L;
+			pEnd->dwRequestSize = min(dwLength,
+					pDmaChannel->dwMaxLength);
+			bDmaOk = pDmaController->pfDmaProgramChannel(
+					pDmaChannel, wPacketSize,
+					pDmaChannel->bDesiredMode,
+					pUrb->transfer_dma,
+					pEnd->dwRequestSize);
+			if (bDmaOk) {
+				wLoadCount = 0;
+			} else {
+				pDmaController->pfDmaReleaseChannel(
+						pDmaChannel);
+				pDmaChannel = pEnd->pDmaChannel = NULL;
+			}
+		}
+#endif
+	} else
+		bDmaOk = 0;
+#endif	/* PIO isn't the only option */
+
+	/* even RX side may need TXCSR, for MGC_M_TXCSR_MODE */
+	wCsr = MGC_ReadCsr16(pBase, MGC_O_HDRC_TXCSR, bEnd);
+
+	/* make sure we clear DMAEnab, autoSet bits from previous run */
+
+	/* OUT/transmit or IN/receive? */
+	if (is_out) {
+		/* transmit */
+		/* disable interrupt in case we flush */
+		wIntrTxE = musb_readw(pBase, MGC_O_HDRC_INTRTXE);
+		musb_writew(pBase, MGC_O_HDRC_INTRTXE, wIntrTxE & ~(1 << bEnd));
+		if (bEnd) {
+
+			// REVISIT assert(bIsReady) earlier
+
+			/* general endpoint setup */
+			if (!pEnd->bIsReady) {
+				u16	csr = wCsr;
+
+				pEnd->bIsReady = TRUE;
+
+				/* flush all old state, set default */
+				csr &= ~(MGC_M_TXCSR_H_NAKTIMEOUT
+				  		| MGC_M_TXCSR_DMAMODE
+						| MGC_M_TXCSR_FRCDATATOG
+						| MGC_M_TXCSR_ISO
+						| MGC_M_TXCSR_H_RXSTALL
+						| MGC_M_TXCSR_H_ERROR
+						| MGC_M_TXCSR_FIFONOTEMPTY
+						| MGC_M_TXCSR_TXPKTRDY
+						);
+				csr |= MGC_M_TXCSR_FLUSHFIFO
+						| MGC_M_TXCSR_MODE;
+
+				if (pEnd->out_traffic_type == PIPE_ISOCHRONOUS)
+					csr |= MGC_M_TXCSR_ISO;
+				else if (usb_gettoggle(pUrb->dev,
+						pEnd->bEnd, 1))
+					csr |= MGC_M_TXCSR_H_WR_DATATOGGLE
+						| MGC_M_TXCSR_H_DATATOGGLE;
+				else
+					csr |= MGC_M_TXCSR_CLRDATATOG;
+
+				/* twice in case of double packet buffering */
+				MGC_WriteCsr16(pBase, MGC_O_HDRC_TXCSR, bEnd,
+						csr);
+				MGC_WriteCsr16(pBase, MGC_O_HDRC_TXCSR, bEnd,
+						csr);
+				wCsr = MGC_ReadCsr16(pBase, MGC_O_HDRC_TXCSR,
+						bEnd);
+			}
+		} else {
+			/* endpoint 0: just flush */
+			MGC_WriteCsr16(pBase, MGC_O_HDRC_CSR0, bEnd,
+				       wCsr | MGC_M_CSR0_FLUSHFIFO);
+			MGC_WriteCsr16(pBase, MGC_O_HDRC_CSR0, bEnd,
+				       wCsr | MGC_M_CSR0_FLUSHFIFO);
+		}
+
+		/* REVISIT:  test multipoint/not at compiletime ... */
+		if (pThis->bIsMultipoint) {
+			/* target addr & hub addr/port */
+			musb_writeb(pBase,
+				   MGC_BUSCTL_OFFSET(bEnd,
+						     MGC_O_HDRC_TXFUNCADDR),
+				   bAddress);
+			musb_writeb(pBase,
+				   MGC_BUSCTL_OFFSET(bEnd,
+						     MGC_O_HDRC_TXHUBADDR),
+				   bIsMulti ? 0x80 | bHubAddr : bHubAddr);
+			musb_writeb(pBase,
+				   MGC_BUSCTL_OFFSET(bEnd,
+						     MGC_O_HDRC_TXHUBPORT),
+				   bHubPort);
+		} else {
+			/* non-multipoint core */
+			musb_writeb(pBase, MGC_O_HDRC_FADDR, bAddress);
+		}
+
+		/* protocol/endpoint/interval/NAKlimit */
+		if (bEnd) {
+			MGC_WriteCsr8(pBase, MGC_O_HDRC_TXTYPE, bEnd, reg);
+#ifdef	C_MP_TX
+			if (bIsBulk && pThis->bBulkSplit) {
+				MGC_WriteCsr16(pBase, MGC_O_HDRC_TXMAXP, bEnd,
+					       wPacketSize |
+					       ((pEnd->wMaxPacketSizeTx /
+						 wPacketSize) - 1) << 11);
+			} else
+#endif
+			{
+				MGC_WriteCsr16(pBase, MGC_O_HDRC_TXMAXP, bEnd,
+					       wPacketSize);
+			}
+// XXX
+			MGC_WriteCsr8(pBase, MGC_O_HDRC_TXINTERVAL, bEnd,
+				      bInterval);
+		} else {
+			MGC_WriteCsr8(pBase, MGC_O_HDRC_NAKLIMIT0, 0,
+				      bInterval);
+			/* REVISIT:  test multipoint/not at compiletime ... */
+			if (pThis->bIsMultipoint) {
+				MGC_WriteCsr8(pBase, MGC_O_HDRC_TYPE0, 0,
+					      reg & 0xc0);
+			}
+		}
+
+#ifdef CONFIG_USB_INVENTRA_DMA
+		if (bDmaOk) {
+			wCsr |= (MGC_M_TXCSR_AUTOSET | MGC_M_TXCSR_DMAENAB |
+				 (pDmaChannel->bDesiredMode
+				  ? MGC_M_TXCSR_DMAMODE : 0));
+			MGC_WriteCsr16(pBase, MGC_O_HDRC_TXCSR, bEnd, wCsr);
+		}
+#elif defined(CONFIG_USB_TI_CPPI_DMA)
+
+		/* candidate for DMA */
+		if (bDmaOk && pDmaChannel) {
+
+			/* program endpoint CSRs first, then setup DMA.
+			 * assume CPPI setup succeeds.
+			 * defer enabling dma.
+			 */
+			wCsr = MGC_ReadCsr16(pBase, MGC_O_HDRC_TXCSR, bEnd);
+			wCsr &= ~(MGC_M_TXCSR_AUTOSET
+					| MGC_M_TXCSR_DMAMODE
+					| MGC_M_TXCSR_DMAENAB);
+			wCsr |= MGC_M_TXCSR_MODE;
+			MGC_WriteCsr16(pBase, MGC_O_HDRC_TXCSR, bEnd,
+				       wCsr | MGC_M_TXCSR_MODE);
+
+			pDmaChannel->dwActualLength = 0L;
+			pEnd->dwRequestSize = dwLength;
+
+			/* TX uses "rndis" mode automatically, but needs help
+			 * to identify the zero-length-final-packet case.
+			 */
+			bDmaOk = pDmaController->pfDmaProgramChannel(
+					pDmaChannel, wPacketSize,
+					(pUrb->transfer_flags
+							& URB_ZERO_PACKET)
+						== URB_ZERO_PACKET,
+					pUrb->transfer_dma,
+					pEnd->dwRequestSize);
+			if (bDmaOk) {
+				wLoadCount = 0;
+			} else {
+				pDmaController->pfDmaReleaseChannel(
+						pDmaChannel);
+				pDmaChannel = pEnd->pDmaChannel = NULL;
+
+				/* REVISIT there's an error path here that
+				 * needs handling:  can't do dma, but
+				 * there's no pio buffer address...
+				 */
+			}
+		}
+#endif
+		if (wLoadCount) {
+			/* PIO to load FIFO */
+			pEnd->dwRequestSize = wLoadCount;
+			musb_write_fifo(pEnd, wLoadCount,
+					 pBuffer);
+			wCsr = MGC_ReadCsr16(pBase, MGC_O_HDRC_TXCSR, bEnd);
+			wCsr &=
+			    ~(MGC_M_TXCSR_DMAENAB | MGC_M_TXCSR_DMAMODE |
+			      MGC_M_TXCSR_AUTOSET);
+			/* write CSR */
+			wCsr |= MGC_M_TXCSR_MODE;
+
+			if (bEnd)
+				MGC_WriteCsr16(pBase, MGC_O_HDRC_TXCSR, bEnd,
+					       wCsr);
+
+		}
+
+		/* re-enable interrupt */
+		musb_writew(pBase, MGC_O_HDRC_INTRTXE, wIntrTxE);
+
+	/* IN/receive */
+	} else {
+		/* First retarget this EP hardware to the correct peripheral
+		 * endpoint.  Then activate the transfer (plus maybe dma).
+		 */
+
+		/* if programmed for Tx, be sure it is ready for re-use */
+		if (pEnd->bIsSharedFifo && (wCsr & MGC_M_TXCSR_MODE)) {
+			pEnd->bIsReady = FALSE;
+			pr_debug("set endready to False \n");
+			if (wCsr & MGC_M_TXCSR_FIFONOTEMPTY) {
+#if 0
+				/* REVISIT but setting toggle won't help as
+				 * much as, oh, clearing the fifo...
+				 */
+				/* this shouldn't happen */
+				MGC_WriteCsr16(pBase, MGC_O_HDRC_TXCSR, bEnd,
+					       MGC_M_TXCSR_FRCDATATOG);
+				MGC_WriteCsr16(pBase, MGC_O_HDRC_TXCSR, bEnd,
+					       MGC_M_TXCSR_FRCDATATOG);
+#endif
+				ERR("TX FIFO%d not empty\n", bEnd);
+			}
+			/* clear mode (and everything else) to enable Rx */
+			MGC_WriteCsr16(pBase, MGC_O_HDRC_TXCSR, bEnd, 0);
+		}
+
+		/* REVISIT:  test multipoint/not at compiletime ... */
+		/* address */
+		if (pThis->bIsMultipoint) {
+			/* target addr & hub addr/port */
+			musb_writeb(pBase,
+				   MGC_BUSCTL_OFFSET(bEnd,
+						     MGC_O_HDRC_RXFUNCADDR),
+				   bAddress);
+			musb_writeb(pBase,
+				   MGC_BUSCTL_OFFSET(bEnd,
+						     MGC_O_HDRC_RXHUBADDR),
+				   bIsMulti ? 0x80 | bHubAddr : bHubAddr);
+			musb_writeb(pBase,
+				   MGC_BUSCTL_OFFSET(bEnd,
+						     MGC_O_HDRC_RXHUBPORT),
+				   bHubPort);
+		} else {
+			/* non-multipoint core */
+			musb_writeb(pBase, MGC_O_HDRC_FADDR, bAddress);
+		}
+
+		/* protocol/endpoint/interval/NAKlimit */
+		if (bEnd) {
+			MGC_WriteCsr8(pBase, MGC_O_HDRC_RXTYPE, bEnd, reg);
+#if 0
+//#ifdef	C_MP_RX
+			/* doesn't work reliably */
+			if (bIsBulk && pThis->bBulkCombine) {
+				MGC_WriteCsr16(pBase, MGC_O_HDRC_RXMAXP, bEnd,
+					       wPacketSize |
+					       ((min
+						 (pEnd->wMaxPacketSizeRx,
+						  dwLength) / wPacketSize) -
+						1) << 11);
+			} else
+#endif
+			{
+				MGC_WriteCsr16(pBase, MGC_O_HDRC_RXMAXP, bEnd,
+					       wPacketSize);
+			}
+			MGC_WriteCsr8(pBase, MGC_O_HDRC_RXINTERVAL, bEnd,
+				      bInterval);
+		} else if (pThis->bIsMultipoint) {
+			/* REVISIT:  test multipoint/not at compiletime ... */
+			MGC_WriteCsr8(pBase, MGC_O_HDRC_TYPE0, 0, reg & 0xc0);
+		}
+
+		/* if not  flush & init toggle */
+		WARN_ON(pEnd->bIsReady);
+		pEnd->bIsReady = TRUE;
+
+		wCsr = MGC_ReadCsr16(pBase, MGC_O_HDRC_RXCSR, bEnd);
+		if (wCsr & MGC_M_RXCSR_RXPKTRDY)
+			WARN("rx%d, packet/%d ready?\n", bEnd,
+				MGC_ReadCsr16(pBase, MGC_O_HDRC_RXCOUNT, bEnd));
+
+// SCRUB (RX)
+		/* twice in case of double packet buffering */
+		MGC_WriteCsr16(pBase, MGC_O_HDRC_RXCSR, bEnd,
+			       MGC_M_RXCSR_FLUSHFIFO |
+			       MGC_M_RXCSR_CLRDATATOG);
+		MGC_WriteCsr16(pBase, MGC_O_HDRC_RXCSR, bEnd,
+			       MGC_M_RXCSR_FLUSHFIFO |
+			       MGC_M_RXCSR_CLRDATATOG);
+
+		if (usb_gettoggle(pUrb->dev, pEnd->bEnd, 0))
+			MGC_WriteCsr16(pBase, MGC_O_HDRC_RXCSR, bEnd,
+					MGC_M_RXCSR_H_WR_DATATOGGLE
+					| MGC_M_RXCSR_H_DATATOGGLE);
+
+		/* kick things off */
+		if (bEnd) {
+			int	 newcsr;
+
+			newcsr = wCsr = MGC_ReadCsr16(pBase, MGC_O_HDRC_RXCSR,
+					  bEnd);
+			newcsr |= MGC_M_RXCSR_H_REQPKT;
+
+			/* scrub any stale state */
+			newcsr &= ~(MGC_M_CSR0_H_ERROR
+					| MGC_M_CSR0_H_RXSTALL
+					| MGC_M_CSR0_H_NAKTIMEOUT
+					| MGC_M_RXCSR_RXPKTRDY
+					);
+
+			if (usb_pipeint(nPipe))
+				newcsr |= MGC_M_RXCSR_DISNYET;
+
+#ifdef CONFIG_USB_INVENTRA_DMA
+			if (bDmaOk) {
+				newcsr &= ~MGC_M_RXCSR_H_REQPKT;
+				newcsr |= MGC_M_RXCSR_H_AUTOREQ;
+				newcsr |=
+				    (MGC_M_RXCSR_AUTOCLEAR | MGC_M_RXCSR_DMAENAB
+				     | (pDmaChannel->
+					bDesiredMode ? MGC_M_RXCSR_DMAMODE :
+					0));
+			}
+#elif defined(CONFIG_USB_TI_CPPI_DMA)
+			/* candidate for DMA */
+			if (pDmaChannel) {
+				pDmaChannel->dwActualLength = 0L;
+				pEnd->dwRequestSize = dwLength;
+
+				/* AUTOREQ is in a DMA register */
+				newcsr &= ~(MGC_M_RXCSR_AUTOCLEAR
+						| MGC_M_RXCSR_DMAMODE
+						| MGC_M_RXCSR_H_REQPKT
+						| MGC_M_RXCSR_H_AUTOREQ);
+				if (newcsr != wCsr) {
+					DBG(7, "RXCSR%d %04x\n", bEnd, newcsr);
+					MGC_WriteCsr16(pBase, MGC_O_HDRC_RXCSR,
+							bEnd, newcsr);
+				}
+
+				/* unless caller treats short rx transfers as
+				 * errors, we dare not queue multiple transfers.
+				 */
+				bDmaOk = pDmaController->pfDmaProgramChannel(
+						pDmaChannel, wPacketSize,
+						!(pUrb->transfer_flags
+							& URB_SHORT_NOT_OK),
+						pUrb->transfer_dma,
+						pEnd->dwRequestSize);
+				if (!bDmaOk) {
+					pDmaController->pfDmaReleaseChannel(
+							pDmaChannel);
+					pDmaChannel = pEnd->pDmaChannel = NULL;
+					newcsr &= ~MGC_M_RXCSR_DMAENAB;
+					wCsr = MGC_ReadCsr16(pBase,
+							MGC_O_HDRC_RXCSR,
+							bEnd);
+				} else
+					newcsr |= MGC_M_RXCSR_DMAENAB
+						| MGC_M_RXCSR_H_REQPKT;
+			}
+#endif
+			if (newcsr != wCsr) {
+				DBG(7, "RXCSR%d := %04x\n", bEnd, newcsr);
+				MGC_WriteCsr16(pBase, MGC_O_HDRC_RXCSR,
+					bEnd,
+					MGC_M_RXCSR_H_WZC_BITS | newcsr);
+			}
+		}
+	}
+}
+
+/*
+ * Try to stop traffic on the given local endpoint.
+ * @param pThis the controller
+ * @param bEnd the endpoint number.
+ * Context: irqs blocked, controller lock held
+ */
+void MGC_HdrcStopEnd(struct musb *pThis, u8 bEnd)
+{
+	u16 wCsr;
+	void __iomem *pBase = pThis->pRegs;
+	const u8 reg = (bEnd) ? MGC_O_HDRC_RXCSR : MGC_O_HDRC_CSR0;
+	struct musb_hw_ep *hw_ep = pThis->aLocalEnd + bEnd;
+
+// REVISIT probably worth calling this in other places, once the
+// urb abort stuff is removed ...
+
+// FIXME it's not just RX endpoints that need stopping ...
+
+// SCRUB (RX -and- TX)
+	/* clear the pending request */
+	MGC_SelectEnd(pBase, bEnd);
+	wCsr = MGC_ReadCsr16(pBase, reg, bEnd);
+	wCsr &= (bEnd) ? ~MGC_M_RXCSR_H_REQPKT : ~MGC_M_CSR0_H_REQPKT;
+	MGC_WriteCsr16(pBase, reg, bEnd, wCsr);
+
+	while (!list_empty(&hw_ep->urb_list)) {
+		struct urb *urb;
+
+		urb = list_entry(hw_ep->urb_list.next, struct urb, urb_list);
+		ERR("abort urb %p, dev %d\n", urb, urb->dev->devnum);
+		musb_giveback(hw_ep, urb, -ESHUTDOWN);
+
+		// REVISIT ... usbcore will abort things for us
+		// if we disable() endpoints properly, so that this
+		// routine should never see urbs still queued
+		// (root hub currently has a big hole)
+	}
+}
+
+/*
+ * Service the default endpoint (ep0) as host.
+ *
+ * @param pThis this
+ * @param wCount current byte count in FIFO
+ * @param pUrb URB pointer for EP0
+ * @return TRUE if more packets are required for this transaction
+ */
+static u8 musb_h_ep0_continue(struct musb *pThis,
+				     u16 wCount, struct urb *pUrb)
+{
+	u8 bMore = FALSE;
+	u8 *pFifoDest = NULL;
+	u16 wFifoCount = 0;
+	struct musb_hw_ep *pEnd = &(pThis->aLocalEnd[0]);
+	struct usb_ctrlrequest *pRequest =
+	    (struct usb_ctrlrequest *)pUrb->setup_packet;
+
+	if (MGC_END0_IN == pThis->bEnd0Stage) {
+		/* we are receiving from peripheral */
+		pFifoDest = pUrb->transfer_buffer + pUrb->actual_length;
+		wFifoCount = min(wCount, ((u16)
+			 (pUrb->transfer_buffer_length - pUrb->actual_length)));
+		if (wFifoCount < wCount)
+			pUrb->status = -EOVERFLOW;
+
+		musb_read_fifo(pEnd, wFifoCount, pFifoDest);
+
+		pUrb->actual_length += wCount;
+		if (wCount < pEnd->wPacketSize) {
+			/* always terminate on short read; it's
+			 * rarely reported as an error.
+			 */
+			if ((pUrb->transfer_flags & URB_SHORT_NOT_OK)
+					&& (pUrb->actual_length <
+						pUrb->transfer_buffer_length))
+				pUrb->status = -EREMOTEIO;
+		} else if (pUrb->actual_length <
+				pUrb->transfer_buffer_length)
+			bMore = TRUE;
+	} else {
+		/* we are sending to peripheral */
+		if ((MGC_END0_START == pThis->bEnd0Stage) &&
+		    (pRequest->bRequestType & USB_DIR_IN)) {
+			/* this means we just did setup; switch to IN */
+			DBG(4, "start IN-DATA\n");
+			pThis->bEnd0Stage = MGC_END0_IN;
+			bMore = TRUE;
+
+		} else if (pRequest->wLength
+			   && (MGC_END0_START == pThis->bEnd0Stage)) {
+			pThis->bEnd0Stage = MGC_END0_OUT;
+			pFifoDest = (u8 *) (pUrb->transfer_buffer +
+				    pUrb->actual_length);
+			wFifoCount =
+			    min(pEnd->wPacketSize,
+				((u16)
+				 (pUrb->transfer_buffer_length -
+				  pUrb->actual_length)));
+			DBG(3, "Sending %d bytes to %p\n", wFifoCount,
+			    pFifoDest);
+			musb_write_fifo(pEnd, wFifoCount, pFifoDest);
+
+			pEnd->dwRequestSize = wFifoCount;
+			pUrb->actual_length += wFifoCount;
+			if (pUrb->actual_length < pUrb->transfer_buffer_length) {
+				bMore = TRUE;
+			}
+		}
+	}
+
+	return bMore;
+}
+
+/*
+ * Handle default endpoint interrupt as host. Only called in IRQ time
+ * from the LinuxIsr() interrupt service routine.
+ *
+ * called with controller irqlocked
+ */
+irqreturn_t musb_h_ep0_irq(struct musb *pThis)
+{
+	struct urb		*pUrb;
+	u16			wCsrVal, wCount;
+	int			status = 0;
+	void __iomem		*pBase = pThis->pRegs;
+	struct musb_hw_ep	*pEnd = &pThis->aLocalEnd[0];
+	u8			bComplete = FALSE;
+	irqreturn_t		retval = IRQ_NONE;
+
+	/* ep0 only has one queue, "in" */
+	pUrb = next_in_urb(pEnd);
+
+	MGC_SelectEnd(pBase, 0);
+	wCsrVal = MGC_ReadCsr16(pBase, MGC_O_HDRC_CSR0, 0);
+	wCount = MGC_ReadCsr8(pBase, MGC_O_HDRC_COUNT0, 0);
+
+	DBG(4, "<== csr0 %04x, count %d, urb %p\n", wCsrVal, wCount, pUrb);
+
+	/* if we just did status stage, we are done */
+	if (MGC_END0_STATUS == pThis->bEnd0Stage) {
+		retval = IRQ_HANDLED;
+		bComplete = TRUE;
+	}
+
+	/* prepare status */
+	if (wCsrVal & MGC_M_CSR0_H_RXSTALL) {
+		DBG(6, "STALLING ENDPOINT\n");
+		status = -EPIPE;
+
+	} else if (wCsrVal & MGC_M_CSR0_H_ERROR) {
+		DBG(2, "no response, csr0 %04x\n", wCsrVal);
+		status = -EPROTO;
+
+	} else if (wCsrVal & MGC_M_CSR0_H_NAKTIMEOUT) {
+		DBG(2, "control NAK timeout\n");
+
+		/* NOTE:  this code path would be a good place to PAUSE a
+		 * control transfer, if another one is queued, so that
+		 * ep0 is more likely to stay busy.
+		 */
+		MGC_WriteCsr16(pBase, MGC_O_HDRC_CSR0, 0, 0);
+		retval = IRQ_HANDLED;
+	}
+
+	if (status) {
+		DBG(6, "aborting\n");
+		retval = IRQ_HANDLED;
+		if (pUrb)
+			pUrb->status = status;
+		bComplete = TRUE;
+
+		/* use the proper sequence to abort the transfer */
+		if (wCsrVal & MGC_M_CSR0_H_REQPKT) {
+			wCsrVal &= ~MGC_M_CSR0_H_REQPKT;
+			MGC_WriteCsr16(pBase, MGC_O_HDRC_CSR0, 0, wCsrVal);
+			wCsrVal &= ~MGC_M_CSR0_H_NAKTIMEOUT;
+			MGC_WriteCsr16(pBase, MGC_O_HDRC_CSR0, 0, wCsrVal);
+		} else {
+			wCsrVal |= MGC_M_CSR0_FLUSHFIFO;
+			MGC_WriteCsr16(pBase, MGC_O_HDRC_CSR0, 0, wCsrVal);
+			MGC_WriteCsr16(pBase, MGC_O_HDRC_CSR0, 0, wCsrVal);
+			wCsrVal &= ~MGC_M_CSR0_H_NAKTIMEOUT;
+			MGC_WriteCsr16(pBase, MGC_O_HDRC_CSR0, 0, wCsrVal);
+		}
+
+		MGC_WriteCsr8(pBase, MGC_O_HDRC_NAKLIMIT0, 0, 0);
+
+		/* clear it */
+		MGC_WriteCsr16(pBase, MGC_O_HDRC_CSR0, 0, 0);
+	}
+
+	if (!pUrb) {
+		/* stop endpoint since we have no place for its data, this
+		 * SHOULD NEVER HAPPEN! */
+		DBG(1, "no URB for end 0\n");
+
+		MGC_WriteCsr16(pBase, MGC_O_HDRC_CSR0, 0, MGC_M_CSR0_FLUSHFIFO);
+		MGC_WriteCsr16(pBase, MGC_O_HDRC_CSR0, 0, MGC_M_CSR0_FLUSHFIFO);
+		MGC_WriteCsr16(pBase, MGC_O_HDRC_CSR0, 0, 0);
+
+		/* start next URB that might be queued for it */
+		musb_advance_urb_queue(pThis, pUrb, pEnd,
+				usb_pipein(pUrb->pipe));
+		goto done;
+	}
+
+	if (!bComplete) {
+		/* call common logic and prepare response */
+		if (musb_h_ep0_continue(pThis, wCount, pUrb)) {
+			/* more packets required */
+			wCsrVal = (MGC_END0_IN == pThis->bEnd0Stage) ?
+			    MGC_M_CSR0_H_REQPKT : MGC_M_CSR0_TXPKTRDY;
+			DBG(5, "more ep0 DATA, csr %04x\n", wCsrVal);
+		} else {
+			/* data transfer complete; perform status phase */
+			wCsrVal = MGC_M_CSR0_H_STATUSPKT |
+			    (usb_pipeout(pUrb->pipe) ? MGC_M_CSR0_H_REQPKT :
+			     MGC_M_CSR0_TXPKTRDY);
+			/* flag status stage */
+			pThis->bEnd0Stage = MGC_END0_STATUS;
+
+			DBG(5, "ep0 STATUS, csr %04x\n", wCsrVal);
+
+		}
+		MGC_WriteCsr16(pBase, MGC_O_HDRC_CSR0, 0, wCsrVal);
+		retval = IRQ_HANDLED;
+	}
+
+	/* call completion handler if done */
+	if (bComplete)
+		musb_advance_urb_queue(pThis, pUrb, pEnd,
+				usb_pipein(pUrb->pipe));
+done:
+	return retval;
+}
+
+
+/* Service a Tx-Available or dma completion irq for the endpoint */
+void musb_host_tx(struct musb *pThis, u8 bEnd)
+{
+	int			nPipe;
+	u8			bDone = FALSE;
+	u16			wTxCsrVal;
+	size_t			wLength = 0;
+	u8			*pBuffer = NULL;
+	struct urb		*pUrb;
+	struct musb_hw_ep	*pEnd = pThis->aLocalEnd + bEnd;
+	u32			status = 0;
+	void __iomem		*pBase = pThis->pRegs;
+	struct dma_channel	*dma;
+
+	pUrb = next_out_urb(pEnd);
+
+	MGC_SelectEnd(pBase, bEnd);
+	wTxCsrVal = MGC_ReadCsr16(pBase, MGC_O_HDRC_TXCSR, bEnd);
+
+	// FIXME we seem to get these sometimes, not clear why...
+	// ... usually right after a cppi completion irq, dma enabled
+	// ... ideally, it's when the fifo empties after dma ...
+	if (!pUrb) {
+		DBG(4, "null urb, TXCSR%d = %04x\n", bEnd, wTxCsrVal);
+		goto finish;
+	}
+
+	nPipe = pUrb->pipe;
+	dma = is_dma_capable() ? pEnd->pDmaChannel : NULL;
+	DBG(4, "OUT/TX%d end, csr %04x%s\n", bEnd, wTxCsrVal,
+			dma ? ", dma" : "");
+
+	/* check for errors */
+	if (wTxCsrVal & MGC_M_TXCSR_H_RXSTALL) {
+		DBG(3, "TX end %d stall\n", bEnd);
+
+		/* stall; record URB status */
+		status = -EPIPE;
+
+	} else if (wTxCsrVal & MGC_M_TXCSR_H_ERROR) {
+		DBG(3, "TX data error on ep=%d\n", bEnd);
+
+		status = -ETIMEDOUT;
+
+	} else if (wTxCsrVal & MGC_M_TXCSR_H_NAKTIMEOUT) {
+		DBG(6, "TX end=%d device not responding\n", bEnd);
+
+		/* NOTE:  this code path would be a good place to PAUSE a
+		 * transfer, if there's some other (nonperiodic) tx urb
+		 * that could use this fifo.  (dma complicates it...)
+		 */
+		MGC_SelectEnd(pBase, bEnd);
+		MGC_WriteCsr16(pBase, MGC_O_HDRC_CSR0, 0,
+				MGC_M_TXCSR_H_WZC_BITS
+				| MGC_M_TXCSR_TXPKTRDY);
+		goto finish;
+	}
+
+	if (status) {
+		if (dma_channel_status(dma) == MGC_DMA_STATUS_BUSY) {
+			dma->bStatus = MGC_DMA_STATUS_CORE_ABORT;
+			(void) pThis->pDmaController->pfDmaAbortChannel(dma);
+		}
+
+		/* do the proper sequence to abort the transfer in the
+		 * usb core; the dma engine should already be stopped.
+		 */
+// SCRUB (TX)
+		wTxCsrVal &= ~(MGC_M_TXCSR_FIFONOTEMPTY
+				| MGC_M_TXCSR_AUTOSET
+				| MGC_M_TXCSR_DMAENAB
+				| MGC_M_TXCSR_H_ERROR
+				| MGC_M_TXCSR_H_RXSTALL
+				| MGC_M_TXCSR_H_NAKTIMEOUT
+				);
+		wTxCsrVal |= MGC_M_TXCSR_FLUSHFIFO;
+
+		MGC_SelectEnd(pBase, bEnd);
+		MGC_WriteCsr16(pBase, MGC_O_HDRC_TXCSR, bEnd, wTxCsrVal);
+		MGC_WriteCsr16(pBase, MGC_O_HDRC_TXCSR, bEnd, wTxCsrVal);
+		MGC_WriteCsr8(pBase, MGC_O_HDRC_TXINTERVAL, bEnd, 0);
+
+		bDone = TRUE;
+	}
+
+	if (dma_channel_status(dma) == MGC_DMA_STATUS_BUSY) {
+		/* SHOULD NOT HAPPEN */
+		DBG(3, "bogus TX%d busy dma, csr %04x\n", bEnd, wTxCsrVal);
+		goto finish;
+
+	}
+
+	/* REVISIT this looks wrong... */
+	if (!status || dma || usb_pipeisoc(nPipe)) {
+
+		if (dma)
+			wLength = pEnd->pDmaChannel->dwActualLength;
+		else
+			wLength = pEnd->dwRequestSize;
+		pEnd->dwOffset += wLength;
+
+		if (usb_pipeisoc(nPipe)) {
+			struct usb_iso_packet_descriptor	*d;
+
+			d = pUrb->iso_frame_desc + pEnd->dwIsoPacket;
+			d->actual_length = pEnd->dwRequestSize;
+			if (++pEnd->dwIsoPacket >= pUrb->number_of_packets) {
+				bDone = TRUE;
+			} else if (!dma) {
+				d++;
+				pBuffer = pUrb->transfer_buffer + d->offset;
+				wLength = d->length;
+			}
+		} else if (dma) {
+			bDone = TRUE;
+		} else {
+			/* see if we need to send more data, or ZLP */
+			if (pEnd->dwRequestSize < pEnd->wPacketSize)
+				bDone = TRUE;
+			else if (pEnd->dwOffset == pUrb->transfer_buffer_length
+					&& !(pUrb-> transfer_flags
+							& URB_ZERO_PACKET))
+				bDone = TRUE;
+			if (!bDone) {
+				pBuffer = pUrb->transfer_buffer
+						+ pEnd->dwOffset;
+				wLength = pUrb->transfer_buffer_length
+						- pEnd->dwOffset;
+			}
+		}
+	}
+
+	/* urb->status != -EINPROGRESS means request has been faulted,
+	 * so we must abort this transfer after cleanup
+	 */
+	if (pUrb->status != -EINPROGRESS) {
+		bDone = TRUE;
+		if (status == 0)
+			status = pUrb->status;
+	}
+
+	if (bDone) {
+		/* set status */
+		pUrb->status = status;
+		pUrb->actual_length = pEnd->dwOffset;
+
+		musb_advance_urb_queue(pThis, pUrb, pEnd, USB_DIR_OUT);
+
+	} else if (!(wTxCsrVal & MGC_M_TXCSR_DMAENAB)) {
+		// WARN_ON(!pBuffer);
+
+		/* PIO:  start next packet in this URB */
+		wLength = min(pEnd->wPacketSize, (u16) wLength);
+		musb_write_fifo(pEnd, wLength, pBuffer);
+		pEnd->dwRequestSize = wLength;
+
+		MGC_SelectEnd(pBase, bEnd);
+		MGC_WriteCsr16(pBase, MGC_O_HDRC_TXCSR, bEnd,
+				MGC_M_TXCSR_H_WZC_BITS | MGC_M_TXCSR_TXPKTRDY);
+	} else
+		DBG(1, "not complete, but dma enabled?\n");
+
+finish:
+	return;
+}
+
+/*
+ * Service an Rx-Ready interrupt for the given endpoint; see section 18.2.1
+ * of the manual for details.
+ *
+ * @param pThis instance pointer
+ * @param bEnd local endpoint
+ */
+void musb_host_rx(struct musb *pThis, u8 bEnd)
+{
+	struct urb		*pUrb;
+	struct musb_hw_ep	*pEnd = &(pThis->aLocalEnd[bEnd]);
+	size_t			xfer_len;
+	void __iomem		*pBase = pThis->pRegs;
+	int			nPipe;
+	u16			wRxCsrVal, wVal;
+	u8			bIsochError = FALSE;
+	u8			bDone = FALSE;
+	u32			status;
+	struct dma_channel	*dma;
+
+	MGC_SelectEnd(pBase, bEnd);
+
+	pUrb = next_in_urb(pEnd);
+	dma = is_dma_capable() ? pEnd->pDmaChannel : NULL;
+	status = 0;
+	xfer_len = 0;
+
+	wVal = wRxCsrVal = MGC_ReadCsr16(pBase, MGC_O_HDRC_RXCSR, bEnd);
+
+	if (!pUrb) {
+		/* SHOULD NOT HAPPEN */
+		DBG(3, "bogus RX%d ready, csr %04x\n", bEnd, wVal);
+		goto finish;
+	}
+
+	nPipe = pUrb->pipe;
+
+	DBG(5, "<== hw %d rxcsr %04x, urb actual %d (+dma %d)\n", bEnd,
+	    wRxCsrVal, pUrb->actual_length,
+	    dma ? dma->dwActualLength : 0);
+
+	/* check for errors, concurrent stall & unlink is not really
+	 * handled yet! */
+	if (wRxCsrVal & MGC_M_RXCSR_H_RXSTALL) {
+		DBG(3, "RX end %d STALL\n", bEnd);
+
+		/* stall; record URB status */
+		status = -EPIPE;
+
+	} else if (wRxCsrVal & MGC_M_RXCSR_H_ERROR) {
+		DBG(3, "end %d RX proto error\n", bEnd);
+
+		status = -EPROTO;
+		MGC_WriteCsr8(pBase, MGC_O_HDRC_RXINTERVAL, bEnd, 0);
+
+	} else if (wRxCsrVal & MGC_M_RXCSR_DATAERROR) {
+
+		if (PIPE_ISOCHRONOUS != pEnd->out_traffic_type) {
+			/* NOTE this code path would be a good place to PAUSE a
+			 * transfer, if there's some other (nonperiodic) rx urb
+			 * that could use this fifo.  (dma complicates it...)
+			 */
+			DBG(6, "RX end=%d device not responding\n", bEnd);
+			MGC_SelectEnd(pBase, bEnd);
+			MGC_WriteCsr16(pBase, MGC_O_HDRC_RXCSR, bEnd,
+					MGC_M_RXCSR_H_WZC_BITS
+					| MGC_M_RXCSR_H_REQPKT);
+
+			goto finish;
+		} else {
+			DBG(3, "bEnd=%d Isochronous error\n", bEnd);
+			// packet[i].status = -EILSEQ;
+			bIsochError = TRUE;
+		}
+	}
+
+	if (status) {
+		/* clean up dma and collect transfer count */
+		if (dma_channel_status(dma) == MGC_DMA_STATUS_BUSY) {
+			dma->bStatus = MGC_DMA_STATUS_CORE_ABORT;
+			(void) pThis->pDmaController->pfDmaAbortChannel(dma);
+			xfer_len = dma->dwActualLength;
+		}
+	}
+
+	if (status) {
+		wVal &= ~(MGC_M_RXCSR_H_ERROR
+			| MGC_M_RXCSR_DATAERROR
+			| MGC_M_RXCSR_H_RXSTALL
+			| MGC_M_RXCSR_RXPKTRDY
+			| MGC_M_RXCSR_H_REQPKT
+			);
+		MGC_SelectEnd(pBase, bEnd);
+		MGC_WriteCsr16(pBase, MGC_O_HDRC_RXCSR, bEnd, wVal);
+		MGC_WriteCsr8(pBase, MGC_O_HDRC_RXINTERVAL, bEnd, 0);
+
+		bDone = TRUE;
+	}
+
+	if (dma_channel_status(dma) == MGC_DMA_STATUS_BUSY) {
+		/* SHOULD NOT HAPPEN */
+		DBG(3, "RX%d busy\n", bEnd);
+		goto finish;
+	}
+
+
+	/* thorough shutdown for now ... given more precise fault handling
+	 * and better queueing support, we might keep a DMA pipeline going
+	 * while processing this irq for earlier completions.
+	 */
+
+	if (wRxCsrVal & MGC_M_RXCSR_H_REQPKT)  {
+		/* REVISIT this happened for a while on some short reads...
+		 * the cleanup still needs investigation... looks bad...
+		 * and also duplicates dma cleanup code above ...
+		 */
+		if (dma_channel_status(dma) == MGC_DMA_STATUS_BUSY) {
+			dma->bStatus = MGC_DMA_STATUS_CORE_ABORT;
+			(void) pThis->pDmaController->pfDmaAbortChannel(dma);
+			xfer_len = dma->dwActualLength;
+		}
+
+		DBG(3, "RXCSR%d %04x, reqpkt, len %d%s\n", bEnd, wRxCsrVal,
+				xfer_len, dma ? ", dma" : "");
+		wRxCsrVal &= ~MGC_M_RXCSR_H_REQPKT;
+
+		MGC_SelectEnd(pBase, bEnd);
+		MGC_WriteCsr16(pBase, MGC_O_HDRC_RXCSR, bEnd,
+				MGC_M_RXCSR_H_WZC_BITS | wRxCsrVal);
+	}
+
+	if (dma && (wRxCsrVal & MGC_M_RXCSR_DMAENAB)) {
+#if 0
+		wRxCsrVal &= ~MGC_M_RXCSR_DMAENAB;
+		MGC_WriteCsr16(pBase, MGC_O_HDRC_RXCSR, bEnd,
+				MGC_M_RXCSR_H_WZC_BITS | wRxCsrVal);
+		MGC_WriteCsr16(pBase, MGC_O_HDRC_RXCSR, bEnd,
+				MGC_M_RXCSR_H_WZC_BITS | wRxCsrVal);
+		DBG(4, "RXCSR%d %04x, dma off, %04x\n", bEnd, wRxCsrVal,
+				MGC_ReadCsr16(pBase, MGC_O_HDRC_RXCSR, bEnd));
+#endif
+		bDone = TRUE;
+		xfer_len = dma->dwActualLength;
+
+	} else if (!bDone && pUrb->status == -EINPROGRESS) {
+
+		/* if no errors, be sure a packet is ready for unloading */
+		if (!(wRxCsrVal & MGC_M_RXCSR_RXPKTRDY)) {
+			status = -EPROTO;
+DBG(1, "Rx interrupt with no errors or packet!\n");
+
+			// FIXME this is another "SHOULD NEVER HAPPEN"
+			// like the "no URB" case below
+
+// SCRUB (RX)
+			/* do the proper sequence to abort the transfer */
+			MGC_SelectEnd(pBase, bEnd);
+			wVal &= ~MGC_M_RXCSR_H_REQPKT;
+			MGC_WriteCsr16(pBase, MGC_O_HDRC_RXCSR, bEnd, wVal);
+		}
+
+		/* we are expecting IN packets */
+		if (pUrb) {
+			if (!bDone) {
+				bDone = musb_host_packet_rx(pThis, pUrb,
+						bEnd, bIsochError);
+				DBG(6, "read %spacket\n", bDone ? "last " : "");
+			}
+		} else {
+			/* THIS SHOULD NEVER HAPPEN */
+			/* stop endpoint since we have no place for its data */
+			DBG(1, "no URB on end %d Rx!\n", bEnd);
+
+// SCRUB (RX)
+			MGC_SelectEnd(pBase, bEnd);
+			wVal |= MGC_M_RXCSR_FLUSHFIFO;
+			wVal &= ~MGC_M_RXCSR_H_REQPKT;
+			MGC_WriteCsr16(pBase, MGC_O_HDRC_RXCSR, bEnd, wVal);
+			MGC_WriteCsr16(pBase, MGC_O_HDRC_RXCSR, bEnd, wVal);
+
+			wVal &= ~(MGC_M_RXCSR_FLUSHFIFO | MGC_M_RXCSR_RXPKTRDY);
+			MGC_WriteCsr16(pBase, MGC_O_HDRC_RXCSR, bEnd, wVal);
+		}
+	} else if (!bDone) {
+		bDone = TRUE;
+		status = pUrb->status;
+	}
+
+	pUrb->actual_length += xfer_len;
+	pEnd->dwOffset += xfer_len;
+
+	if (bDone) {
+		pUrb->status = status;
+		goto advance;
+	} else {
+		DBG(5, "not done yet, setup next in transaction\n");
+
+		/* continue by clearing RxPktRdy and setting ReqPkt */
+		MGC_SelectEnd(pBase, bEnd);
+		wVal &= ~MGC_M_RXCSR_RXPKTRDY;
+		wVal |= MGC_M_RXCSR_H_REQPKT | MGC_M_RXCSR_H_WZC_BITS;
+		MGC_WriteCsr16(pBase, MGC_O_HDRC_RXCSR, bEnd, wVal);
+	}
+
+finish:
+	return;
+
+advance:
+	musb_advance_urb_queue(pThis, pUrb, pEnd, USB_DIR_IN);
+	return;
+}
+
+/*
+ * Find an endpoint for the given pipe
+ */
+static struct musb_hw_ep *musb_find_ep(struct musb *pThis, struct urb *pUrb)
+{
+	unsigned int	pipe = pUrb->pipe;
+	unsigned int	nOut;
+	struct musb_hw_ep *pEnd;
+	unsigned long	flags;
+	int		nEnd;
+	s32		dwDiff;
+	u16		wBestDiff;
+	int		nBestEnd;
+	u16		wPacketSize;
+	u8		bEnd;
+	u8		bAddress;
+
+	/* control is always EP0 */
+	if (usb_pipecontrol(pipe))
+		return pThis->aLocalEnd;
+
+	nOut = usb_pipeout(pipe);
+
+	/* bulk uses reserved endpoints too (policy choice) */
+	if (usb_pipebulk(pipe)) {
+		if (nOut)
+			return pThis->bulk_tx_end;
+		else
+			return pThis->bulk_rx_end;
+	}
+
+	wBestDiff = 0xffff;
+	nBestEnd = -1;
+	wPacketSize = usb_maxpacket(pUrb->dev, pipe, nOut);
+	bEnd = usb_pipeendpoint(pipe);
+	bAddress = usb_pipedevice(pipe);
+
+	/* FIXME this doesn't consider direction, so it can only
+	 * work for one half of the endpoint hardware, and assumes
+	 * the previous cases handled all non-shared endpoints...
+	 */
+
+	/* for periodic, use exact match or something ok but unclaimed */
+	spin_lock_irqsave(&pThis->Lock, flags);
+	for (nEnd = 1; nEnd < pThis->bEndCount; nEnd++) {
+		u8	type;
+
+		pEnd = &pThis->aLocalEnd[nEnd];
+		if (nOut) {
+			if (pEnd == pThis->bulk_tx_end)
+				continue;
+			if (pEnd->wMaxPacketSizeTx < wPacketSize)
+				continue;
+			dwDiff = pEnd->wMaxPacketSizeTx - wPacketSize;
+		} else {
+			if (pEnd == pThis->bulk_rx_end)
+				continue;
+			if (pEnd->wMaxPacketSizeRx < wPacketSize)
+				continue;
+			dwDiff = pEnd->wMaxPacketSizeRx - wPacketSize;
+		}
+
+		type = usb_pipein(pipe)
+				? pEnd->in_traffic_type
+				: pEnd->out_traffic_type;
+
+		/* exact match */
+		if ((usb_pipetype(pipe) == type)
+				&& (pEnd->bEnd == bEnd)
+				&& (pEnd->bAddress == bAddress)) {
+			nBestEnd = nEnd;
+			break;
+		}
+
+		/* unclaimed, and a closer match? */
+		if (!pEnd->bIsClaimed && (wBestDiff > dwDiff)) {
+			wBestDiff = (u16) dwDiff;
+			nBestEnd = nEnd;
+		}
+	}
+	spin_unlock_irqrestore(&pThis->Lock, flags);
+
+	DBG(4, "(out=%d, size=%d, proto=%d, addr=%d, end=%d, urb=%lx) = %d\n",
+	    nOut, wPacketSize, usb_pipetype(pipe),
+	    bAddress, bEnd, (unsigned long)pUrb,
+	    nBestEnd);
+
+	if (nBestEnd >= 0)
+		return pThis->aLocalEnd + nBestEnd;
+	return NULL;
+}
+
+/*
+ * Submit an URB, either to the virtual root hut or to a real device;
+ * This is called by the Linux USB core. TSubmit Urb lock pThis
+ * and the End to use, so make sure the caller releases its locks.
+ *
+ * also set the hcpriv member to the localEnd
+ *
+ * @param pUrb URB pointer (urb = USB request block data structure)
+ * @return status code (0 succes)
+ */
+static int musb_submit_urb(struct urb *pUrb, gfp_t iMemFlags)
+{
+	unsigned long		flags;
+	unsigned int		pipe = pUrb->pipe;
+	struct musb_hw_ep	*pEnd;
+	struct musb		*pThis;
+	int			nEnd, idle = 0;
+	int			status;
+	enum dma_data_direction	maptype = DMA_NONE;
+
+	pThis = pUrb->dev->bus->hcpriv;
+
+	/* root hub requests are OK except in peripheral-only mode */
+	if (pThis->board_mode == MUSB_PERIPHERAL)
+		return -ENODEV;
+	if (!pUrb->dev->parent)
+		return MGC_VirtualHubSubmitUrb(&(pThis->RootHub), pUrb);
+
+	/* for other devices, host role must be active */
+	if (!is_host_active(pThis))
+		return -ENODEV;
+
+	/* find appropriate local endpoint to do it */
+	pEnd = musb_find_ep(pThis, pUrb);
+	if (!pEnd)
+		return -EBUSY;
+	nEnd = pEnd->bLocalEnd;
+
+	DBG(6, "pUrb=%p, end=%d, bufsize=%d\n",
+			pUrb, nEnd, pUrb->transfer_buffer_length);
+
+	/* setup DMA mapping, if needed (does dcache sync)
+	 * insist on either a PIO or DMA buffer
+	 */
+	if (is_dma_capable()
+			&& nEnd
+			&& pThis->controller->dma_mask
+			&& pUrb->transfer_buffer_length >= MIN_DMA_REQUEST) {
+		if (!(pUrb->transfer_flags & URB_NO_TRANSFER_DMA_MAP)) {
+			maptype = usb_pipein(pipe)
+						? DMA_FROM_DEVICE
+						: DMA_TO_DEVICE;
+			pUrb->transfer_dma = dma_map_single(pThis->controller,
+					pUrb->transfer_buffer,
+					pUrb-> transfer_buffer_length,
+					maptype);
+		}
+	} else if (pUrb->transfer_buffer == NULL
+			&& pUrb->transfer_buffer_length != 0) {
+		/* FIXME release pEnd claim, for periodic endpoint */
+		return -EINVAL;
+	} else
+		pUrb->transfer_dma = 0;
+
+	/* if no root device, assume this must be it */
+	if (!pThis->pRootDevice)
+		pThis->pRootDevice = usb_get_dev(pUrb->dev);
+
+	/* reserve new periodic bandwidth, unless this endpoint has
+	 * already had its bandwidth reserved.
+	 *
+	 * FIXME but do it right.  For now we can just rely on the
+	 * fact that we don't make enough endpoints available to
+	 * overcommit bandwidth except maybe for fullspeed ISO.
+	 * Two low-rate interrupt transfers and we're full...
+	 */
+	if (usb_pipeisoc(pipe) || usb_pipeint(pipe)) {
+		pUrb->start_frame = musb_readw(pThis->pRegs, MGC_O_HDRC_FRAME)
+				+ pUrb->interval;
+	}
+
+	/* FIXME for reserved bulk endpoints, stick it in the relevant
+	 * ring of endpoints ...
+	 */
+
+	DBG(6, "end %d claimed for type=%d, addr=%d, end=%d\n", nEnd,
+	    usb_pipetype(pipe), usb_pipedevice(pipe), usb_pipeendpoint(pipe));
+
+	pEnd = &(pThis->aLocalEnd[nEnd]);
+
+	/* increment reference counts, neither urb nor device may vanish yet */
+	pUrb = usb_get_urb(pUrb);
+	usb_get_dev(pUrb->dev);
+
+	/* queue & start */
+	spin_lock_irqsave(&pThis->Lock, flags);
+	if (usb_pipein(pipe) || pEnd->bIsSharedFifo)
+		idle = !pEnd->in_busy && list_empty(&pEnd->in_urb_list);
+	else
+		idle = !pEnd->out_busy && list_empty(&pEnd->out_urb_list);
+
+	pEnd->bIsClaimed = 1;
+
+	/* assign the URB to the endpoint */
+	spin_lock(&pUrb->lock);
+	if (unlikely(pUrb->reject)) {
+		INIT_LIST_HEAD(&pUrb->urb_list);
+		status = -EPERM;
+	} else {
+		status = 0;
+		pUrb->error_count = 0;
+		list_add_tail(&pUrb->urb_list, &pEnd->urb_list);
+		pUrb->hcpriv = pEnd;
+		atomic_inc(&pUrb->use_count);
+	}
+	spin_unlock(&pUrb->lock);
+	if (status) {
+		usb_put_dev(pUrb->dev);
+		usb_put_urb(pUrb);
+		goto unmap;
+	}
+
+	DBG(4, "submit %p hw%d, dev%d ep%d%s, len %d\n",
+			pUrb, nEnd,
+			usb_pipedevice(pipe),
+			usb_pipeendpoint(pipe),
+			usb_pipein(pipe) ? "in" : "out",
+			pUrb->transfer_buffer_length
+			);
+
+
+	if (idle)
+		musb_start_urb(pThis, pEnd);
+	spin_unlock_irqrestore(&pThis->Lock, flags);
+
+	return status;
+unmap:
+	spin_unlock_irqrestore(&pThis->Lock, flags);
+	if (is_dma_capable() && maptype != DMA_NONE)
+		dma_unmap_single(pThis->controller, pUrb->transfer_dma,
+				pUrb->transfer_buffer_length,
+				maptype);
+	return status;
+}
+
+
+/*
+ * abort a transfer that's at the head of a hardware queue.
+ * called with controller locked, irqs blocked
+ */
+static int musb_cleanup_urb(struct urb *urb, struct musb_hw_ep *ep, int is_in)
+{
+	unsigned	hw_end = ep->bLocalEnd;
+	void __iomem	*regs = ep->musb->pRegs;
+	u16		csr;
+	int		status = 0;
+
+	MGC_SelectEnd(ep->musb->pRegs, hw_end);
+
+	if (is_dma_capable() && ep->pDmaChannel) {
+		status = ep->musb->pDmaController->pfDmaAbortChannel(
+				ep->pDmaChannel);
+		DBG(status ? 1 : 3, "abort %cX%d DMA for urb %p --> %d\n",
+			is_in ? 'R' : 'T', ep->bLocalEnd, urb, status);
+	}
+
+	/* turn off DMA requests, discard state, stop polling ... */
+	if (is_in) {
+
+// SCRUB (RX)
+		csr = MGC_ReadCsr16(regs, MGC_O_HDRC_RXCSR, hw_end);
+		csr &= ~( MGC_M_RXCSR_AUTOCLEAR
+			| MGC_M_RXCSR_H_AUTOREQ
+			| MGC_M_RXCSR_H_REQPKT
+			| MGC_M_RXCSR_DMAENAB
+			| MGC_M_RXCSR_H_RXSTALL
+			| MGC_M_RXCSR_DATAERROR
+			| MGC_M_RXCSR_H_ERROR
+			| MGC_M_RXCSR_RXPKTRDY
+			);
+		csr |= MGC_M_RXCSR_FLUSHFIFO;
+		MGC_WriteCsr16(regs, MGC_O_HDRC_RXCSR, 0, csr);
+		MGC_WriteCsr16(regs, MGC_O_HDRC_RXCSR, 0, csr);
+	} else {
+// SCRUB (TX)
+		csr = MGC_ReadCsr16(regs, MGC_O_HDRC_TXCSR, hw_end);
+		csr &= ~( MGC_M_TXCSR_AUTOSET
+			| MGC_M_TXCSR_DMAENAB
+			| MGC_M_TXCSR_H_RXSTALL
+			| MGC_M_TXCSR_H_NAKTIMEOUT
+			| MGC_M_TXCSR_H_ERROR
+			| MGC_M_TXCSR_FIFONOTEMPTY
+			| MGC_M_TXCSR_TXPKTRDY
+			);
+		csr |= MGC_M_TXCSR_FLUSHFIFO;
+		MGC_WriteCsr16(regs, MGC_O_HDRC_TXCSR, 0, csr);
+		MGC_WriteCsr16(regs, MGC_O_HDRC_TXCSR, 0, csr);
+	}
+	if (status == 0)
+		musb_giveback(ep, urb, 0);
+	return status;
+}
+
+/*
+ * Cancel URB.
+ * @param pUrb URB pointer
+ */
+static int musb_unlink_urb(struct urb *pUrb, int status)
+{
+	struct musb		*musb;
+	struct musb_hw_ep	*ep;
+	unsigned		i;
+	unsigned long		flags;
+
+	DBG(4, "urb=%p, dev%d ep%d%s\n", pUrb,
+			usb_pipedevice(pUrb->pipe),
+			usb_pipeendpoint(pUrb->pipe),
+			usb_pipein(pUrb->pipe) ? "in" : "out");
+
+	/* sanity */
+	if (!pUrb || !pUrb->hcpriv)
+		return -EINVAL;
+	if (!pUrb->dev || !pUrb->dev->bus)
+		return -ENODEV;
+	musb = pUrb->dev->bus->hcpriv;
+	if (!musb)
+		return -ENODEV;
+
+	spin_lock_irqsave(&musb->Lock, flags);
+
+	for (i = 0, ep = musb->aLocalEnd; i < MUSB_C_NUM_EPS; i++, ep++)  {
+		struct urb		*urb;
+
+		list_for_each_entry(urb, &ep->urb_list, urb_list) {
+			if (urb == pUrb)
+				goto found;
+		}
+	}
+	status = -ENOENT;
+	goto done;
+
+found:
+	spin_lock(&pUrb->lock);
+	if (pUrb->hcpriv != ep)
+		status = -ENOENT;
+	else if (pUrb->status != -EINPROGRESS)
+		status = -EBUSY;
+	else {
+		pUrb->status = status;
+		status = 0;
+	}
+	spin_unlock(&pUrb->lock);
+
+	if (status)
+		goto done;
+
+	/* if it is a request to the root hub, delegate */
+	if (pUrb->dev == musb->RootHub.pDevice) {
+		spin_unlock_irqrestore(&musb->Lock, flags);
+		/* screwey locking */
+		return MGC_VirtualHubUnlinkUrb(&(musb->RootHub), pUrb);
+	}
+
+	/* anything not at the head of the queue can just be given back,
+	 * else cleanup pending dma etc
+	 */
+	if (pUrb->urb_list.prev != &ep->urb_list) {
+		musb_giveback(ep, pUrb, 0);
+		status = 0;
+	} else {
+		status = musb_cleanup_urb(pUrb, ep, pUrb->pipe & USB_DIR_IN);
+		/* FIXME still needs to restart this queue... it
+		 * may have pending transfers for other endpoints
+		 */
+	}
+
+done:
+	spin_unlock_irqrestore(&musb->Lock, flags);
+	return status;
+}
+
+// 2.6.current can't work without a new version of this routine
+// #error rewrite host endpoint disable routine
+
+/* disable an endpoint */
+static void musb_h_disable(struct usb_device *udev, int epnum)
+{
+	unsigned long		flags;
+	struct musb		*musb = udev->bus->hcpriv;
+	struct musb_hw_ep	*ep;
+	unsigned		i;
+	unsigned		do_wait = 0;
+	u8			is_in = epnum & USB_DIR_IN;
+	u8			epn = epnum & 0x0f;
+
+	/* FIXME 2.6.current passes "struct usb_host_endpoint *hep" as the
+	 * parameter, not "epnum" ... and the endpoint's URBs are provided
+	 * in that structure, so no searching is needed.  (Only a check to
+	 * see if it's at the front of a hardware endpoint's queue ...)
+	 */
+
+	spin_lock_irqsave(&musb->Lock, flags);
+
+	/* more current 2.6 kernels make this much simpler! */
+	for (i = 0, ep = musb->aLocalEnd; i < MUSB_C_NUM_EPS; i++, ep++)  {
+		struct urb		*urb;
+		unsigned		pipe;
+
+rescan:
+		list_for_each_entry(urb, &ep->urb_list, urb_list) {
+#if 0
+dev_dbg(&udev->dev,
+	"disable epnum %02x ... hw%d urb %p head %p (n%p p%p) ?\n",
+	epnum, i, urb, &ep->urb_list,
+	urb->urb_list.next, urb->urb_list.prev
+	);
+#endif
+			if (urb->dev != udev)
+				continue;
+			pipe = urb->pipe;
+			if ((pipe & USB_DIR_IN) != is_in)
+				continue;
+			if (usb_pipeendpoint(pipe) != epn)
+				continue;
+
+			/* REVISIT compiler wierdness ...  gcc 3.4.3/generic
+			 * codegen bug?  behavior was that we'd land here
+			 * despite "urb" having been unlinked already, and so
+			 * not on the endpoint list.  giveback twice --> oops.
+			 * just adding this test prevented the wierdness...
+			 */
+			if (list_empty(&urb->urb_list)) {
+				dev_dbg(&udev->dev,
+					"... wierd, ep %p (n%p p%p) ?\n",
+					ep, ep->urb_list.next,
+					ep->urb_list.prev);
+				continue;
+			}
+
+			/* easy case: the hardware's not touching it */
+			if (ep->urb_list.next != &urb->urb_list) {
+				musb_giveback(ep, urb, -ESHUTDOWN);
+				goto rescan;
+			}
+
+			/* make software (then hardware) stop ASAP */
+			spin_lock(&urb->lock);
+			if (urb->status == -EINPROGRESS)
+				urb->status = -ESHUTDOWN;
+			spin_unlock(&urb->lock);
+
+			/* cleanup */
+			musb_cleanup_urb(urb, ep, urb->pipe & USB_DIR_IN);
+			do_wait++;
+
+			/* REVISIT this _should_ eventually just walk that
+			 * host endpoint's queue directly, once it's found.
+			 *
+			 * FIXME still needs to restart this queue... it
+			 * may have pending transfers for other endpoints
+			 */
+
+			break;
+		}
+	}
+	spin_unlock_irqrestore(&musb->Lock, flags);
+
+	/* REVISIT gives (most) irqs a chance to trigger */
+	if (do_wait)
+		msleep(10);
+}
+
+static void *musb_host_alloc_buffer(struct usb_bus *pBus, size_t nSize,
+				  gfp_t iMemFlags, dma_addr_t * pDmaAddress)
+{
+	return musb_alloc_buffer(pBus->hcpriv, nSize,
+			iMemFlags, pDmaAddress);
+}
+
+static void musb_host_free_buffer(struct usb_bus *pBus, size_t nSize,
+				void *address, dma_addr_t dma)
+{
+	musb_free_buffer(pBus->hcpriv, nSize, address, dma);
+}
+
+/*
+ * Get the current frame number
+ * @param usb_dev pointer to USB device
+ * @return frame number
+ */
+static int musb_h_get_frame_number(struct usb_device *pDevice)
+{
+	struct musb	*pThis = pDevice->bus->hcpriv;
+
+	return musb_readw(pThis->pRegs, MGC_O_HDRC_FRAME);
+}
+
+/* FIXME -- switchover to use the hcd glue layer;
+ * define root hub support with hub suspend/resume calls
+ *
+ * latest mentor code has some of that, plus ULPI calls
+ *
+ * also, kernel.org interfaces now pass a usb_host_endpoint
+ * handle around; "struct hcd_dev" is gone.
+ */
+struct usb_operations musb_host_bus_ops = {
+	.get_frame_number	= musb_h_get_frame_number,
+	.submit_urb		= musb_submit_urb,
+	.unlink_urb		= musb_unlink_urb,
+	.buffer_alloc		= musb_host_alloc_buffer,
+	.buffer_free		= musb_host_free_buffer,
+	.disable		= musb_h_disable,
+};
Index: linux-2.6.10/drivers/usb/musb/musb_host.h
===================================================================
--- /dev/null
+++ linux-2.6.10/drivers/usb/musb/musb_host.h
@@ -0,0 +1,128 @@
+/******************************************************************
+ * Copyright 2005 Mentor Graphics Corporation
+ * Copyright (C) 2005-2006 by Texas Instruments
+ *
+ * This file is part of the Inventra Controller Driver for Linux.
+ *
+ * The Inventra Controller Driver for Linux is free software; you
+ * can redistribute it and/or modify it under the terms of the GNU
+ * General Public License version 2 as published by the Free Software
+ * Foundation.
+ *
+ * The Inventra Controller Driver for Linux is distributed in
+ * the hope that it will be useful, but WITHOUT ANY WARRANTY;
+ * without even the implied warranty of MERCHANTABILITY or
+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public
+ * License for more details.
+ *
+ * You should have received a copy of the GNU General Public License
+ * along with The Inventra Controller Driver for Linux ; if not,
+ * write to the Free Software Foundation, Inc., 59 Temple Place,
+ * Suite 330, Boston, MA  02111-1307  USA
+ *
+ * ANY DOWNLOAD, USE, REPRODUCTION, MODIFICATION OR DISTRIBUTION
+ * OF THIS DRIVER INDICATES YOUR COMPLETE AND UNCONDITIONAL ACCEPTANCE
+ * OF THOSE TERMS.THIS DRIVER IS PROVIDED "AS IS" AND MENTOR GRAPHICS
+ * MAKES NO WARRANTIES, EXPRESS OR IMPLIED, RELATED TO THIS DRIVER.
+ * MENTOR GRAPHICS SPECIFICALLY DISCLAIMS ALL IMPLIED WARRANTIES
+ * OF MERCHANTABILITY; FITNESS FOR A PARTICULAR PURPOSE AND
+ * NON-INFRINGEMENT.  MENTOR GRAPHICS DOES NOT PROVIDE SUPPORT
+ * SERVICES OR UPDATES FOR THIS DRIVER, EVEN IF YOU ARE A MENTOR
+ * GRAPHICS SUPPORT CUSTOMER.
+ ******************************************************************/
+
+#ifndef _MUSB_HOST_H
+#define _MUSB_HOST_H
+
+/* host side representation of one hardware transfer channel, bound
+ * during transfers to the peripheral endpoint addressed by urb->pipe.
+ */
+struct musb_host_ep {
+	unsigned		tx:1;
+
+	unsigned		claimed:1;	/* unavailable for binding? */
+	unsigned		busy:1;		/* unsafe to touch hw? */
+	unsigned		ready:1;
+
+	/* address and type of current peripheral endpoint */
+	u8			remote_addr;
+	u8			remote_end;
+
+	u8			type;
+	u16			max_packet;
+
+	/* transfer state */
+	u16			wait_frame;
+
+	unsigned int		offset;
+	unsigned int		request_size;
+	unsigned int		iso_packet;	/* index into urb */
+
+	/* FIXME just hook into a separate schedule data structure.
+	 * When scheduling is this closely coupled to hardware, we
+	 * waste resources in ways that are surprising to users.
+	 */
+	struct urb		*urb;
+	struct list_head	urb_list;
+	// struct musb_sched_node	*next;
+};
+
+
+/* in newer 2.6 kernels, something like this should be the schedule data
+ * structure stored in "usb_host_endpoint.hcpriv"; store it there when
+ * queueing the first URB, remove when usb_host_endpoint.urb_list empties.
+ */
+struct musb_sched_node {
+	struct usb_host_endpoint *host_ep;	/* usbcore info */
+	struct usb_device	*dev;
+	struct musb_host_ep	*ep;		/* current binding */
+	struct list_head	ring;		/* of host_ep */
+	struct musb_sched_node	*next;		/* for periodic tree */
+};
+
+
+extern void MGC_HdrcStartTx(struct musb *, u8 bEnd);
+
+extern void MGC_HdrcStopEnd(struct musb *, u8 bEnd);
+
+static inline struct urb *MGC_GetCurrentUrb(struct musb_hw_ep *pEnd)
+{
+#ifdef CONFIG_USB_MUSB_HDRC_HCD
+	return list_empty(&(pEnd->urb_list)) ? NULL
+	    : list_entry(pEnd->urb_list.next, struct urb, urb_list);
+#else
+	return NULL;
+#endif
+}
+
+extern void musb_root_disconnect(struct musb *musb);
+
+extern struct usb_operations musb_host_bus_ops;
+
+static inline struct urb *next_in_urb(struct musb_hw_ep *hw_ep)
+{
+#ifdef CONFIG_USB_MUSB_HDRC_HCD
+	struct list_head	*queue = &hw_ep->in_urb_list;
+
+	if (list_empty(queue))
+		return NULL;
+	return container_of(queue->next, struct urb, urb_list);
+#else
+	return NULL;
+#endif
+}
+
+static inline struct urb *next_out_urb(struct musb_hw_ep *hw_ep)
+{
+#ifdef CONFIG_USB_MUSB_HDRC_HCD
+	struct list_head	*queue = &hw_ep->out_urb_list;
+
+	if (list_empty(queue))
+		return NULL;
+	return container_of(queue->next, struct urb, urb_list);
+#else
+	return NULL;
+#endif
+}
+
+#endif				/* _MUSB_HOST_H */
Index: linux-2.6.10/drivers/usb/musb/musb_procfs.c
===================================================================
--- /dev/null
+++ linux-2.6.10/drivers/usb/musb/musb_procfs.c
@@ -0,0 +1,756 @@
+/******************************************************************
+ * Copyright 2005 Mentor Graphics Corporation
+ * Copyright (C) 2005-2006 by Texas Instruments
+ *
+ * This file is part of the Inventra Controller Driver for Linux.
+ *
+ * The Inventra Controller Driver for Linux is free software; you
+ * can redistribute it and/or modify it under the terms of the GNU
+ * General Public License version 2 as published by the Free Software
+ * Foundation.
+ *
+ * The Inventra Controller Driver for Linux is distributed in
+ * the hope that it will be useful, but WITHOUT ANY WARRANTY;
+ * without even the implied warranty of MERCHANTABILITY or
+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public
+ * License for more details.
+ *
+ * You should have received a copy of the GNU General Public License
+ * along with The Inventra Controller Driver for Linux ; if not,
+ * write to the Free Software Foundation, Inc., 59 Temple Place,
+ * Suite 330, Boston, MA  02111-1307  USA
+ *
+ * ANY DOWNLOAD, USE, REPRODUCTION, MODIFICATION OR DISTRIBUTION
+ * OF THIS DRIVER INDICATES YOUR COMPLETE AND UNCONDITIONAL ACCEPTANCE
+ * OF THOSE TERMS.THIS DRIVER IS PROVIDED "AS IS" AND MENTOR GRAPHICS
+ * MAKES NO WARRANTIES, EXPRESS OR IMPLIED, RELATED TO THIS DRIVER.
+ * MENTOR GRAPHICS SPECIFICALLY DISCLAIMS ALL IMPLIED WARRANTIES
+ * OF MERCHANTABILITY; FITNESS FOR A PARTICULAR PURPOSE AND
+ * NON-INFRINGEMENT.  MENTOR GRAPHICS DOES NOT PROVIDE SUPPORT
+ * SERVICES OR UPDATES FOR THIS DRIVER, EVEN IF YOU ARE A MENTOR
+ * GRAPHICS SUPPORT CUSTOMER.
+ ******************************************************************/
+
+/*
+ * Inventra Controller Driver (ICD) for Linux.
+ *
+ * The code managing debug files (currently in procfs).
+ */
+
+#include <linux/config.h>
+#include <linux/kernel.h>
+#include <linux/proc_fs.h>
+#include <linux/seq_file.h>
+#include <linux/usb.h>
+#include <asm/uaccess.h>	/* FIXME remove procfs writes */
+
+#include "musbdefs.h"
+
+#include "davinci.h"
+
+
+#ifdef CONFIG_USB_MUSB_OTG
+
+static const char *state_string(enum usb_otg_state state)
+{
+	switch (state) {
+	case OTG_STATE_A_IDLE:		return "a_idle";
+	case OTG_STATE_A_WAIT_VRISE:	return "a_wait_vrise";
+	case OTG_STATE_A_WAIT_BCON:	return "a_wait_bcon";
+	case OTG_STATE_A_HOST:		return "a_host";
+	case OTG_STATE_A_SUSPEND:	return "a_suspend";
+	case OTG_STATE_A_PERIPHERAL:	return "a_peripheral";
+	case OTG_STATE_A_WAIT_VFALL:	return "a_wait_vfall";
+	case OTG_STATE_A_VBUS_ERR:	return "a_vbus_err";
+	case OTG_STATE_B_IDLE:		return "b_idle";
+	case OTG_STATE_B_SRP_INIT:	return "b_srp_init";
+	case OTG_STATE_B_PERIPHERAL:	return "b_peripheral";
+	case OTG_STATE_B_WAIT_ACON:	return "b_wait_acon";
+	case OTG_STATE_B_HOST:		return "b_host";
+	default:			return "UNDEFINED";
+	}
+}
+
+#endif
+
+#ifdef CONFIG_USB_MUSB_HDRC_HCD
+static int dump_urbs(struct list_head *list, char *buf, unsigned max)
+{
+	int		count = 0;
+	int		tmp;
+	struct urb	*urb;
+
+	if (list_empty(list))
+		return snprintf(buf, max, "\t(queue empty)\n");
+
+	list_for_each_entry(urb, list, urb_list) {
+		const unsigned 	pipe = urb->pipe;
+
+		/* for non-multipoint, urb->dev never changes */
+		tmp = snprintf(buf, max,
+				"\turb %p dev%d ep%d%s-%s %d/%d\n",
+				urb, urb->dev->devnum,
+				usb_pipeendpoint(pipe),
+				usb_pipein(pipe) ? "in" : "out",
+				({ char *s; switch(usb_pipetype(pipe)){
+				 case PIPE_BULK:	s = "bulk"; break;
+				 case PIPE_INTERRUPT:	s = "int"; break;
+				 case PIPE_CONTROL:	s = "control"; break;
+				 default:		s = "iso"; break;
+				 }; s; }),
+				urb->actual_length,
+				urb->transfer_buffer_length);
+		if (tmp < 0)
+			break;
+		tmp = min(tmp, (int)max);
+		count += tmp;
+		buf += tmp;
+		max -= tmp;
+	}
+	return count;
+}
+#endif
+
+#ifdef CONFIG_USB_GADGET_MUSB_HDRC
+static int dump_ep(struct musb_ep *ep, char *buffer, unsigned max)
+{
+	char		*buf = buffer;
+	int		code = 0;
+	void __iomem	*regs = ep->pThis->pRegs;
+
+	do {
+		struct usb_request	*req;
+
+		code = snprintf(buf, max,
+				"\n%s (hw%d): %scsr %04x maxp %04x\n",
+				ep->name, ep->bEndNumber,
+				ep->dma ? "dma, " : "",
+				MGC_ReadCsr16(regs,
+					(ep->is_in || !ep->bEndNumber)
+						? MGC_O_HDRC_TXCSR
+						: MGC_O_HDRC_RXCSR,
+					ep->bEndNumber),
+				MGC_ReadCsr16(regs,
+					ep->is_in
+						? MGC_O_HDRC_TXMAXP
+						: MGC_O_HDRC_RXMAXP,
+					ep->bEndNumber)
+				);
+		if (code < 0)
+			break;
+		code = min(code, (int) max);
+		buf += code;
+		max -= code;
+
+#ifdef	CONFIG_USB_TI_CPPI_DMA
+		if (ep->bEndNumber) {
+			unsigned	cppi = ep->bEndNumber - 1;
+			void __iomem	*base = ep->pThis->ctrl_base;
+			unsigned	off1 = cppi << 2;
+			void __iomem	*ram = base;
+			char		tmp[16];
+
+			if (ep->is_in) {
+				ram += DAVINCI_TXCPPI_STATERAM_OFFSET(cppi);
+				tmp[0] = 0;
+			} else {
+				ram += DAVINCI_RXCPPI_STATERAM_OFFSET(cppi);
+				snprintf(tmp, sizeof tmp, "%d left, ",
+					musb_readl(base,
+					DAVINCI_RXCPPI_BUFCNT0_REG + off1));
+			}
+
+			code = snprintf(buf, max, "%cX DMA%d: %s"
+					"%08x %08x, %08x %08x; "
+					"%08x %08x %08x .. %08x\n",
+				ep->is_in ? 'T' : 'R',
+				ep->bEndNumber - 1, tmp,
+				musb_readl(ram, 0 * 4),
+				musb_readl(ram, 1 * 4),
+				musb_readl(ram, 2 * 4),
+				musb_readl(ram, 3 * 4),
+				musb_readl(ram, 4 * 4),
+				musb_readl(ram, 5 * 4),
+				musb_readl(ram, 6 * 4),
+				musb_readl(ram, 7 * 4));
+			if (code < 0)
+				break;
+			code = min(code, (int) max);
+			buf += code;
+			max -= code;
+		}
+#endif
+
+		if (list_empty(&ep->req_list)) {
+			code = snprintf(buf, max, "\t(queue empty)\n");
+			if (code < 0)
+				break;
+			code = min(code, (int) max);
+			buf += code;
+			max -= code;
+			break;
+		}
+		list_for_each_entry (req, &ep->req_list, list) {
+			code = snprintf(buf, max, "\treq %p, %s%s%d/%d\n",
+					req,
+					req->zero ? "zero, " : "",
+					req->short_not_ok ? "!short, " : "",
+					req->actual, req->length);
+			if (code < 0)
+				break;
+			code = min(code, (int) max);
+			buf += code;
+			max -= code;
+		}
+	} while(0);
+	return (buf > buffer) ? (buf - buffer) : code;
+}
+#endif
+
+static int
+dump_end_info(struct musb *pThis, u8 bEnd, char *aBuffer, unsigned max)
+{
+	int code = 0;
+	char *buf = aBuffer;
+	struct musb_hw_ep *pEnd = &pThis->aLocalEnd[bEnd];
+
+	do {
+		MGC_SelectEnd(pThis->pRegs, bEnd);
+#ifdef CONFIG_USB_MUSB_HDRC_HCD
+		if (is_host_active(pThis)) {
+			int dump_rx, dump_tx;
+
+			/* TEMPORARY (!) until host handles both
+			 * directions of the hardware
+			 */
+			if (pEnd->bIsSharedFifo) {
+				/* control is shared, uses RX queue
+				 * but (mostly) shadowed tx registers
+				 */
+				if (!bEnd)
+					dump_tx = 1;
+				else {
+					if (!pEnd->bIsClaimed)
+						break;
+
+					/* presumably interrupt-IN...
+					 * THIS IS A GUESS
+					 * (could look at the queue)
+					 */
+					dump_tx = 0;
+				}
+
+				dump_rx = !dump_tx;
+
+			} else if (pEnd == pThis->bulk_tx_end) {
+				dump_tx = 1;
+				dump_rx = 0;
+			} else if (pEnd == pThis->bulk_rx_end) {
+				dump_tx = 0;
+				dump_rx = 1;
+			} else {
+				dump_rx = pEnd->wMaxPacketSizeRx;
+				dump_tx = pEnd->wMaxPacketSizeTx;
+			}
+			/* END TEMPORARY */
+
+
+			/* FIXME for rx and tx dump hardware fifo and
+			 * double-buffer flags ... and make register and stat
+			 * dumps (mostly) usable on the peripheral side too
+			 */
+			if (dump_rx) {
+				code = snprintf(buf, max,
+					"\nEnd-%d:  rxcsr %04x interval %02x "
+					"max %04x type %02x; "
+					"dev %d hub %d port %d"
+					"\n",
+					bEnd,
+					MGC_ReadCsr16(pThis->pRegs,
+						MGC_O_HDRC_RXCSR,
+						bEnd),
+					MGC_ReadCsr8(pThis->pRegs,
+						MGC_O_HDRC_RXINTERVAL,
+						bEnd),
+					MGC_ReadCsr16(pThis->pRegs,
+						MGC_O_HDRC_RXMAXP,
+						bEnd),
+					MGC_ReadCsr8(pThis->pRegs,
+						MGC_O_HDRC_RXTYPE,
+						bEnd),
+					/* FIXME:  assumes multipoint */
+					musb_readb(pThis->pRegs,
+						MGC_BUSCTL_OFFSET(bEnd,
+						MGC_O_HDRC_RXFUNCADDR)),
+					musb_readb(pThis->pRegs,
+						MGC_BUSCTL_OFFSET(bEnd,
+						MGC_O_HDRC_RXHUBADDR)),
+					musb_readb(pThis->pRegs,
+						MGC_BUSCTL_OFFSET(bEnd,
+						MGC_O_HDRC_RXHUBPORT))
+					);
+				if (code < 0)
+					break;
+				code = min(code, (int) max);
+				buf += code;
+				max -= code;
+
+#ifdef	CONFIG_USB_TI_CPPI_DMA
+				if (bEnd && pEnd->pDmaChannel) {
+					unsigned	cppi = bEnd - 1;
+					unsigned	off1 = cppi << 2;
+					void __iomem	*base;
+					void __iomem	*ram;
+					char		tmp[16];
+
+					base = pThis->ctrl_base;
+					ram = base + DAVINCI_RXCPPI_STATERAM_OFFSET(cppi);
+					snprintf(tmp, sizeof tmp, "%d left, ",
+						musb_readl(base,
+						DAVINCI_RXCPPI_BUFCNT0_REG
+								+ off1));
+
+					code = snprintf(buf, max,
+						"    rx dma%d: %s"
+						"%08x %08x, %08x %08x; "
+						"%08x %08x %08x .. %08x\n",
+						cppi, tmp,
+						musb_readl(ram, 0 * 4),
+						musb_readl(ram, 1 * 4),
+						musb_readl(ram, 2 * 4),
+						musb_readl(ram, 3 * 4),
+						musb_readl(ram, 4 * 4),
+						musb_readl(ram, 5 * 4),
+						musb_readl(ram, 6 * 4),
+						musb_readl(ram, 7 * 4));
+					if (code < 0)
+						break;
+					code = min(code, (int) max);
+					buf += code;
+					max -= code;
+				}
+#endif
+				code = dump_urbs(&pEnd->urb_list,
+						buf, max);
+				if (code < 0)
+					break;
+				code = min(code, (int) max);
+				buf += code;
+				max -= code;
+			}
+
+			if (dump_tx) {
+				code = snprintf(buf, max,
+					"End-%d:  txcsr %04x interval %02x "
+					"max %04x type %02x; "
+					"dev %d hub %d port %d"
+					"\n",
+					bEnd,
+					MGC_ReadCsr16(pThis->pRegs,
+						MGC_O_HDRC_TXCSR,
+						bEnd),
+					MGC_ReadCsr8(pThis->pRegs,
+						MGC_O_HDRC_TXINTERVAL,
+						bEnd),
+					MGC_ReadCsr16(pThis->pRegs,
+						MGC_O_HDRC_TXMAXP,
+						bEnd),
+					MGC_ReadCsr8(pThis->pRegs,
+						MGC_O_HDRC_TXTYPE,
+						bEnd),
+					/* FIXME:  assumes multipoint */
+					musb_readb(pThis->pRegs,
+						MGC_BUSCTL_OFFSET(bEnd,
+						MGC_O_HDRC_TXFUNCADDR)),
+					musb_readb(pThis->pRegs,
+						MGC_BUSCTL_OFFSET(bEnd,
+						MGC_O_HDRC_TXHUBADDR)),
+					musb_readb(pThis->pRegs,
+						MGC_BUSCTL_OFFSET(bEnd,
+						MGC_O_HDRC_TXHUBPORT))
+					);
+				if (code < 0)
+					break;
+				code = min(code, (int) max);
+				buf += code;
+				max -= code;
+#ifdef	CONFIG_USB_TI_CPPI_DMA
+				if (bEnd && pEnd->pDmaChannel) {
+					unsigned	cppi = bEnd - 1;
+					void __iomem	*base;
+					void __iomem	*ram;
+
+					base = pThis->ctrl_base;
+					ram = base + DAVINCI_TXCPPI_STATERAM_OFFSET(cppi);
+					code = snprintf(buf, max,
+						"    tx dma%d: "
+						"%08x %08x, %08x %08x; "
+						"%08x %08x %08x .. %08x\n",
+						cppi,
+						musb_readl(ram, 0 * 4),
+						musb_readl(ram, 1 * 4),
+						musb_readl(ram, 2 * 4),
+						musb_readl(ram, 3 * 4),
+						musb_readl(ram, 4 * 4),
+						musb_readl(ram, 5 * 4),
+						musb_readl(ram, 6 * 4),
+						musb_readl(ram, 7 * 4));
+					if (code < 0)
+						break;
+					code = min(code, (int) max);
+					buf += code;
+					max -= code;
+				}
+#endif
+				code = dump_urbs(&pEnd->urb_list, buf, max);
+				if (code < 0)
+					break;
+				code = min(code, (int) max);
+				buf += code;
+				max -= code;
+			}
+		}
+#endif
+#ifdef CONFIG_USB_GADGET_MUSB_HDRC
+		if (is_peripheral_active(pThis)) {
+			code = 0;
+
+			if (pEnd->ep_in.desc || !bEnd) {
+				code = dump_ep(&pEnd->ep_in, buf, max);
+				if (code < 0)
+					break;
+				code = min(code, (int) max);
+				buf += code;
+				max -= code;
+			}
+			if (pEnd->ep_out.desc) {
+				code = dump_ep(&pEnd->ep_out, buf, max);
+				if (code < 0)
+					break;
+				code = min(code, (int) max);
+				buf += code;
+				max -= code;
+			}
+		}
+#endif
+	} while (0);
+
+	return buf - aBuffer;
+}
+
+/** Dump the current status and compile options.
+ * @param pThis the device driver instance
+ * @param buffer where to dump the status; it must be big enough hold the
+ * result otherwise "BAD THINGS HAPPENS(TM)".
+ */
+static int dump_header_stats(struct musb *pThis, char *buffer)
+{
+	int code, count = 0;
+	const void __iomem *pBase = pThis->pRegs;
+
+	*buffer = 0;
+	count = sprintf(buffer, "Status: %sHDRC, Mode=%s "
+				"(Power=%02x, DevCtl=%02x)\n",
+			(pThis->bIsMultipoint ? "M" : ""), MUSB_MODE(pThis),
+			musb_readb(pBase, MGC_O_HDRC_POWER),
+			musb_readb(pBase, MGC_O_HDRC_DEVCTL));
+	if (count < 0)
+		return count;
+	buffer += count;
+
+#ifdef CONFIG_USB_MUSB_OTG
+	code = sprintf(buffer, "OTG state: %s (%s)\n",
+		state_string(pThis->OtgMachine.bState),
+		state_string(pThis->xceiv.state));
+	if (code < 0)
+		return code;
+	buffer += code;
+	count += code;
+#endif
+
+	code = sprintf(buffer,
+			"Options: "
+#ifdef CONFIG_USB_INVENTRA_FIFO
+			"[pio]"
+#elif defined(CONFIG_USB_TI_CPPI_DMA)
+			"[cppi-dma]"
+#elif defined(CONFIG_USB_INVENTRA_DMA)
+			"[musb-dma]"
+#else
+			"[?]"
+#endif
+			" "
+#ifdef CONFIG_USB_MUSB_OTG
+			"[otg: peripheral+host]"
+#elif defined(CONFIG_USB_GADGET_MUSB_HDRC)
+			"[peripheral]"
+#elif defined(CONFIG_USB_MUSB_HDRC_HCD)
+			"[host]"
+#endif
+			" [debug=%d] [eps=%d]\n",
+		MGC_GetDebugLevel(), pThis->bEndCount);
+	if (code < 0)
+		return code;
+	count += code;
+	buffer += code;
+
+#ifdef	CONFIG_ARCH_DAVINCI
+	code = sprintf(buffer,
+			"DaVinci: ctrl=%02x stat=%1x phy=%03x\n"
+			"\trndis=%05x auto=%04x intsrc=%08x intmsk=%08x"
+			"\n",
+			musb_readl(pThis->ctrl_base, DAVINCI_USB_CTRL_REG),
+			musb_readl(pThis->ctrl_base, DAVINCI_USB_STAT_REG),
+			__raw_readl(IO_ADDRESS(USBPHY_CTL_PADDR)),
+			musb_readl(pThis->ctrl_base, DAVINCI_RNDIS_REG),
+			musb_readl(pThis->ctrl_base, DAVINCI_AUTOREQ_REG),
+			musb_readl(pThis->ctrl_base,
+					DAVINCI_USB_INT_SOURCE_REG),
+			musb_readl(pThis->ctrl_base,
+					DAVINCI_USB_INT_MASK_REG));
+	if (code < 0)
+		return count;
+	count += code;
+	buffer += code;
+#endif	/* DAVINCI */
+
+#ifdef	CONFIG_USB_TI_CPPI_DMA
+	code = sprintf(buffer,
+			"CPPI: txcr=%d txsrc=%01x txena=%01x; "
+			"rxcr=%d rxsrc=%01x rxena=%01x "
+			"\n",
+			musb_readl(pThis->ctrl_base, DAVINCI_TXCPPI_CTRL_REG),
+			musb_readl(pThis->ctrl_base, DAVINCI_TXCPPI_RAW_REG),
+			musb_readl(pThis->ctrl_base,
+				DAVINCI_TXCPPI_INTENAB_REG),
+			musb_readl(pThis->ctrl_base, DAVINCI_RXCPPI_CTRL_REG),
+			musb_readl(pThis->ctrl_base, DAVINCI_RXCPPI_RAW_REG),
+			musb_readl(pThis->ctrl_base,
+				DAVINCI_RXCPPI_INTENAB_REG));
+	if (code < 0)
+		return count;
+	count += code;
+	buffer += code;
+#endif	/* CPPI */
+
+#ifdef CONFIG_USB_GADGET_MUSB_HDRC
+	if (is_peripheral_enabled(pThis)) {
+		code = sprintf(buffer, "Gadget driver: %s\n",
+				pThis->pGadgetDriver
+					? pThis->pGadgetDriver->driver.name
+					: "(none)");
+		if (code < 0)
+			return code;
+		count += code;
+		buffer += code;
+	}
+#endif
+
+	return count;
+}
+
+/* Write to ProcFS
+ *
+ * C soft-connect
+ * c soft-disconnect
+ * I enable HS
+ * i disable HS
+ * s stop session
+ * F force session (OTG-unfriendly)
+ * E rElinquish bus (OTG)
+ * H request host mode
+ * h cancel host request
+ * D<num> set/query the debug level
+ */
+static int musb_proc_write(struct file *file, const char __user *buffer,
+			 unsigned long count, void *data)
+{
+	char cmd;
+	u8 bReg;
+	void __iomem *pBase = ((struct musb *) data)->pRegs;
+
+	/* MOD_INC_USE_COUNT; */
+
+	copy_from_user(&cmd, buffer, 1);
+	switch (cmd) {
+	case 'C':
+		if (pBase) {
+			bReg =
+			    musb_readb(pBase,
+				      MGC_O_HDRC_POWER) | MGC_M_POWER_SOFTCONN;
+			musb_writeb(pBase, MGC_O_HDRC_POWER, bReg);
+		}
+		break;
+
+	case 'c':
+		if (pBase) {
+			bReg =
+			    musb_readb(pBase,
+				      MGC_O_HDRC_POWER) & ~MGC_M_POWER_SOFTCONN;
+			musb_writeb(pBase, MGC_O_HDRC_POWER, bReg);
+		}
+		break;
+
+	case 'I':
+		if (pBase) {
+			bReg =
+			    musb_readb(pBase,
+				      MGC_O_HDRC_POWER) | MGC_M_POWER_HSENAB;
+			musb_writeb(pBase, MGC_O_HDRC_POWER, bReg);
+		}
+		break;
+
+	case 'i':
+		if (pBase) {
+			bReg =
+			    musb_readb(pBase,
+				      MGC_O_HDRC_POWER) & ~MGC_M_POWER_HSENAB;
+			musb_writeb(pBase, MGC_O_HDRC_POWER, bReg);
+		}
+		break;
+
+	case 'F':
+		bReg = musb_readb(pBase, MGC_O_HDRC_DEVCTL);
+		bReg |= MGC_M_DEVCTL_SESSION;
+		musb_writeb(pBase, MGC_O_HDRC_DEVCTL, bReg);
+		break;
+
+	case 'H':
+		if (pBase) {
+			bReg = musb_readb(pBase, MGC_O_HDRC_DEVCTL);
+			bReg |= MGC_M_DEVCTL_HR;
+			musb_writeb(pBase, MGC_O_HDRC_DEVCTL, bReg);
+			//MUSB_HST_MODE( ((struct musb*)data) );
+			//WARN("Host Mode\n");
+		}
+		break;
+
+	case 'h':
+		if (pBase) {
+			bReg = musb_readb(pBase, MGC_O_HDRC_DEVCTL);
+			bReg &= ~MGC_M_DEVCTL_HR;
+			musb_writeb(pBase, MGC_O_HDRC_DEVCTL, bReg);
+		}
+		break;
+
+#if (MUSB_DEBUG>0)
+		/* set/read debug level */
+	case 'D':{
+			if (count > 1) {
+				char digits[8], *p = digits;
+				int i = 0, level = 0, sign = 1, len =
+				    min(count - 1, (unsigned long)8);
+
+				copy_from_user(&digits, &buffer[1], len);
+
+				/* optional sign */
+				if (*p == '-') {
+					len -= 1;
+					sign = -sign;
+					p++;
+				}
+
+				/* read it */
+				while (i++ < len && *p > '0' && *p < '9') {
+					level = level * 10 + (*p - '0');
+					p++;
+				}
+
+				level *= sign;
+				DBG(1, "debug level %d\n", level);
+				MGC_SetDebugLevel(level);
+			}
+		}
+		break;
+
+
+	case '?':
+		INFO("?: you are seeing it\n");
+		INFO("C/c: soft connect enable/disable\n");
+		INFO("I/i: hispeed enable/disable\n");
+		INFO("F: force session start\n");
+		INFO("H: host mode\n");
+		INFO("D: set/read dbug level\n");
+		break;
+#endif
+
+	default:
+		ERR("Command %c not implemented\n", cmd);
+		break;
+	}
+
+	return count;
+}
+
+static int musb_proc_read(char *page, char **start,
+			off_t off, int count, int *eof, void *data)
+{
+	char *buffer = page;
+	int code = 0;
+	unsigned long	flags;
+	struct musb	*pThis = data;
+	unsigned	bEnd;
+
+	count -= off;
+	count -= 1;		/* for NUL at end */
+	if (count < 0)
+		return -EINVAL;
+
+	spin_lock_irqsave(&pThis->Lock, flags);
+
+	code = dump_header_stats(pThis, buffer);
+	if (code > 0) {
+		buffer += code;
+		count -= code;
+	}
+
+	/* generate the report for the end points */
+	// REVISIT ... not unless something's connected!
+	for (bEnd = 0; count >= 0 && bEnd < pThis->bEndCount;
+			bEnd++) {
+		code = dump_end_info(pThis, bEnd, buffer, count);
+		if (code > 0) {
+			buffer += code;
+			count -= code;
+		}
+	}
+
+	spin_unlock_irqrestore(&pThis->Lock, flags);
+	*eof = 1;
+	return (buffer - page) - off;
+}
+
+void __exit musb_debug_delete(char *name, struct musb *musb)
+{
+	if (musb->pProcEntry)
+		remove_proc_entry(name, NULL);
+}
+
+struct proc_dir_entry *__init
+musb_debug_create(char *name, struct musb *data)
+{
+	struct proc_dir_entry	*pde;
+
+	/* FIXME convert everything to seq_file; then later, debugfs */
+
+	if (!name)
+		return NULL;
+
+	data->pProcEntry = pde = create_proc_entry(name,
+					     S_IFREG | S_IRUGO | S_IWUSR, NULL);
+	if (pde) {
+		pde->data = data;
+		// pde->owner = THIS_MODULE;
+
+		pde->read_proc = musb_proc_read;
+		pde->write_proc = musb_proc_write;
+
+		pde->size = 0;
+
+		pr_debug("Registered /proc/%s\n", name);
+	} else {
+		pr_debug("Cannot create a valid proc file entry");
+	}
+
+	return pde;
+}
Index: linux-2.6.10/drivers/usb/musb/musbdefs.h
===================================================================
--- /dev/null
+++ linux-2.6.10/drivers/usb/musb/musbdefs.h
@@ -0,0 +1,537 @@
+/******************************************************************
+ * Copyright 2005 Mentor Graphics Corporation
+ * Copyright (C) 2005-2006 by Texas Instruments
+ *
+ * This file is part of the Inventra Controller Driver for Linux.
+ *
+ * The Inventra Controller Driver for Linux is free software; you
+ * can redistribute it and/or modify it under the terms of the GNU
+ * General Public License version 2 as published by the Free Software
+ * Foundation.
+ *
+ * The Inventra Controller Driver for Linux is distributed in
+ * the hope that it will be useful, but WITHOUT ANY WARRANTY;
+ * without even the implied warranty of MERCHANTABILITY or
+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public
+ * License for more details.
+ *
+ * You should have received a copy of the GNU General Public License
+ * along with The Inventra Controller Driver for Linux ; if not,
+ * write to the Free Software Foundation, Inc., 59 Temple Place,
+ * Suite 330, Boston, MA  02111-1307  USA
+ *
+ * ANY DOWNLOAD, USE, REPRODUCTION, MODIFICATION OR DISTRIBUTION
+ * OF THIS DRIVER INDICATES YOUR COMPLETE AND UNCONDITIONAL ACCEPTANCE
+ * OF THOSE TERMS.THIS DRIVER IS PROVIDED "AS IS" AND MENTOR GRAPHICS
+ * MAKES NO WARRANTIES, EXPRESS OR IMPLIED, RELATED TO THIS DRIVER.
+ * MENTOR GRAPHICS SPECIFICALLY DISCLAIMS ALL IMPLIED WARRANTIES
+ * OF MERCHANTABILITY; FITNESS FOR A PARTICULAR PURPOSE AND
+ * NON-INFRINGEMENT.  MENTOR GRAPHICS DOES NOT PROVIDE SUPPORT
+ * SERVICES OR UPDATES FOR THIS DRIVER, EVEN IF YOU ARE A MENTOR
+ * GRAPHICS SUPPORT CUSTOMER.
+ ******************************************************************/
+
+#ifndef __MUSB_MUSBDEFS_H__
+#define __MUSB_MUSBDEFS_H__
+
+#include <linux/slab.h>
+#include <linux/list.h>
+#include <linux/interrupt.h>
+#include <linux/smp_lock.h>
+#include <linux/errno.h>
+#include <linux/usb_ch9.h>
+#include <linux/usb_otg.h>
+
+#include <linux/usb_musb.h>
+
+#define	gfp_t	int
+
+#include "debug.h"
+#include "dma.h"
+
+#ifdef CONFIG_USB_INVENTRA_STATIC_CONFIG
+#include "plat_cnf.h"
+#endif
+
+#include "plat_arc.h"
+#include "musbhdrc.h"
+
+struct musb;
+
+/* REVISIT tune this */
+#define	MIN_DMA_REQUEST		1	/* use PIO below this xfer size */
+
+
+#ifdef CONFIG_USB_MUSB_OTG
+#include "otg.h"
+
+#define	is_peripheral_enabled(musb)	((musb)->board_mode != MUSB_HOST)
+#define	is_host_enabled(musb)		((musb)->board_mode != MUSB_PERIPHERAL)
+#define	is_otg_enabled(musb)		((musb)->board_mode == MUSB_OTG)
+
+/* NOTE:  otg and peripheral-only state machines start at B_IDLE.
+ * OTG or host-only go to A_IDLE when ID is sensed.
+ */
+#define is_peripheral_active(m)	(is_peripheral_capable() && !(m)->bIsHost)
+#define is_host_active(m)	(is_host_capable() && (m)->bIsHost)
+
+#else
+#define	is_peripheral_enabled(musb)	is_peripheral_capable()
+#define	is_host_enabled(musb)		is_host_capable()
+#define	is_otg_enabled(musb)		0
+
+#define	is_peripheral_active(musb)	is_peripheral_capable()
+#define	is_host_active(musb)		is_host_capable()
+#endif
+
+#ifdef CONFIG_PROC_FS
+#include <linux/fs.h>
+#define MUSB_CONFIG_PROC_FS
+#define MUSB_STATISTICS
+#endif
+
+/****************************** PERIPHERAL ROLE ********************************/
+
+struct musb_ep;
+
+#ifdef CONFIG_USB_GADGET_MUSB_HDRC
+
+#include <linux/usb_gadget.h>
+#include "musb_gadget.h"
+
+#define	is_peripheral_capable()	(1)
+
+extern irqreturn_t musb_g_ep0_irq(struct musb *);
+extern void musb_g_tx(struct musb *, u8);
+extern void musb_g_rx(struct musb *, u8);
+extern void musb_g_reset(struct musb *);
+extern void musb_g_suspend(struct musb *);
+extern void musb_g_resume(struct musb *);
+extern void musb_g_disconnect(struct musb *);
+
+#else
+
+#define	is_peripheral_capable()	(0)
+
+static inline irqreturn_t musb_g_ep0_irq(struct musb *m) { return IRQ_NONE; }
+static inline void musb_g_tx(struct musb *m, u8 e) {}
+static inline void musb_g_rx(struct musb *m, u8 e) {}
+static inline void musb_g_reset(struct musb *m) {}
+static inline void musb_g_suspend(struct musb *m) {}
+static inline void musb_g_resume(struct musb *m) {}
+static inline void musb_g_disconnect(struct musb *m) {}
+
+#endif
+
+/****************************** HOST ROLE **************************************/
+
+struct musb_hw_ep;
+
+#ifdef CONFIG_USB_MUSB_HDRC_HCD
+
+/* for sizeof struct virtual_root */
+#include "virthub.h"
+// #include "musb_host.h"
+
+#define	is_host_capable()	(1)
+
+extern irqreturn_t musb_h_ep0_irq(struct musb *);
+extern void musb_host_tx(struct musb *, u8);
+extern void musb_host_rx(struct musb *, u8);
+
+#else
+
+#define	is_host_capable()	(0)
+
+static inline irqreturn_t musb_h_ep0_irq(struct musb *m) { return IRQ_NONE; }
+static inline void musb_host_tx(struct musb *m, u8 e) {}
+static inline void musb_host_rx(struct musb *m, u8 e) {}
+
+#endif
+
+
+/****************************** CONSTANTS ********************************/
+
+#ifndef TRUE
+#define TRUE 1
+#endif
+#ifndef FALSE
+#define FALSE 0
+#endif
+
+#ifndef MUSB_C_NUM_EPS
+#define MUSB_C_NUM_EPS ((u8)16)
+#endif
+
+#ifndef MUSB_MAX_END0_PACKET
+#define MUSB_MAX_END0_PACKET ((u16)MGC_END0_FIFOSIZE)
+#endif
+
+/* host side ep0 states */
+#define MGC_END0_START  0x0
+#define MGC_END0_OUT    0x2
+#define MGC_END0_IN     0x4
+#define MGC_END0_STATUS 0x8
+
+/* peripheral side ep0 states */
+enum musb_g_ep0_state {
+	MGC_END0_STAGE_SETUP,		/* idle, waiting for setup */
+	MGC_END0_STAGE_TX,		/* IN data */
+	MGC_END0_STAGE_RX,		/* OUT data */
+	MGC_END0_STAGE_STATUSIN,	/* (after OUT data) */
+	MGC_END0_STAGE_STATUSOUT,	/* (after IN data) */
+	MGC_END0_STAGE_ACKWAIT,		/* after zlp, before statusin */
+} __attribute__ ((packed));
+
+/* failure codes */
+#define MUSB_ERR_WAITING	1
+#define MUSB_ERR_VBUS		-1
+#define MUSB_ERR_BABBLE		-2
+#define MUSB_ERR_CORRUPTED	-3
+#define MUSB_ERR_IRQ		-4
+#define MUSB_ERR_SHUTDOWN	-5
+#define MUSB_ERR_RESTART	-6
+
+/****************************** FUNCTIONS ********************************/
+
+#define kzalloc(n,f) kcalloc(1,(n),(f))
+
+/*************************** REGISTER ACCESS ********************************/
+
+/* Endpoint registers (other than dynfifo setup) can be accessed either
+ * directly with the "flat" model, or after setting up an index register.
+ */
+
+#ifdef CONFIG_ARCH_DAVINCI
+/* REVISIT "flat" takes about 1% more object code space and can't be very
+ * noticeable for speed differences.  But for now indexed access seems to
+ * misbehave at least for peripheral IN ...
+ */
+#define	MUSB_FLAT_REG
+#endif
+
+#if	defined(CONFIG_USB_TUSB_6010)
+#define MGC_SelectEnd(_pBase, _bEnd) \
+	musb_writeb((_pBase), MGC_O_HDRC_INDEX, (_bEnd))
+#define	MGC_END_OFFSET			MGC_TUSB_OFFSET
+
+#elif	defined(MUSB_FLAT_REG)
+#define MGC_SelectEnd(_pBase, _bEnd)	(((void)(_pBase)),((void)(_bEnd)))
+#define	MGC_END_OFFSET			MGC_FLAT_OFFSET
+
+#else
+#define MGC_SelectEnd(_pBase, _bEnd) \
+	musb_writeb((_pBase), MGC_O_HDRC_INDEX, (_bEnd))
+#define	MGC_END_OFFSET			MGC_INDEXED_OFFSET
+#endif
+
+#define MGC_ReadCsr8(_pBase, _bOffset, _bEnd) \
+	musb_readb((_pBase), MGC_END_OFFSET((_bEnd), (_bOffset)))
+#define MGC_ReadCsr16(_pBase, _bOffset, _bEnd) \
+	musb_readw((_pBase), MGC_END_OFFSET((_bEnd), (_bOffset)))
+#define MGC_WriteCsr8(_pBase, _bOffset, _bEnd, _bData) \
+	musb_writeb((_pBase), MGC_END_OFFSET((_bEnd), (_bOffset)), (_bData))
+#define MGC_WriteCsr16(_pBase, _bOffset, _bEnd, _bData) \
+	musb_writew((_pBase), MGC_END_OFFSET((_bEnd), (_bOffset)), (_bData))
+
+/****************************** FUNCTIONS ********************************/
+
+#define MUSB_HST_MODE(_pthis) { (_pthis)->bIsHost=TRUE; (_pthis)->bIsDevice=FALSE; \
+	(_pthis)->bFailCode=0; }
+#define MUSB_DEV_MODE(_pthis) { (_pthis)->bIsHost=FALSE; (_pthis)->bIsDevice=TRUE; \
+	(_pthis)->bFailCode=0; }
+#define MUSB_OTG_MODE(_pthis) { (_pthis)->bIsHost=FALSE; (_pthis)->bIsDevice=FALSE; \
+	(_pthis)->bFailCode=MUSB_ERR_WAITING; }
+#define MUSB_ERR_MODE(_pthis, _cause) { (_pthis)->bIsHost=FALSE; (_pthis)->bIsDevice=FALSE; \
+	(_pthis)->bFailCode=_cause; }
+
+#define MUSB_IS_ERR(_x) ( (_x)->bFailCode<0 )
+#define MUSB_IS_HST(_x) ( !MUSB_IS_ERR(_x) && (_x)->bIsHost && !(_x)->bIsDevice )
+#define MUSB_IS_DEV(_x) ( !MUSB_IS_ERR(_x) && !(_x)->bIsHost && (_x)->bIsDevice )
+#define MUSB_IS_OTG(_x) ( !MUSB_IS_ERR(_x) && !(_x)->bIsHost && !(_x)->bIsDevice )
+
+#define test_devctl_hst_mode(_x) (musb_readb((_x)->pRegs, MGC_O_HDRC_DEVCTL)&MGC_M_DEVCTL_HM)
+
+#define MUSB_MODE(_x) ( MUSB_IS_HST(_x)?"HOST" \
+		:( MUSB_IS_DEV(_x)?"PERIPHERAL" \
+		:(MUSB_IS_OTG(_x)?"UNCONNECTED" \
+		:"ERROR")) )
+
+/******************************** DMA TYPES **********************************/
+
+#ifdef CONFIG_USB_INVENTRA_DMA
+#include "dma.h"
+
+#ifndef MGC_HSDMA_CHANNELS
+#define MGC_HSDMA_CHANNELS 8
+#endif
+
+#endif
+
+/************************** Ep Configuration ********************************/
+
+/** The End point descriptor */
+struct MUSB_EpFifoDescriptor {
+	u8 bType;		/* 0 for autoconfig, CNTR, ISOC, BULK, INTR */
+	u8 bDir;		/* 0 for autoconfig, INOUT, IN, OUT */
+	int wSize;		/* 0 for autoconfig, or the size */
+};
+
+#define MUSB_EPD_AUTOCONFIG	0
+
+#define MUSB_EPD_T_CNTRL	1
+#define MUSB_EPD_T_ISOC		2
+#define MUSB_EPD_T_BULK		3
+#define MUSB_EPD_T_INTR		4
+
+#define MUSB_EPD_D_INOUT	0
+#define MUSB_EPD_D_TX		1
+#define MUSB_EPD_D_RX		2
+
+/******************************** TYPES *************************************/
+
+/*
+ * struct musb_hw_ep - endpoint hardware (bidirectional)
+ *
+ * REVISIT the TX and RX sides should be more completely decoupled,
+ * each with separate host and peripheral side state structures
+ */
+struct musb_hw_ep {
+	struct musb		*musb;
+	void __iomem		*fifo;
+	void __iomem		*regs;
+
+#ifdef CONFIG_USB_MUSB_HDRC_HCD
+	/* host side */
+
+#if 1
+
+#define in_urb_list		urb_list
+#define out_urb_list		urb_list
+	struct list_head	urb_list;
+
+#define in_traffic_type		bTrafficType
+#define out_traffic_type	bTrafficType
+	u8			bTrafficType;
+
+#define in_busy			busy
+#define out_busy		busy
+	u8			busy;
+
+	/* FIXME not all host side endpoint structures reflect the fact
+	 * that each of these endpoints could go in either direction,
+	 * unless it's using a shared fifo ...
+	 */
+	u8			bIsClaimed;
+	u8 bAddress;
+	u8 bEnd;
+	u8 bIsReady;
+	u16 wPacketSize;
+	u16			dwWaitFrame;
+
+	unsigned int dwOffset;
+	unsigned int dwRequestSize;
+	unsigned int dwIsoPacket;
+
+#else
+	struct musb_host_ep	in;
+	struct musb_host_ep	out;
+
+#define in_urb_list		in.urb_list
+#define out_urb_list		out.urb_list
+#define in_traffic_type		in.type
+#define out_traffic_type	out.type
+#define in_busy			in.busy
+#define out_busy		out.busy
+
+#endif
+
+#endif	/* CONFIG_USB_MUSB_HDRC_HCD */
+
+#ifdef CONFIG_USB_GADGET_MUSB_HDRC
+	/* peripheral side */
+	struct musb_ep		ep_in;			/* TX */
+	struct musb_ep		ep_out;			/* RX */
+#endif
+
+	/* FIXME each direction should have its own channel... */
+#define	tx_channel	pDmaChannel
+#define	rx_channel	pDmaChannel
+	struct dma_channel	*pDmaChannel;
+	//struct dma_channel	*tx_channel;
+	//struct dma_channel	*rx_channel;
+
+	/* hardware configuration, possibly dynamic */
+	u16			wMaxPacketSizeTx;
+	u16			wMaxPacketSizeRx;
+	u8			tx_double_buffered;
+	u8			rx_double_buffered;
+	u8			bIsSharedFifo;
+
+	/* index in musb->aLocalEnd[]  */
+	u8			bLocalEnd;
+};
+
+static inline struct usb_request *next_in_request(struct musb_hw_ep *hw_ep)
+{
+#ifdef CONFIG_USB_GADGET_MUSB_HDRC
+	return next_request(&hw_ep->ep_in);
+#else
+	return NULL;
+#endif
+}
+
+static inline struct usb_request *next_out_request(struct musb_hw_ep *hw_ep)
+{
+#ifdef CONFIG_USB_GADGET_MUSB_HDRC
+	return next_request(&hw_ep->ep_out);
+#else
+	return NULL;
+#endif
+}
+
+/*
+ * struct musb - Driver instance data.
+ */
+struct musb {
+	spinlock_t		Lock;
+	struct usb_bus		*pBus;
+	struct clk		*clock;
+	irqreturn_t		(*isr)(int, void *, struct pt_regs *);
+
+#ifdef CONFIG_USB_MUSB_HDRC_HCD
+	struct virtual_root	RootHub;
+	struct usb_device	*pRootDevice;
+	struct timer_list	Timer;
+
+	u8 bEnd0Stage;		/* end0 stage while in host */
+
+	/* bulk traffic normally dedicates endpoint hardware, and each
+	 * direction has its own ring of host side endpoints.
+	 * we try to progress the transfer at the head of each endpoint's
+	 * queue until it completes or NAKs too much; then we try the next
+	 * endpoint.
+	 */
+	struct musb_hw_ep	*bulk_tx_end;
+	struct musb_hw_ep	*bulk_rx_end;
+
+#ifdef	SCHEDULER
+	/* REVISIT implement a schedule, something like this. */
+	struct list_head	tx_bulk;	/* of musb_sched_node */
+	struct list_head	rx_bulk;	/* of musb_sched_node */
+	struct musb_sched_node *periodic[32];	/* tree of interrupt+iso */
+#endif	/* SCHEDULER */
+
+#endif
+
+	struct dma_controller	*pDmaController;
+
+	struct device		*controller;
+	void __iomem		*ctrl_base;
+	void __iomem		*pRegs;
+
+	/* passed down from chip/board specific irq handlers */
+	u8			int_usb;
+	u16			int_rx;
+	u16			int_tx;
+	struct pt_regs		*int_regs;
+
+	struct otg_transceiver	xceiv;
+
+	int nIrq;
+
+	struct musb_hw_ep	 aLocalEnd[MUSB_C_NUM_EPS];
+
+	u16 wEndMask;
+	u8 bEndCount;
+	u8 bRootSpeed;
+	u8 board_mode;		/* enum musb_mode */
+
+	s8 bFailCode;		/* one of MUSB_ERR_* failure code */
+
+	unsigned bIsMultipoint:1;
+	unsigned bIsDevice:1;
+	unsigned bIsHost:1;
+	unsigned bIgnoreDisconnect:1;	/* during bus resets, fake disconnects */
+	unsigned bBulkSplit:1;
+	unsigned bBulkCombine:1;
+
+#ifdef CONFIG_USB_GADGET_MUSB_HDRC
+	unsigned bIsSelfPowered:1;
+	unsigned bMayWakeup:1;
+	unsigned bSetAddress:1;
+	unsigned bTestMode:1;
+	unsigned softconnect:1;
+
+	enum musb_g_ep0_state	ep0_state;
+	u8			bAddress;
+	u8			bTestModeValue;
+	u16			ackpend;		/* ep0 */
+	struct usb_gadget	g;			/* the gadget */
+	struct usb_gadget_driver *pGadgetDriver;	/* its driver */
+#endif
+
+#ifdef CONFIG_USB_MUSB_OTG
+	struct otg_machine	OtgMachine;
+	u8 bDelayPortPowerOff;
+#endif
+
+#ifdef MUSB_CONFIG_PROC_FS
+	struct proc_dir_entry *pProcEntry;
+#endif
+};
+
+#ifdef CONFIG_USB_GADGET_MUSB_HDRC
+static inline struct musb *gadget_to_musb(struct usb_gadget *g)
+{
+	return container_of(g, struct musb, g);
+}
+#endif
+
+
+/***************************** Glue it together *****************************/
+
+extern const char musb_driver_name[];
+
+void *musb_alloc_buffer(struct musb *pThis, size_t bytes, gfp_t gfp_flags,
+			    dma_addr_t * dma);
+void musb_free_buffer(struct musb *pThis, size_t bytes, void *address,
+			  dma_addr_t dma);
+
+extern void musb_start(struct musb *pThis);
+extern void musb_stop(struct musb *pThis);
+
+extern void musb_write_fifo(struct musb_hw_ep *ep,
+			     u16 wCount, const u8 * pSource);
+extern void musb_read_fifo(struct musb_hw_ep *ep,
+			       u16 wCount, u8 * pDest);
+
+extern irqreturn_t musb_interrupt(struct musb *);
+
+extern void musb_platform_enable(struct musb *musb);
+extern void musb_platform_disable(struct musb *musb);
+
+extern int __init musb_platform_init(struct musb *musb);
+extern int musb_platform_exit(struct musb *musb);
+
+/*-------------------------- ProcFS definitions ---------------------*/
+
+struct proc_dir_entry;
+
+#if (MUSB_DEBUG > 0) && defined(MUSB_CONFIG_PROC_FS)
+extern struct proc_dir_entry *musb_debug_create(char *name,
+						    struct musb *data);
+extern void musb_debug_delete(char *name, struct musb *data);
+
+#else
+static inline struct proc_dir_entry *musb_debug_create(char *name,
+							   struct musb *data)
+{
+	return NULL;
+}
+static inline void musb_debug_delete(char *name, struct musb *data)
+{
+}
+#endif
+
+#endif	/* __MUSB_MUSBDEFS_H__ */
Index: linux-2.6.10/drivers/usb/musb/musbhdrc.h
===================================================================
--- /dev/null
+++ linux-2.6.10/drivers/usb/musb/musbhdrc.h
@@ -0,0 +1,306 @@
+/******************************************************************
+ * Copyright 2005 Mentor Graphics Corporation
+ * Copyright (C) 2005-2006 by Texas Instruments
+ *
+ * This file is part of the Inventra Controller Driver for Linux.
+ *
+ * The Inventra Controller Driver for Linux is free software; you
+ * can redistribute it and/or modify it under the terms of the GNU
+ * General Public License version 2 as published by the Free Software
+ * Foundation.
+ *
+ * The Inventra Controller Driver for Linux is distributed in
+ * the hope that it will be useful, but WITHOUT ANY WARRANTY;
+ * without even the implied warranty of MERCHANTABILITY or
+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public
+ * License for more details.
+ *
+ * You should have received a copy of the GNU General Public License
+ * along with The Inventra Controller Driver for Linux ; if not,
+ * write to the Free Software Foundation, Inc., 59 Temple Place,
+ * Suite 330, Boston, MA  02111-1307  USA
+ *
+ * ANY DOWNLOAD, USE, REPRODUCTION, MODIFICATION OR DISTRIBUTION
+ * OF THIS DRIVER INDICATES YOUR COMPLETE AND UNCONDITIONAL ACCEPTANCE
+ * OF THOSE TERMS.THIS DRIVER IS PROVIDED "AS IS" AND MENTOR GRAPHICS
+ * MAKES NO WARRANTIES, EXPRESS OR IMPLIED, RELATED TO THIS DRIVER.
+ * MENTOR GRAPHICS SPECIFICALLY DISCLAIMS ALL IMPLIED WARRANTIES
+ * OF MERCHANTABILITY; FITNESS FOR A PARTICULAR PURPOSE AND
+ * NON-INFRINGEMENT.  MENTOR GRAPHICS DOES NOT PROVIDE SUPPORT
+ * SERVICES OR UPDATES FOR THIS DRIVER, EVEN IF YOU ARE A MENTOR
+ * GRAPHICS SUPPORT CUSTOMER.
+ ******************************************************************/
+
+#ifndef __MUSB_HDRC_DEFS_H__
+#define __MUSB_HDRC_DEFS_H__
+
+/*
+ * HDRC-specific definitions
+ */
+
+#define MGC_MAX_USB_ENDS       16
+
+#define MGC_END0_FIFOSIZE      64	/* this is non-configurable */
+
+/*
+ *     MUSBMHDRC Register map
+ */
+
+/* Common USB registers */
+
+#define MGC_O_HDRC_FADDR	0x00	/* 8-bit */
+#define MGC_O_HDRC_POWER	0x01	/* 8-bit */
+
+#define MGC_O_HDRC_INTRTX	0x02	/* 16-bit */
+#define MGC_O_HDRC_INTRRX       0x04
+#define MGC_O_HDRC_INTRTXE      0x06
+#define MGC_O_HDRC_INTRRXE      0x08
+#define MGC_O_HDRC_INTRUSB      0x0A	/* 8 bit */
+#define MGC_O_HDRC_INTRUSBE     0x0B	/* 8 bit */
+#define MGC_O_HDRC_FRAME        0x0C
+#define MGC_O_HDRC_INDEX        0x0E	/* 8 bit */
+#define MGC_O_HDRC_TESTMODE     0x0F	/* 8 bit */
+
+/* Get offset for a given FIFO */
+#ifdef CONFIG_USB_TUSB_6010
+#define MGC_FIFO_OFFSET(_bEnd) (0x200 + ((_bEnd) * 0x20))
+#else
+#define MGC_FIFO_OFFSET(_bEnd) (0x20 + ((_bEnd) * 4))
+#endif
+
+/* Additional Control Registers */
+
+#define MGC_O_HDRC_DEVCTL	0x60	/* 8 bit */
+// vctrl/vstatus:  optional vendor utmi+phy register at 0x68
+#define MGC_O_HDRC_HWVERS	0x6C	/* 8 bit */
+
+/* These are always controlled through the INDEX register */
+#define MGC_O_HDRC_TXFIFOSZ	0x62	/* 8-bit (see masks) */
+#define MGC_O_HDRC_RXFIFOSZ	0x63	/* 8-bit (see masks) */
+#define MGC_O_HDRC_TXFIFOADD	0x64	/* 16-bit offset shifted right 3 */
+#define MGC_O_HDRC_RXFIFOADD	0x66	/* 16-bit offset shifted right 3 */
+
+/* offsets to endpoint registers */
+#define MGC_O_HDRC_TXMAXP	0x00
+#define MGC_O_HDRC_TXCSR	0x02
+#define MGC_O_HDRC_CSR0		MGC_O_HDRC_TXCSR	/* re-used for EP0 */
+#define MGC_O_HDRC_RXMAXP	0x04
+#define MGC_O_HDRC_RXCSR	0x06
+#define MGC_O_HDRC_RXCOUNT	0x08
+#define MGC_O_HDRC_COUNT0	MGC_O_HDRC_RXCOUNT	/* re-used for EP0 */
+#define MGC_O_HDRC_TXTYPE	0x0A
+#define MGC_O_HDRC_TYPE0	MGC_O_HDRC_TXTYPE	/* re-used for EP0 */
+#define MGC_O_HDRC_TXINTERVAL	0x0B
+#define MGC_O_HDRC_NAKLIMIT0	MGC_O_HDRC_TXINTERVAL	/* re-used for EP0 */
+#define MGC_O_HDRC_RXTYPE	0x0C
+#define MGC_O_HDRC_RXINTERVAL	0x0D
+#define MGC_O_HDRC_FIFOSIZE	0x0F
+#define MGC_O_HDRC_CONFIGDATA	MGC_O_HDRC_FIFOSIZE	/* re-used for EP0 */
+
+/* offsets to endpoint registers in indexed model (using INDEX register) */
+#define MGC_INDEXED_OFFSET(_bEnd, _bOffset)	\
+	(0x10                   + (_bOffset))
+
+/* offsets to endpoint registers in flat models */
+#define MGC_FLAT_OFFSET(_bEnd, _bOffset)	\
+	(0x100 + (0x10*(_bEnd)) + (_bOffset))
+#define MGC_TUSB_OFFSET(_bEnd, _bOffset)	\
+	(0x400 + (((_bEnd - 1) & 0xf) << 2) + (_bOffset))
+
+/* "bus control" registers */
+#define MGC_O_HDRC_TXFUNCADDR	0x00
+#define MGC_O_HDRC_TXHUBADDR	0x02
+#define MGC_O_HDRC_TXHUBPORT	0x03
+
+#define MGC_O_HDRC_RXFUNCADDR	0x04
+#define MGC_O_HDRC_RXHUBADDR	0x06
+#define MGC_O_HDRC_RXHUBPORT	0x07
+
+#define MGC_BUSCTL_OFFSET(_bEnd, _bOffset) \
+	(0x80 + (8*(_bEnd)) + (_bOffset))
+
+/*
+ *     MUSBHDRC Register bit masks
+ */
+
+/* POWER */
+
+#define MGC_M_POWER_ISOUPDATE   0x80
+#define MGC_M_POWER_SOFTCONN    0x40
+#define MGC_M_POWER_HSENAB	0x20
+#define MGC_M_POWER_HSMODE	0x10
+#define MGC_M_POWER_RESET       0x08
+#define MGC_M_POWER_RESUME      0x04
+#define MGC_M_POWER_SUSPENDM    0x02
+#define MGC_M_POWER_ENSUSPEND   0x01
+
+/* INTRUSB */
+#define MGC_M_INTR_SUSPEND    0x01
+#define MGC_M_INTR_RESUME     0x02
+#define MGC_M_INTR_RESET      0x04
+#define MGC_M_INTR_BABBLE     0x04
+#define MGC_M_INTR_SOF        0x08
+#define MGC_M_INTR_CONNECT    0x10
+#define MGC_M_INTR_DISCONNECT 0x20
+#define MGC_M_INTR_SESSREQ    0x40
+#define MGC_M_INTR_VBUSERROR  0x80	/* FOR SESSION END */
+#define MGC_M_INTR_EP0      0x01	/* FOR EP0 INTERRUPT */
+
+/* DEVCTL */
+#define MGC_M_DEVCTL_BDEVICE    0x80
+#define MGC_M_DEVCTL_FSDEV      0x40
+#define MGC_M_DEVCTL_LSDEV      0x20
+#define MGC_M_DEVCTL_VBUS       0x18
+#define MGC_S_DEVCTL_VBUS       3
+#define MGC_M_DEVCTL_HM         0x04
+#define MGC_M_DEVCTL_HR         0x02
+#define MGC_M_DEVCTL_SESSION    0x01
+
+/* TESTMODE */
+
+#define MGC_M_TEST_FORCE_HOST   0x80
+#define MGC_M_TEST_FIFO_ACCESS  0x40
+#define MGC_M_TEST_FORCE_FS     0x20
+#define MGC_M_TEST_FORCE_HS     0x10
+#define MGC_M_TEST_PACKET       0x08
+#define MGC_M_TEST_K            0x04
+#define MGC_M_TEST_J            0x02
+#define MGC_M_TEST_SE0_NAK      0x01
+
+/* allocate for double-packet buffering (effectively doubles assigned _SIZE) */
+#define MGC_M_FIFOSZ_DPB	0x10
+/* allocation size (8, 16, 32, ... 4096) */
+#define MGC_M_FIFOSZ_SIZE	0x0f
+
+/* CSR0 */
+#define MGC_M_CSR0_FLUSHFIFO      0x0100
+#define MGC_M_CSR0_TXPKTRDY       0x0002
+#define MGC_M_CSR0_RXPKTRDY       0x0001
+
+/* CSR0 in Peripheral mode */
+#define MGC_M_CSR0_P_SVDSETUPEND  0x0080
+#define MGC_M_CSR0_P_SVDRXPKTRDY  0x0040
+#define MGC_M_CSR0_P_SENDSTALL    0x0020
+#define MGC_M_CSR0_P_SETUPEND     0x0010
+#define MGC_M_CSR0_P_DATAEND      0x0008
+#define MGC_M_CSR0_P_SENTSTALL    0x0004
+
+/* CSR0 in Host mode */
+#define MGC_M_CSR0_H_WR_DATATOGGLE   0x0400	/* set to allow setting: */
+#define MGC_M_CSR0_H_DATATOGGLE	    0x0200	/* data toggle control */
+#define MGC_M_CSR0_H_NAKTIMEOUT   0x0080
+#define MGC_M_CSR0_H_STATUSPKT    0x0040
+#define MGC_M_CSR0_H_REQPKT       0x0020
+#define MGC_M_CSR0_H_ERROR        0x0010
+#define MGC_M_CSR0_H_SETUPPKT     0x0008
+#define MGC_M_CSR0_H_RXSTALL      0x0004
+
+/* CSR0 bits to avoid zeroing (write zero clears, write 1 ignored) */
+#define MGC_M_CSR0_P_WZC_BITS	\
+	( MGC_M_CSR0_P_SENTSTALL )
+#define MGC_M_CSR0_H_WZC_BITS	\
+	( MGC_M_CSR0_H_NAKTIMEOUT | MGC_M_CSR0_H_RXSTALL \
+	| MGC_M_CSR0_RXPKTRDY )
+
+
+/* TxType/RxType */
+#define MGC_M_TYPE_SPEED	0xc0
+#define MGC_S_TYPE_SPEED	6
+#define MGC_TYPE_SPEED_HIGH	1
+#define MGC_TYPE_SPEED_FULL	2
+#define MGC_TYPE_SPEED_LOW	3
+#define MGC_M_TYPE_PROTO	0x30
+#define MGC_S_TYPE_PROTO	4
+#define MGC_M_TYPE_REMOTE_END	0xf
+
+/* CONFIGDATA */
+
+#define MGC_M_CONFIGDATA_MPRXE      0x80	/* auto bulk pkt combining */
+#define MGC_M_CONFIGDATA_MPTXE      0x40	/* auto bulk pkt splitting */
+#define MGC_M_CONFIGDATA_BIGENDIAN  0x20
+#define MGC_M_CONFIGDATA_HBRXE      0x10	/* HB-ISO for RX */
+#define MGC_M_CONFIGDATA_HBTXE      0x08	/* HB-ISO for TX */
+#define MGC_M_CONFIGDATA_DYNFIFO    0x04	/* dynamic FIFO sizing */
+#define MGC_M_CONFIGDATA_SOFTCONE   0x02	/* SoftConnect */
+#define MGC_M_CONFIGDATA_UTMIDW     0x01	/* data width 0 => 8bits, 1 => 16bits */
+
+/* TXCSR in Peripheral and Host mode */
+
+#define MGC_M_TXCSR_AUTOSET       0x8000
+#define MGC_M_TXCSR_ISO           0x4000
+#define MGC_M_TXCSR_MODE          0x2000
+#define MGC_M_TXCSR_DMAENAB       0x1000
+#define MGC_M_TXCSR_FRCDATATOG    0x0800
+#define MGC_M_TXCSR_DMAMODE       0x0400
+#define MGC_M_TXCSR_CLRDATATOG    0x0040
+#define MGC_M_TXCSR_FLUSHFIFO     0x0008
+#define MGC_M_TXCSR_FIFONOTEMPTY  0x0002
+#define MGC_M_TXCSR_TXPKTRDY      0x0001
+
+/* TXCSR in Peripheral mode */
+
+#define MGC_M_TXCSR_P_INCOMPTX    0x0080
+#define MGC_M_TXCSR_P_SENTSTALL   0x0020
+#define MGC_M_TXCSR_P_SENDSTALL   0x0010
+#define MGC_M_TXCSR_P_UNDERRUN    0x0004
+
+/* TXCSR in Host mode */
+
+#define MGC_M_TXCSR_H_WR_DATATOGGLE   0x0200
+#define MGC_M_TXCSR_H_DATATOGGLE      0x0100
+#define MGC_M_TXCSR_H_NAKTIMEOUT  0x0080
+#define MGC_M_TXCSR_H_RXSTALL     0x0020
+#define MGC_M_TXCSR_H_ERROR       0x0004
+
+/* TXCSR bits to avoid zeroing (write zero clears, write 1 ignored) */
+#define MGC_M_TXCSR_P_WZC_BITS	\
+	( MGC_M_TXCSR_P_INCOMPTX | MGC_M_TXCSR_P_SENTSTALL \
+	| MGC_M_TXCSR_P_UNDERRUN | MGC_M_TXCSR_FIFONOTEMPTY )
+#define MGC_M_TXCSR_H_WZC_BITS	\
+	( MGC_M_TXCSR_H_NAKTIMEOUT | MGC_M_TXCSR_H_RXSTALL \
+	| MGC_M_TXCSR_H_ERROR | MGC_M_TXCSR_FIFONOTEMPTY )
+
+
+/* RXCSR in Peripheral and Host mode */
+
+#define MGC_M_RXCSR_AUTOCLEAR     0x8000
+#define MGC_M_RXCSR_DMAENAB       0x2000
+#define MGC_M_RXCSR_DISNYET       0x1000
+#define MGC_M_RXCSR_DMAMODE       0x0800
+#define MGC_M_RXCSR_INCOMPRX      0x0100
+#define MGC_M_RXCSR_CLRDATATOG    0x0080
+#define MGC_M_RXCSR_FLUSHFIFO     0x0010
+#define MGC_M_RXCSR_DATAERROR     0x0008
+#define MGC_M_RXCSR_FIFOFULL      0x0002
+#define MGC_M_RXCSR_RXPKTRDY      0x0001
+
+/* RXCSR in Peripheral mode */
+
+#define MGC_M_RXCSR_P_ISO         0x4000
+#define MGC_M_RXCSR_P_SENTSTALL   0x0040
+#define MGC_M_RXCSR_P_SENDSTALL   0x0020
+#define MGC_M_RXCSR_P_OVERRUN     0x0004
+
+/* RXCSR in Host mode */
+
+#define MGC_M_RXCSR_H_AUTOREQ     0x4000
+#define MGC_M_RXCSR_H_WR_DATATOGGLE   0x0400
+#define MGC_M_RXCSR_H_DATATOGGLE        0x0200
+#define MGC_M_RXCSR_H_RXSTALL     0x0040
+#define MGC_M_RXCSR_H_REQPKT      0x0020
+#define MGC_M_RXCSR_H_ERROR       0x0004
+
+/* RXCSR bits to avoid zeroing (write zero clears, write 1 ignored) */
+#define MGC_M_RXCSR_P_WZC_BITS	\
+	( MGC_M_RXCSR_P_SENTSTALL | MGC_M_RXCSR_P_OVERRUN \
+	| MGC_M_RXCSR_RXPKTRDY )
+#define MGC_M_RXCSR_H_WZC_BITS	\
+	( MGC_M_RXCSR_H_RXSTALL | MGC_M_RXCSR_H_ERROR \
+	| MGC_M_RXCSR_DATAERROR | MGC_M_RXCSR_RXPKTRDY )
+
+
+/* HUBADDR */
+#define MGC_M_HUBADDR_MULTI_TT		0x80
+
+
+#endif	/* __MUSB_HDRC_DEFS_H__ */
Index: linux-2.6.10/drivers/usb/musb/musbhsdma.c
===================================================================
--- /dev/null
+++ linux-2.6.10/drivers/usb/musb/musbhsdma.c
@@ -0,0 +1,367 @@
+/******************************************************************
+ * Copyright 2005 Mentor Graphics Corporation
+ * Copyright (C) 2005-2006 by Texas Instruments
+ *
+ * This file is part of the Inventra Controller Driver for Linux.
+ *
+ * The Inventra Controller Driver for Linux is free software; you
+ * can redistribute it and/or modify it under the terms of the GNU
+ * General Public License version 2 as published by the Free Software
+ * Foundation.
+ *
+ * The Inventra Controller Driver for Linux is distributed in
+ * the hope that it will be useful, but WITHOUT ANY WARRANTY;
+ * without even the implied warranty of MERCHANTABILITY or
+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public
+ * License for more details.
+ *
+ * You should have received a copy of the GNU General Public License
+ * along with The Inventra Controller Driver for Linux ; if not,
+ * write to the Free Software Foundation, Inc., 59 Temple Place,
+ * Suite 330, Boston, MA  02111-1307  USA
+ *
+ * ANY DOWNLOAD, USE, REPRODUCTION, MODIFICATION OR DISTRIBUTION
+ * OF THIS DRIVER INDICATES YOUR COMPLETE AND UNCONDITIONAL ACCEPTANCE
+ * OF THOSE TERMS.THIS DRIVER IS PROVIDED "AS IS" AND MENTOR GRAPHICS
+ * MAKES NO WARRANTIES, EXPRESS OR IMPLIED, RELATED TO THIS DRIVER.
+ * MENTOR GRAPHICS SPECIFICALLY DISCLAIMS ALL IMPLIED WARRANTIES
+ * OF MERCHANTABILITY; FITNESS FOR A PARTICULAR PURPOSE AND
+ * NON-INFRINGEMENT.  MENTOR GRAPHICS DOES NOT PROVIDE SUPPORT
+ * SERVICES OR UPDATES FOR THIS DRIVER, EVEN IF YOU ARE A MENTOR
+ * GRAPHICS SUPPORT CUSTOMER.
+ ******************************************************************/
+
+/*
+ * DMA implementation for high-speed controllers.
+ */
+
+#ifndef CONFIG_USB_INVENTRA_DMA
+#error misconfigured, why are you trying to build this
+#endif
+
+#define MUSB_HSDMA
+
+#include "musbdefs.h"
+
+/****************************** CONSTANTS ********************************/
+
+#define MGC_O_HSDMA_BASE    0x200
+#define MGC_O_HSDMA_INTR    0x200
+
+#define MGC_O_HSDMA_CONTROL 4
+#define MGC_O_HSDMA_ADDRESS 8
+#define MGC_O_HSDMA_COUNT   0xc
+
+#define MGC_HSDMA_CHANNEL_OFFSET(_bChannel, _bOffset) (MGC_O_HSDMA_BASE + (_bChannel << 4) + _bOffset)
+
+/* control register (16-bit): */
+#define MGC_S_HSDMA_ENABLE	0
+#define MGC_S_HSDMA_TRANSMIT	1
+#define MGC_S_HSDMA_MODE1	2
+#define MGC_S_HSDMA_IRQENABLE	3
+#define MGC_S_HSDMA_ENDPOINT	4
+#define MGC_S_HSDMA_BUSERROR	8
+#define MGC_S_HSDMA_BURSTMODE	9
+#define MGC_M_HSDMA_BURSTMODE	(3 << MGC_S_HSDMA_BURSTMODE)
+#define MGC_HSDMA_BURSTMODE_UNSPEC  0
+#define MGC_HSDMA_BURSTMODE_INCR4   1
+#define MGC_HSDMA_BURSTMODE_INCR8   2
+#define MGC_HSDMA_BURSTMODE_INCR16  3
+
+/******************************* Types ********************************/
+
+struct _MGC_HsDmaController;
+
+typedef struct {
+	struct dma_channel Channel;
+	struct _MGC_HsDmaController *pController;
+	u32 dwStartAddress;
+	u32 dwCount;
+	u16 wMaxPacketSize;
+	u8 bIndex;
+	u8 bEnd;
+	u8 bTransmit;
+} MGC_HsDmaChannel;
+
+typedef struct _MGC_HsDmaController {
+	struct dma_controller Controller;
+	MGC_HsDmaChannel aChannel[MGC_HSDMA_CHANNELS];
+	MGC_pfDmaChannelStatusChanged pfDmaChannelStatusChanged;
+	void *pDmaPrivate;
+	u8 *pCoreBase;
+	u8 bChannelCount;
+	u8 bmUsedChannels;
+} MGC_HsDmaController;
+
+/******************************* FORWARDS ********************************/
+
+static u8 MGC_HsDmaStartController(void *pPrivateData);
+
+static u8 MGC_HsDmaStopController(void *pPrivateData);
+
+static struct dma_channel *MGC_HsDmaAllocateChannel(void *pPrivateData,
+						u8 bLocalEnd, u8 bTransmit,
+						u8 bProtocol,
+						u16 wMaxPacketSize);
+
+static void MGC_HsDmaReleaseChannel(struct dma_channel *pChannel);
+
+static u8 MGC_HsDmaProgramChannel(struct dma_channel *pChannel,
+				  u16 wPacketSize, u8 bMode,
+				  dma_addr_t dma_addr, u32 dwLength);
+
+static u8 MGC_HsDmaControllerIsr(void *pPrivateData);
+
+static struct dma_controller *MGC_HsNewDmaController(MGC_pfDmaChannelStatusChanged
+						 pfDmaChannelStatusChanged,
+						 void *pDmaPrivate,
+						 u8 * pCoreBase);
+
+static void MGC_HsDestroyDmaController(struct dma_controller *pController);
+
+/******************************* GLOBALS *********************************/
+
+struct dma_controller_factory dma_controller_factory = {
+	.pfNewDmaController =		MGC_HsNewDmaController,
+	.pfDestroyDmaController =	MGC_HsDestroyDmaController,
+};
+
+/****************************** FUNCTIONS ********************************/
+
+#ifdef MUSB_HSDMA
+
+static u8 MGC_HsDmaStartController(void *pPrivateData)
+{
+	/* nothing to do */
+	return TRUE;
+}
+
+static u8 MGC_HsDmaStopController(void *pPrivateData)
+{
+	/* nothing to do */
+	return TRUE;
+}
+
+static struct dma_channel *MGC_HsDmaAllocateChannel(void *pPrivateData,
+						u8 bLocalEnd, u8 bTransmit,
+						u8 bProtocol,
+						u16 wMaxPacketSize)
+{
+	u8 bBit;
+	struct dma_channel *pChannel = NULL;
+	MGC_HsDmaChannel *pImplChannel = NULL;
+	MGC_HsDmaController *pController = (MGC_HsDmaController *) pPrivateData;
+
+	for (bBit = 0; bBit < MGC_HSDMA_CHANNELS; bBit++) {
+		if (!(pController->bmUsedChannels & (1 << bBit))) {
+			pController->bmUsedChannels |= (1 << bBit);
+			pImplChannel = &(pController->aChannel[bBit]);
+			pImplChannel->pController = pController;
+			pImplChannel->wMaxPacketSize = wMaxPacketSize;
+			pImplChannel->bIndex = bBit;
+			pImplChannel->bEnd = bLocalEnd;
+			pImplChannel->bTransmit = bTransmit;
+			pChannel = &(pImplChannel->Channel);
+			pChannel->pPrivateData = pImplChannel;
+			pChannel->bStatus = MGC_DMA_STATUS_FREE;
+			pChannel->dwMaxLength = 0x10000;
+			/* Tx => mode 1; Rx => mode 0 */
+			pChannel->bDesiredMode = bTransmit;
+			break;
+		}
+	}
+	return pChannel;
+}
+
+static void MGC_HsDmaReleaseChannel(struct dma_channel *pChannel)
+{
+	MGC_HsDmaChannel *pImplChannel =
+	    (MGC_HsDmaChannel *) pChannel->pPrivateData;
+
+	pImplChannel->pController->bmUsedChannels &=
+	    ~(1 << pImplChannel->bIndex);
+	pImplChannel->Channel.bStatus = MGC_DMA_STATUS_FREE;
+}
+
+static u8 MGC_HsDmaProgramChannel(struct dma_channel *pChannel,
+				  u16 wPacketSize, u8 bMode,
+				  dma_addr_t dma_addr, u32 dwLength)
+{
+	MGC_HsDmaChannel *pImplChannel =
+	    (MGC_HsDmaChannel *) pChannel->pPrivateData;
+	MGC_HsDmaController *pController = pImplChannel->pController;
+	u8 *pBase = pController->pCoreBase;
+	u16 wCsr =
+	    (pImplChannel->
+	     bEnd << MGC_S_HSDMA_ENDPOINT) | (1 << MGC_S_HSDMA_ENABLE);
+	u8 bChannel = pImplChannel->bIndex;
+
+	if (bMode) {
+		wCsr |= 1 << MGC_S_HSDMA_MODE1;
+		if (dwLength < wPacketSize) {
+			return FALSE;
+		}
+		if (pImplChannel->wMaxPacketSize >= 64) {
+			wCsr |=
+			    MGC_HSDMA_BURSTMODE_INCR16 << MGC_S_HSDMA_BURSTMODE;
+		} else if (pImplChannel->wMaxPacketSize >= 32) {
+			wCsr |=
+			    MGC_HSDMA_BURSTMODE_INCR8 << MGC_S_HSDMA_BURSTMODE;
+		} else if (pImplChannel->wMaxPacketSize >= 16) {
+			wCsr |=
+			    MGC_HSDMA_BURSTMODE_INCR4 << MGC_S_HSDMA_BURSTMODE;
+		}
+	}
+
+	if (pImplChannel->bTransmit) {
+		wCsr |= 1 << MGC_S_HSDMA_TRANSMIT;
+	}
+	wCsr |= 1 << MGC_S_HSDMA_IRQENABLE;
+
+	/* address/count */
+	musb_writel(pBase,
+		    MGC_HSDMA_CHANNEL_OFFSET(bChannel, MGC_O_HSDMA_ADDRESS),
+		    dma_addr);
+	musb_writel(pBase,
+		    MGC_HSDMA_CHANNEL_OFFSET(bChannel, MGC_O_HSDMA_COUNT),
+		    dwLength);
+
+	/* control (this should start things) */
+	pChannel->dwActualLength = 0L;
+	pImplChannel->dwStartAddress = dma_addr;
+	pImplChannel->dwCount = dwLength;
+	musb_writew(pBase,
+		    MGC_HSDMA_CHANNEL_OFFSET(bChannel, MGC_O_HSDMA_CONTROL),
+		    wCsr);
+
+	return TRUE;
+}
+
+/* FIXME just update the status when it changes ... */
+static enum dma_channel_status MGC_HsDmaGetChannelStatus(struct dma_channel *pChannel)
+{
+	u32 dwAddress;
+	MGC_HsDmaChannel *pImplChannel =
+	    (MGC_HsDmaChannel *) pChannel->pPrivateData;
+	MGC_HsDmaController *pController = pImplChannel->pController;
+	u8 *pBase = pController->pCoreBase;
+	u8 bChannel = pImplChannel->bIndex;
+	u16 wCsr = musb_readw(pBase,
+			      MGC_HSDMA_CHANNEL_OFFSET(bChannel,
+						       MGC_O_HSDMA_CONTROL));
+
+	if (wCsr & (1 << MGC_S_HSDMA_BUSERROR)) {
+		return MGC_DMA_STATUS_BUS_ABORT;
+	}
+	/* most DMA controllers would update the count register for simplicity... */
+	dwAddress =
+	    musb_readl(pBase,
+		       MGC_HSDMA_CHANNEL_OFFSET(bChannel, MGC_O_HSDMA_ADDRESS));
+	if (dwAddress < (pImplChannel->dwStartAddress + pImplChannel->dwCount)) {
+		return MGC_DMA_STATUS_BUSY;
+	}
+	return MGC_DMA_STATUS_FREE;
+}
+
+static u8 MGC_HsDmaControllerIsr(void *pPrivateData)
+{
+	u8 bChannel;
+	u16 wCsr;
+	u32 dwAddress;
+	MGC_HsDmaChannel *pImplChannel;
+	MGC_HsDmaController *pController = (MGC_HsDmaController *) pPrivateData;
+	u8 *pBase = pController->pCoreBase;
+	u8 bIntr = musb_readb(pBase, MGC_O_HSDMA_INTR);
+
+	if (!bIntr) {
+		return FALSE;
+	}
+	for (bChannel = 0; bChannel < MGC_HSDMA_CHANNELS; bChannel++) {
+		if (bIntr & (1 << bChannel)) {
+			pImplChannel =
+			    (MGC_HsDmaChannel *) & (pController->
+						    aChannel[bChannel]);
+			wCsr =
+			    musb_readw(pBase,
+				       MGC_HSDMA_CHANNEL_OFFSET(bChannel,
+								MGC_O_HSDMA_CONTROL));
+			if (wCsr & (1 << MGC_S_HSDMA_BUSERROR)) {
+				pImplChannel->Channel.bStatus =
+				    MGC_DMA_STATUS_BUS_ABORT;
+			} else {
+				/* most DMA controllers would update the count register for simplicity... */
+				dwAddress = musb_readl(pBase,
+						       MGC_HSDMA_CHANNEL_OFFSET
+						       (bChannel,
+							MGC_O_HSDMA_ADDRESS));
+				pImplChannel->Channel.bStatus =
+				    MGC_DMA_STATUS_FREE;
+				pImplChannel->Channel.dwActualLength =
+				    dwAddress - pImplChannel->dwStartAddress;
+				pController->
+				    pfDmaChannelStatusChanged(pController->
+							      pDmaPrivate,
+							      pImplChannel->
+							      bEnd,
+							      pImplChannel->
+							      bTransmit);
+			}
+		}
+	}
+	return TRUE;
+}
+
+#endif				/* MUSB_HSDMA */
+
+static struct dma_controller *MGC_HsNewDmaController(MGC_pfDmaChannelStatusChanged
+						 pfDmaChannelStatusChanged,
+						 void *pDmaPrivate,
+						 u8 * pCoreBase)
+{
+	struct dma_controller *pResult = NULL;
+#ifdef MUSB_HSDMA
+	MGC_HsDmaController *pController =
+	    (MGC_HsDmaController *) kmalloc(sizeof(MGC_HsDmaController),
+					    GFP_KERNEL);
+	if (pController) {
+		memset(pController, 0, sizeof(MGC_HsDmaController));
+		pController->bChannelCount = MGC_HSDMA_CHANNELS;
+		pController->pfDmaChannelStatusChanged =
+		    pfDmaChannelStatusChanged;
+		pController->pDmaPrivate = pDmaPrivate;
+		pController->pCoreBase = pCoreBase;
+		pController->Controller.pPrivateData = pController;
+		pController->Controller.pfDmaStartController =
+		    MGC_HsDmaStartController;
+		pController->Controller.pfDmaStopController =
+		    MGC_HsDmaStopController;
+		pController->Controller.pfDmaAllocateChannel =
+		    MGC_HsDmaAllocateChannel;
+		pController->Controller.pfDmaReleaseChannel =
+		    MGC_HsDmaReleaseChannel;
+		pController->Controller.pfDmaAllocateBuffer =
+		    MGC_HsDmaAllocateBuffer;
+		pController->Controller.pfDmaReleaseBuffer =
+		    MGC_HsDmaReleaseBuffer;
+		pController->Controller.pfDmaProgramChannel =
+		    MGC_HsDmaProgramChannel;
+		pController->Controller.pfDmaControllerIsr =
+		    MGC_HsDmaControllerIsr;
+		pResult = &(pController->Controller);
+	}
+#endif
+	return pResult;
+}
+
+static void MGC_HsDestroyDmaController(struct dma_controller *pController)
+{
+#ifdef MUSB_HSDMA
+	MGC_HsDmaController *pHsController =
+	    (MGC_HsDmaController *) pController->pPrivateData;
+
+	if (pHsController) {
+		pHsController->Controller.pPrivateData = NULL;
+		kfree(pHsController);
+	}
+#endif
+}
Index: linux-2.6.10/drivers/usb/musb/otg.c
===================================================================
--- /dev/null
+++ linux-2.6.10/drivers/usb/musb/otg.c
@@ -0,0 +1,390 @@
+/******************************************************************
+ * Copyright 2005 Mentor Graphics Corporation
+ * Copyright (C) 2005-2006 by Texas Instruments
+ *
+ * This file is part of the Inventra Controller Driver for Linux.
+ *
+ * The Inventra Controller Driver for Linux is free software; you
+ * can redistribute it and/or modify it under the terms of the GNU
+ * General Public License version 2 as published by the Free Software
+ * Foundation.
+ *
+ * The Inventra Controller Driver for Linux is distributed in
+ * the hope that it will be useful, but WITHOUT ANY WARRANTY;
+ * without even the implied warranty of MERCHANTABILITY or
+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public
+ * License for more details.
+ *
+ * You should have received a copy of the GNU General Public License
+ * along with The Inventra Controller Driver for Linux ; if not,
+ * write to the Free Software Foundation, Inc., 59 Temple Place,
+ * Suite 330, Boston, MA  02111-1307  USA
+ *
+ * ANY DOWNLOAD, USE, REPRODUCTION, MODIFICATION OR DISTRIBUTION
+ * OF THIS DRIVER INDICATES YOUR COMPLETE AND UNCONDITIONAL ACCEPTANCE
+ * OF THOSE TERMS.THIS DRIVER IS PROVIDED "AS IS" AND MENTOR GRAPHICS
+ * MAKES NO WARRANTIES, EXPRESS OR IMPLIED, RELATED TO THIS DRIVER.
+ * MENTOR GRAPHICS SPECIFICALLY DISCLAIMS ALL IMPLIED WARRANTIES
+ * OF MERCHANTABILITY; FITNESS FOR A PARTICULAR PURPOSE AND
+ * NON-INFRINGEMENT.  MENTOR GRAPHICS DOES NOT PROVIDE SUPPORT
+ * SERVICES OR UPDATES FOR THIS DRIVER, EVEN IF YOU ARE A MENTOR
+ * GRAPHICS SUPPORT CUSTOMER.
+ ******************************************************************/
+
+/* OTG state machine status 8-mar:
+ *
+ *   - on DaVinci
+ *        + EVM gamma boards have troublesome C133, preventing
+ *          conformant timings for A_WAIT_VFALL transitions
+ *        + ID-pin based role initialization and VBUS switching
+ *	    seems partly functional ... seems to bypass this code.
+ *        + haven't tried HNP or SRP.
+ *
+ *   - needs updating along the lines of <linux/usb_otg.h>
+ *
+ *   - doesn't yet use all the linux 2.6.10 usbcore hooks for OTG, but
+ *     some of the conversion (and consequent shrinkage) has begun.
+ *
+ *   - it's not clear if any version of this code ever have passed
+ *     the USB-IF OTG tests even at full speed; presumably not.
+ */
+
+#include <linux/config.h>
+#include <linux/module.h>
+#include <linux/kernel.h>
+#include <linux/delay.h>
+#include <linux/sched.h>
+#include <linux/slab.h>
+#include <linux/smp_lock.h>
+#include <linux/errno.h>
+#include <linux/init.h>
+#include <linux/time.h>
+#include <linux/timer.h>
+
+#include <linux/usb.h>
+
+#include "musbdefs.h"
+#include "otg.h"
+#include "musb_host.h"
+
+#include "../core/hcd.h"
+
+
+static void otg_set_session(struct musb *musb, u8 bSession)
+{
+	void *__iomem pBase = musb->pRegs;
+	u8 devctl = musb_readb(pBase, MGC_O_HDRC_DEVCTL);
+
+	DBG(2, "<==\n");
+
+	/* REVISIT unclear what this should do, but this looks
+	 * like the wrong thing ... the OTG machine should never
+	 * shut down so long as both host and peripheral drivers
+	 * are active.
+	 */
+	if (bSession) {
+		devctl |= MGC_M_DEVCTL_SESSION;
+		musb_writeb(pBase, MGC_O_HDRC_DEVCTL, devctl);
+	// } else if (is_peripheral_active(musb)) {
+		//pThis->pRootDevice = NULL;
+	} else {
+		//devctl &= ~MGC_M_DEVCTL_SESSION;
+		musb_root_disconnect(musb);
+		//musb_writeb(pBase, MGC_O_HDRC_DEVCTL, devctl);
+	}
+}
+
+#if 0
+static void otg_request_session(struct musb *musb)
+{
+	void *__iomem pBase = musb->pRegs;
+	u8 devctl;
+
+	DBG(2, "<==\n");
+	devctl = musb_readb(pBase, MGC_O_HDRC_DEVCTL);
+	devctl |= MGC_M_DEVCTL_SESSION;
+	musb_writeb(pBase, MGC_O_HDRC_DEVCTL, devctl);
+}
+#endif
+
+/* caller has irqlocked musb */
+static void otg_state_changed(struct musb *musb, enum usb_otg_state state)
+{
+	/* caller should pass the timeout here */
+	unsigned long	timer = 0;
+
+	if (state == musb->OtgMachine.bState)
+		return;
+
+	DBG(1, "%d --> %d\n", musb->OtgMachine.bState, state);
+	musb->OtgMachine.bState = state;
+
+	/* OTG timeouts the hardware doesn't handle:
+	 *  - ...
+	 */
+
+	switch (state) {
+	case OTG_STATE_A_HOST:
+	case OTG_STATE_B_HOST:
+		/* TODO: graceful Gadget shutdown */
+		MUSB_HST_MODE(musb);
+		break;
+
+	case OTG_STATE_A_PERIPHERAL:
+	case OTG_STATE_B_PERIPHERAL:
+		/* TODO: graceful host shutdown */
+		MUSB_DEV_MODE(musb);
+		break;
+
+	default:
+		/* TODO: graceful host shutdown */
+		/* TODO: graceful Gadget shutdown */
+		DBG(1, "state change to %d?\n", state);
+		MUSB_OTG_MODE(musb);
+		break;
+	}
+
+	if (timer)
+		mod_timer(&musb->OtgMachine.Timer, jiffies + timer);
+	else
+		del_timer(&musb->OtgMachine.Timer);
+
+	/* FIXME  the otg state implies MUSB_MODE().  Properly track
+	 * xceiv.state, then remove OtgMachine.bState and MUSB_MODE...
+	 */
+	DBG(2, "==> OTG state %d(%d), mode %s\n",
+			state, musb->xceiv.state,
+			MUSB_MODE(musb));
+}
+
+
+/**
+ * Timer expiration function to complete the interrupt URB on changes
+ * @param ptr standard expiration param (hub pointer)
+ */
+static void otg_timeout(unsigned long ptr)
+{
+	struct otg_machine	*pMachine = (void *) ptr;
+	void __iomem	*mregs;
+	u8		devctl;
+	struct musb	*musb = pMachine->musb;
+	unsigned long	flags;
+
+	DBG(0, "** TIMEOUT ** state %d(%d)\n",
+			pMachine->bState, pMachine->musb->xceiv.state);
+
+	/* REVISIT:  a few of these cases _require_ (per the OTG spec)
+	 * some sort of user notification, such as turning on an LED
+	 * or displaying a message on the screen; INFO() not enough.
+	 */
+
+	spin_lock_irqsave(&musb->Lock, flags);
+	switch (pMachine->bState) {
+	case OTG_STATE_B_SRP_INIT:
+		INFO("SRP failed\n");
+		otg_set_session(pMachine->musb, FALSE);
+		otg_state_changed(pMachine->musb, OTG_STATE_B_IDLE);
+		break;
+
+	case OTG_STATE_B_WAIT_ACON:
+		INFO("No response from A-device\n");
+		mregs = pMachine->musb->pRegs;
+		devctl = musb_readb(mregs, MGC_O_HDRC_DEVCTL);
+		musb_writeb(mregs, MGC_O_HDRC_DEVCTL,
+				devctl & ~MGC_M_DEVCTL_HR);
+		otg_set_session(pMachine->musb, TRUE);
+		otg_state_changed(pMachine->musb, OTG_STATE_B_PERIPHERAL);
+		break;
+
+	case OTG_STATE_A_WAIT_BCON:
+		/* REVISIT we'd like to force the VBUS-off path here... */
+		INFO("No response from B-device\n");
+		otg_set_session(pMachine->musb, FALSE);
+		/* transition via OTG_STATE_A_WAIT_VFALL */
+		otg_state_changed(pMachine->musb, OTG_STATE_A_IDLE);
+		break;
+
+	case OTG_STATE_A_SUSPEND:
+		/* FIXME b-dev HNP is _optional_ so this is no error */
+		INFO("No B-device HNP response\n");
+		otg_set_session(pMachine->musb, FALSE);
+		/* transition via OTG_STATE_A_WAIT_VFALL */
+		otg_state_changed(pMachine->musb, OTG_STATE_A_IDLE);
+		break;
+
+	default:
+		WARN("timeout in state %d, now what?\n", pMachine->bState);
+	}
+	spin_unlock_irqrestore(&musb->Lock, flags);
+}
+
+void MGC_OtgMachineInit(struct otg_machine *pMachine, struct musb *musb)
+{
+	memset(pMachine, 0, sizeof *pMachine);
+	spin_lock_init(&pMachine->Lock);
+	pMachine->musb = musb;
+
+	init_timer(&pMachine->Timer);
+	pMachine->Timer.function = otg_timeout;
+	pMachine->Timer.data = (unsigned long)pMachine;
+
+	pMachine->bState = OTG_STATE_B_IDLE;
+	pMachine->bRequest = MGC_OTG_REQUEST_UNKNOWN;
+}
+
+void MGC_OtgMachineDestroy(struct otg_machine *pMachine)
+{
+	/* stop timer */
+	del_timer_sync(&pMachine->Timer);
+}
+
+/* caller has irqlocked musb */
+void MGC_OtgMachineInputsChanged(struct otg_machine *pMachine,
+				 const MGC_OtgMachineInputs * pInputs)
+{
+
+	DBG(2, "<== bState %d(%d)%s%s%s%s%s%s\n",
+			pMachine->bState, pMachine->musb->xceiv.state,
+			pInputs->bSession ? ", sess" : "",
+			pInputs->bSuspend ? ", susp" : "",
+			pInputs->bConnection ? ", bcon" : "",
+			pInputs->bReset ? ", reset" : "",
+			pInputs->bConnectorId ? ", B-Dev" : ", A-Dev",
+			pInputs->bVbusError ? ", vbus_error" : "");
+
+	if (pInputs->bVbusError) {
+		/* transition via OTG_STATE_VBUS_ERR and
+		 * then OTG_STATE_A_WAIT_VFALL
+		 */
+		otg_state_changed(pMachine->musb, OTG_STATE_A_IDLE);
+		return;
+	}
+
+	switch (pMachine->bState) {
+	case OTG_STATE_B_IDLE:
+		if (pInputs->bSession && pInputs->bConnectorId) {
+			/* WRONG:  if VBUS is below session threshold,
+			 * it's still B_IDLE
+			 */
+			otg_state_changed(pMachine->musb,
+					OTG_STATE_B_PERIPHERAL);
+		}
+		break;
+	case OTG_STATE_A_IDLE:
+		if (pInputs->bConnection) {
+			/*
+			 * SKIP a state because connect IRQ comes so quickly
+			 * after setting session,
+			 * and only happens in host mode
+			 */
+			otg_state_changed(pMachine->musb, OTG_STATE_A_HOST);
+		} else if (pInputs->bSession) {
+			otg_state_changed(pMachine->musb,
+					OTG_STATE_A_WAIT_BCON);
+			mod_timer(&pMachine->Timer, jiffies
+				+ msecs_to_jiffies(MGC_OTG_T_A_WAIT_BCON));
+		}
+		break;
+
+	case OTG_STATE_B_SRP_INIT:
+		if (pInputs->bReset) {
+			otg_state_changed(pMachine->musb,
+					OTG_STATE_B_PERIPHERAL);
+		} else if (pInputs->bConnection) {
+			/* FIXME bogus:  there is no such transition!!! */
+			otg_state_changed(pMachine->musb,
+					pInputs->bConnectorId
+						? OTG_STATE_B_HOST
+						: OTG_STATE_A_HOST);
+		}
+		break;
+
+	case OTG_STATE_B_PERIPHERAL:
+		if (!pInputs->bSession) {
+			otg_state_changed(pMachine->musb, OTG_STATE_B_IDLE);
+		}
+
+		/* FIXME nothing ever sets bRequest ... */
+		if ((MGC_OTG_REQUEST_START_BUS == pMachine->bRequest)
+				&& pMachine->musb->g.b_hnp_enable) {
+			otg_state_changed(pMachine->musb,
+					OTG_STATE_B_WAIT_ACON);
+			//mdelay(10);
+			//otg_set_session(pMachine->musb, FALSE);
+			mod_timer(&pMachine->Timer, jiffies
+				+ msecs_to_jiffies(MGC_OTG_T_B_ASE0_BRST));
+		}
+		break;
+
+	case OTG_STATE_B_WAIT_ACON:
+		if (pInputs->bConnection) {
+			otg_state_changed(pMachine->musb, OTG_STATE_B_HOST);
+		} else if (!pInputs->bSession) {
+			otg_state_changed(pMachine->musb, OTG_STATE_B_IDLE);
+		} else if (!pInputs->bSuspend) {
+			otg_state_changed(pMachine->musb,
+					OTG_STATE_B_PERIPHERAL);
+		}
+		break;
+
+	case OTG_STATE_B_HOST:
+		if (!pInputs->bConnection) {
+			otg_state_changed(pMachine->musb, OTG_STATE_B_IDLE);
+		} else if (pInputs->bConnection && !pInputs->bReset) {
+			/* REVISIT seems incomplete */
+		}
+		break;
+
+	case OTG_STATE_A_WAIT_BCON:
+		if (pInputs->bConnection) {
+			otg_state_changed(pMachine->musb, OTG_STATE_A_HOST);
+		} else if (pInputs->bReset) {
+			/* FIXME there is no such transition */
+			otg_state_changed(pMachine->musb,
+					OTG_STATE_A_PERIPHERAL);
+		}
+		break;
+
+	case OTG_STATE_A_HOST:
+		if (!pInputs->bConnection) {
+			otg_state_changed(pMachine->musb,
+					OTG_STATE_A_WAIT_BCON);
+			mod_timer(&pMachine->Timer, jiffies
+				+ msecs_to_jiffies(MGC_OTG_T_A_WAIT_BCON));
+		} else if (pInputs->bConnection && !pInputs->bReset) {
+			/* REVISIT seems incomplete */
+		}
+		break;
+
+	case OTG_STATE_A_SUSPEND:
+		if (!pInputs->bSuspend) {
+			otg_state_changed(pMachine->musb, OTG_STATE_A_HOST);
+		} else if (!pInputs->bConnection) {
+			if (pMachine->musb->pBus->b_hnp_enable) {
+				otg_state_changed(pMachine->musb,
+						OTG_STATE_A_PERIPHERAL);
+			} else {
+				otg_state_changed(pMachine->musb,
+						OTG_STATE_A_WAIT_BCON);
+				mod_timer(&pMachine->Timer, jiffies
+					+ msecs_to_jiffies(MGC_OTG_T_A_WAIT_BCON));
+			}
+		}
+		break;
+
+	case OTG_STATE_A_PERIPHERAL:
+		if (!pInputs->bSession) {
+			/* transition via OTG_STATE_A_WAIT_VFALL */
+			otg_state_changed(pMachine->musb, OTG_STATE_A_IDLE);
+		} else if (pInputs->bSuspend) {
+			otg_state_changed(pMachine->musb,
+					OTG_STATE_A_WAIT_BCON);
+			mod_timer(&pMachine->Timer, jiffies
+				+ msecs_to_jiffies(MGC_OTG_T_A_WAIT_BCON));
+		}
+		break;
+
+	default:
+		WARN("event in state %d, now what?\n", pMachine->bState);
+	}
+}
Index: linux-2.6.10/drivers/usb/musb/otg.h
===================================================================
--- /dev/null
+++ linux-2.6.10/drivers/usb/musb/otg.h
@@ -0,0 +1,176 @@
+/******************************************************************
+ * Copyright 2005 Mentor Graphics Corporation
+ * Copyright (C) 2005-2006 by Texas Instruments
+ *
+ * This file is part of the Inventra Controller Driver for Linux.
+ *
+ * The Inventra Controller Driver for Linux is free software; you
+ * can redistribute it and/or modify it under the terms of the GNU
+ * General Public License version 2 as published by the Free Software
+ * Foundation.
+ *
+ * The Inventra Controller Driver for Linux is distributed in
+ * the hope that it will be useful, but WITHOUT ANY WARRANTY;
+ * without even the implied warranty of MERCHANTABILITY or
+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public
+ * License for more details.
+ *
+ * You should have received a copy of the GNU General Public License
+ * along with The Inventra Controller Driver for Linux ; if not,
+ * write to the Free Software Foundation, Inc., 59 Temple Place,
+ * Suite 330, Boston, MA  02111-1307  USA
+ *
+ * ANY DOWNLOAD, USE, REPRODUCTION, MODIFICATION OR DISTRIBUTION
+ * OF THIS DRIVER INDICATES YOUR COMPLETE AND UNCONDITIONAL ACCEPTANCE
+ * OF THOSE TERMS.THIS DRIVER IS PROVIDED "AS IS" AND MENTOR GRAPHICS
+ * MAKES NO WARRANTIES, EXPRESS OR IMPLIED, RELATED TO THIS DRIVER.
+ * MENTOR GRAPHICS SPECIFICALLY DISCLAIMS ALL IMPLIED WARRANTIES
+ * OF MERCHANTABILITY; FITNESS FOR A PARTICULAR PURPOSE AND
+ * NON-INFRINGEMENT.  MENTOR GRAPHICS DOES NOT PROVIDE SUPPORT
+ * SERVICES OR UPDATES FOR THIS DRIVER, EVEN IF YOU ARE A MENTOR
+ * GRAPHICS SUPPORT CUSTOMER.
+ ******************************************************************/
+
+/*
+ * Interface to a generic OTG state machine for use by an OTG controller.
+ *
+ * FIXME most of this must vanish; usbcore handles some of it, and
+ * the OTG parts of a peripheral controller (and its driver) handle
+ * other things.  Package it as an "otg transceiver".
+ */
+
+#ifndef __MUSB_LINUX_OTG_H__
+#define __MUSB_LINUX_OTG_H__
+
+#include <linux/spinlock.h>
+#include <linux/timer.h>
+
+/**
+ * Introduction.
+ * An OTG state machine for use by a controller driver for an OTG controller
+ * that wishes to be OTG-aware.
+ * The state machine requires relevant inputs and a couple of services
+ * from the controller driver, and calls the controller driver to inform
+ * it of the current state and errors.
+ * Finally, it provides the necessary bus control service.
+ */
+
+/****************************** CONSTANTS ********************************/
+
+/**
+ * Define this (in milliseconds) to a target-specific value to override default.
+ * The OTG-spec minimum is 5000, and maximum is 6000 (see OTG spec errata).
+ */
+#ifndef MGC_OTG_T_B_SRP_FAIL
+#define MGC_OTG_T_B_SRP_FAIL	5000
+#endif
+
+/**
+ * Define this (in milliseconds) to a target-specific value to override default.
+ * This is the time an A-device should wait for a B-device to connect.
+ * The OTG-spec minimum is 1000.
+ * As a special case, for normal host-like behavior, you can set this to 0.
+ */
+#ifndef MGC_OTG_T_A_WAIT_BCON
+#define MGC_OTG_T_A_WAIT_BCON	1000
+#endif
+
+/**
+ * Define this (in milliseconds) to a target-specific value to override default.
+ * The OTG-spec minimum is 250.
+ */
+#ifndef MGC_OTG_T_AIDL_BDIS
+#define MGC_OTG_T_AIDL_BDIS	250
+#endif
+
+//#define MGC_OTG_T_B_ASE0_BRST 4
+#define MGC_OTG_T_B_ASE0_BRST	100
+
+/*
+ * MGC_OtgRequest.
+ * A software request for the OTG state machine
+ */
+typedef enum {
+	MGC_OTG_REQUEST_UNKNOWN,
+    /** Request the bus */
+	MGC_OTG_REQUEST_START_BUS,
+    /** Drop the bus */
+	MGC_OTG_REQUEST_DROP_BUS,
+    /** Suspend the bus */
+	MGC_OTG_REQUEST_SUSPEND_BUS,
+    /** Reset the state machine */
+	MGC_OTG_REQUEST_RESET
+} MGC_OtgRequest;
+
+
+/******************************** TYPES **********************************/
+
+/*
+ * MGC_OtgMachineInputs.
+ * The set of inputs which drives the state machine
+ * @field bSession TRUE when a session is in progress; FALSE when not
+ * @field bConnectorId TRUE for B-device; FALSE for A-device
+ * (assumed valid only when a bSession is TRUE)
+ * @field bReset TRUE when reset is detected (peripheral role only)
+ * @field bConnection TRUE when connection is detected (host role only)
+ * @field bSuspend TRUE when bus suspend is detected
+ * @field bVbusError TRUE when a Vbus error is detected
+ */
+typedef struct {
+	u8 bSession;
+	u8 bConnectorId;
+	u8 bReset;
+	u8 bConnection;
+	u8 bSuspend;
+	u8 bVbusError;
+} MGC_OtgMachineInputs;
+
+/*
+ * OTG state machine instance data.
+ * @field Lock spinlock
+ * @field bState current state (one of the OTG_STATE_* constants)
+ * @field pOtgServices pointer to OTG services
+ * @field Timer interval timer for status change interrupts
+ * @field bState current state
+ * @field bRequest current pending request
+ */
+struct otg_machine {
+	spinlock_t Lock;
+	struct musb		*musb;
+	enum usb_otg_state	bState;
+	struct timer_list Timer;
+	MGC_OtgRequest bRequest;
+
+	/* FIXME standard Linux-USB host and peripheral code includes
+	 * OTG support ... most of this "otg machine" must vanish
+	 */
+
+};
+
+/****************************** FUNCTIONS ********************************/
+
+/*
+ * Initialize an OTG state machine.
+ */
+extern void MGC_OtgMachineInit(struct otg_machine * pMachine,
+			     struct musb *musb);
+
+/*
+ * Destroy an OTG state machine
+ * @param pMachine machine pointer
+ * @see #MGC_OtgMachineInit
+ */
+extern void MGC_OtgMachineDestroy(struct otg_machine * pMachine);
+
+/*
+ * OTG inputs have changed.
+ * A controller driver calls this when anything in the
+ * MGC_OtgMachineInputs has changed
+ * @param pMachine machine pointer
+ * @param pInputs current inputs
+ * @see #MGC_OtgMachineInit
+ */
+extern void MGC_OtgMachineInputsChanged(struct otg_machine * pMachine,
+					const MGC_OtgMachineInputs * pInputs);
+
+#endif				/* multiple inclusion protection */
Index: linux-2.6.10/drivers/usb/musb/plat_arc.h
===================================================================
--- /dev/null
+++ linux-2.6.10/drivers/usb/musb/plat_arc.h
@@ -0,0 +1,101 @@
+/******************************************************************
+ * Copyright 2005 Mentor Graphics Corporation
+ * Copyright (C) 2005-2006 by Texas Instruments
+ *
+ * This file is part of the Inventra Controller Driver for Linux.
+ *
+ * The Inventra Controller Driver for Linux is free software; you
+ * can redistribute it and/or modify it under the terms of the GNU
+ * General Public License version 2 as published by the Free Software
+ * Foundation.
+ *
+ * The Inventra Controller Driver for Linux is distributed in
+ * the hope that it will be useful, but WITHOUT ANY WARRANTY;
+ * without even the implied warranty of MERCHANTABILITY or
+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public
+ * License for more details.
+ *
+ * You should have received a copy of the GNU General Public License
+ * along with The Inventra Controller Driver for Linux ; if not,
+ * write to the Free Software Foundation, Inc., 59 Temple Place,
+ * Suite 330, Boston, MA  02111-1307  USA
+ *
+ * ANY DOWNLOAD, USE, REPRODUCTION, MODIFICATION OR DISTRIBUTION
+ * OF THIS DRIVER INDICATES YOUR COMPLETE AND UNCONDITIONAL ACCEPTANCE
+ * OF THOSE TERMS.THIS DRIVER IS PROVIDED "AS IS" AND MENTOR GRAPHICS
+ * MAKES NO WARRANTIES, EXPRESS OR IMPLIED, RELATED TO THIS DRIVER.
+ * MENTOR GRAPHICS SPECIFICALLY DISCLAIMS ALL IMPLIED WARRANTIES
+ * OF MERCHANTABILITY; FITNESS FOR A PARTICULAR PURPOSE AND
+ * NON-INFRINGEMENT.  MENTOR GRAPHICS DOES NOT PROVIDE SUPPORT
+ * SERVICES OR UPDATES FOR THIS DRIVER, EVEN IF YOU ARE A MENTOR
+ * GRAPHICS SUPPORT CUSTOMER.
+ ******************************************************************/
+
+/*
+ * Linux-specific architecture definitions
+ */
+
+#ifndef __MUSB_LINUX_PLATFORM_ARCH_H__
+#define __MUSB_LINUX_PLATFORM_ARCH_H__
+
+#include <asm/io.h>
+
+/* NOTE:  these offsets are all in bytes */
+
+static inline u16 musb_readw(const void __iomem *addr, unsigned offset)
+	{ return __raw_readw(addr + offset); }
+
+static inline u32 musb_readl(const void __iomem *addr, unsigned offset)
+	{ return __raw_readl(addr + offset); }
+
+
+static inline void musb_writew(void __iomem *addr, unsigned offset, u16 data)
+	{ __raw_writew(data, addr + offset); }
+
+static inline void musb_writel(void __iomem *addr, unsigned offset, u32 data)
+	{ __raw_writel(data, addr + offset); }
+
+
+#ifdef CONFIG_USB_TUSB_6010
+
+/*
+ * TUSB6010 doesn't allow 8-bit access; 16-bit access is the minimum.
+ */
+static inline u8 musb_readb(const void __iomem *addr, unsigned offset)
+{
+	u16 tmp;
+	u8 val;
+
+	tmp = __raw_readw(addr + (offset & ~1));
+	if (offset & 1)
+		val = (tmp >> 8);
+	else
+		val = tmp & 0xff;
+
+	return val;
+}
+
+static inline void musb_writeb(void __iomem *addr, unsigned offset, u8 data)
+{
+	u16 tmp;
+
+	tmp = __raw_readw(addr + (offset & ~1));
+	if (offset & 1)
+		tmp = (data << 8) | (tmp & 0xff);
+	else
+		tmp = (tmp & 0xff00) | data;
+
+	__raw_writew(tmp, addr + (offset & ~1));
+}
+
+#else
+
+static inline u8 musb_readb(const void __iomem *addr, unsigned offset)
+	{ return __raw_readb(addr + offset); }
+
+static inline void musb_writeb(void __iomem *addr, unsigned offset, u8 data)
+	{ __raw_writeb(data, addr + offset); }
+
+#endif	/* CONFIG_USB_TUSB_6010 */
+
+#endif
Index: linux-2.6.10/drivers/usb/musb/plat_cnf.h
===================================================================
--- /dev/null
+++ linux-2.6.10/drivers/usb/musb/plat_cnf.h
@@ -0,0 +1,189 @@
+/******************************************************************
+ * Copyright 2005 Mentor Graphics Corporation
+ * Copyright (C) 2005-2006 by Texas Instruments
+ *
+ * This file is part of the Inventra Controller Driver for Linux.
+ *
+ * The Inventra Controller Driver for Linux is free software; you
+ * can redistribute it and/or modify it under the terms of the GNU
+ * General Public License version 2 as published by the Free Software
+ * Foundation.
+ *
+ * The Inventra Controller Driver for Linux is distributed in
+ * the hope that it will be useful, but WITHOUT ANY WARRANTY;
+ * without even the implied warranty of MERCHANTABILITY or
+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public
+ * License for more details.
+ *
+ * You should have received a copy of the GNU General Public License
+ * along with The Inventra Controller Driver for Linux ; if not,
+ * write to the Free Software Foundation, Inc., 59 Temple Place,
+ * Suite 330, Boston, MA  02111-1307  USA
+ *
+ * ANY DOWNLOAD, USE, REPRODUCTION, MODIFICATION OR DISTRIBUTION
+ * OF THIS DRIVER INDICATES YOUR COMPLETE AND UNCONDITIONAL ACCEPTANCE
+ * OF THOSE TERMS.THIS DRIVER IS PROVIDED "AS IS" AND MENTOR GRAPHICS
+ * MAKES NO WARRANTIES, EXPRESS OR IMPLIED, RELATED TO THIS DRIVER.
+ * MENTOR GRAPHICS SPECIFICALLY DISCLAIMS ALL IMPLIED WARRANTIES
+ * OF MERCHANTABILITY; FITNESS FOR A PARTICULAR PURPOSE AND
+ * NON-INFRINGEMENT.  MENTOR GRAPHICS DOES NOT PROVIDE SUPPORT
+ * SERVICES OR UPDATES FOR THIS DRIVER, EVEN IF YOU ARE A MENTOR
+ * GRAPHICS SUPPORT CUSTOMER.
+ ******************************************************************/
+
+/*
+ * Linux-specific platform configuration.
+ */
+
+#ifndef __MUSB_LINUX_CONFIG_H__
+#define __MUSB_LINUX_CONFIG_H__
+
+/*
+ * Get core configuration from a header converted (by cfg_conv)
+ * from the Verilog config file generated by the core config utility
+ *
+ * For now we assume that header is provided along with other
+ * arch-specific files.  Discrete chips will need a build tweak.
+ * So will using AHB IDs from silicon that provides them.
+ */
+#include <asm/arch/hdrc_cnf.h>
+
+/*
+ * Handle dynamic FIFO sizing in a way that doesn't create more code
+ * (but could make your brain hurt)
+ *
+ * FIXME simplify: just provide a handful of predefined configurations
+ */
+#ifdef MUSB_C_DYNFIFO_DEF
+#define MGC_DFIFO_TOTAL (1 << (MUSB_C_RAM_BITS + 2))
+
+/* values for the SZ field */
+#define MGC_BLK_SZ 6		/* 512 bytes */
+#define MGC_CTL_SZ 3		/* 64 bytes */
+#define MGC_ALL_SZ 0		/* 8 bytes minimum for anything (hubs to 64 ports, most HIDs) */
+
+#ifdef MUSB_C_HB_TX
+#define MGC_ISO_TX_SZ 9		/* 4096 bytes for high-bandwidth (needs 3072) */
+#else
+#define MGC_ISO_TX_SZ 7		/* 1024 bytes for normal-bandwidth */
+#endif
+
+#ifdef MUSB_C_HB_RX
+#define MGC_ISO_RX_SZ 9		/* 4096 bytes for high-bandwidth (needs 3072) */
+#else
+#define MGC_ISO_RX_SZ 7		/* 1024 bytes for normal-bandwidth */
+#endif
+
+/*
+ * Define desires by subtracting all, so impossible ones become negatives
+ */
+#if MUSB_C_NUM_EPS > 2
+
+#define MGC_BLK_DB 1
+/* isoch Tx: try a double-buffered one with a double-buffered bulk */
+#define MGC_ISO_TX_DB 1
+#define MGC_DFIFO_ISO_TX (MGC_DFIFO_TOTAL - (1 << (MGC_ISO_TX_SZ+4)) - (1 << (MGC_BLK_SZ+3+MGC_BLK_DB)) - (1 << (MGC_CTL_SZ+3)) - ((MUSB_C_NUM_EPS - 3) * (1 << (MGC_ALL_SZ+3))))
+#if MGC_DFIFO_ISO_TX < 0
+/* no good; try with a single-buffered bulk */
+#undef MGC_BLK_DB
+#define MGC_BLK_DB 0
+#undef MGC_DFIFO_ISO_TX
+#define MGC_DFIFO_ISO_TX (MGC_DFIFO_TOTAL - (1 << (MGC_ISO_TX_SZ+4)) - (1 << (MGC_BLK_SZ+3+MGC_BLK_DB)) - (1 << (MGC_CTL_SZ+3)) - ((MUSB_C_NUM_EPS - 3) * (1 << (MGC_ALL_SZ+3))))
+#endif
+#if MGC_DFIFO_ISO_TX < 0
+/* still no good; try single-buffered isoch Tx */
+#undef MGC_DFIFO_ISO_TX
+#undef MGC_ISO_TX_DB
+#define MGC_ISO_TX_DB 0
+#define MGC_DFIFO_ISO_TX (MGC_DFIFO_TOTAL - (1 << (MGC_ISO_TX_SZ+3)) - (1 << (MGC_BLK_SZ+3+MGC_BLK_DB)) - (1 << (MGC_CTL_SZ+3)) - ((MUSB_C_NUM_EPS - 3) * (1 << (MGC_ALL_SZ+3))))
+#endif
+/* actual isoch Tx size */
+#define MGC_DFIFO_ISO_TX_SIZE ((MGC_DFIFO_ISO_TX < 0) ? 0 : (1 << (MGC_ISO_TX_SZ+3+MGC_ISO_TX_DB)))
+
+/* isoch Rx: try a double-buffered one with a (current)-buffered bulk */
+#define MGC_ISO_RX_DB 1
+#define MGC_DFIFO_ISO_RX (MGC_DFIFO_TOTAL - MGC_DFIFO_ISO_TX_SIZE - (1 << (MGC_ISO_RX_SZ+4)) - (1 << (MGC_BLK_SZ+3+MGC_BLK_DB)) - (1 << (MGC_CTL_SZ+3)) - ((MUSB_C_NUM_EPS - 3) * (1 << (MGC_ALL_SZ+3))))
+#if MGC_DFIFO_ISO_RX < 0
+/* no good; try with a single-buffered bulk */
+#undef MGC_BLK_DB
+#define MGC_BLK_DB 0
+#undef MGC_DFIFO_ISO_RX
+#define MGC_DFIFO_ISO_RX (MGC_DFIFO_TOTAL - MGC_DFIFO_ISO_TX_SIZE - (1 << (MGC_ISO_RX_SZ+4)) - (1 << (MGC_BLK_SZ+3+MGC_BLK_DB)) - (1 << (MGC_CTL_SZ+3)) - ((MUSB_C_NUM_EPS - 3) * (1 << (MGC_ALL_SZ+3))))
+#endif
+#if MGC_DFIFO_ISO_RX < 0
+/* still no good; try single-buffered isoch Rx */
+#undef MGC_DFIFO_ISO_RX
+#undef MGC_ISO_RX_DB
+#define MGC_ISO_RX_DB 0
+#define MGC_DFIFO_ISO_RX (MGC_DFIFO_TOTAL - MGC_DFIFO_ISO_TX_SIZE - (1 << (MGC_ISO_RX_SZ+3)) - (1 << (MGC_BLK_SZ+3+MGC_BLK_DB)) - (1 << (MGC_CTL_SZ+3)) - ((MUSB_C_NUM_EPS - 3) * (1 << (MGC_ALL_SZ+3))))
+#endif
+/* actual isoch Rx size */
+#define MGC_DFIFO_ISO_RX_SIZE ((MGC_DFIFO_ISO_RX < 0) ? 0 : (1 << (MGC_ISO_RX_SZ+3+MGC_ISO_RX_DB)))
+
+/* register values the code may use */
+#define MGC_DFIFO_ISO_TX_VAL ((MGC_ISO_TX_DB << 4) | MGC_ISO_TX_SZ)
+#define MGC_DFIFO_ISO_RX_VAL ((MGC_ISO_RX_DB << 4) | MGC_ISO_RX_SZ)
+#define MGC_DFIFO_BLK_VAL ((MGC_BLK_DB << 4) | MGC_BLK_SZ)
+
+#else				/* !(MUSB_C_NUM_EPS > 2) */
+
+/* <= 2 endpoints; make one suitable for bulk */
+#if MGC_DFIFO_TOTAL > 1024
+#define MGC_BLK_DB 1
+#else
+#define MGC_BLK_DB 0
+#endif
+#define MGC_DFIFO_BLK_VAL ((MGC_BLK_DB << 4) | MGC_BLK_SZ)
+#define MGC_DFIFO_ISO_TX -1
+#define MGC_DFIFO_ISO_TX_SIZE 0
+#define MGC_DFIFO_ISO_RX -1
+#define MGC_DFIFO_ISO_RX_SIZE 0
+
+#endif				/* MUSB_C_NUM_EPS > 2 */
+
+/* now compute actual size per remaining end */
+#define MGC_DFIFO_BLK_SIZE (1 << (MGC_BLK_SZ+3+MGC_BLK_DB))
+#define MGC_DFIFO_CTL_SIZE (1 << (MGC_CTL_SZ+3))
+#define MGC_DFIFO_REMAIN (MGC_DFIFO_TOTAL - MGC_DFIFO_ISO_TX_SIZE - MGC_DFIFO_ISO_RX_SIZE - MGC_DFIFO_BLK_SIZE - MGC_DFIFO_CTL_SIZE)
+
+/* but, if there's a problem, throw out bulk and try again */
+#if MGC_DFIFO_REMAIN < 0
+#undef MGC_DFIFO_BLK_SIZE
+#undef MGC_DFIFO_BLK_VAL
+#define MGC_DFIFO_BLK_SIZE 0
+#define MGC_DFIFO_BLK_VAL 0
+#define MGC_DFIFO_REMAIN (MGC_DFIFO_TOTAL - MGC_DFIFO_ISO_TX_SIZE - MGC_DFIFO_ISO_RX_SIZE - MGC_DFIFO_BLK_SIZE - MGC_DFIFO_CTL_SIZE)
+#endif
+
+#define MGC_DFIFO_ALL_COUNT (MUSB_C_NUM_EPS - ((MGC_DFIFO_ISO_TX < 0) ? 0 : 1) - ((MGC_DFIFO_ISO_RX < 0) ? 0 : 1) - (MGC_DFIFO_BLK_SIZE ? 1 : 0) - 1)
+#if MGC_DFIFO_ALL_COUNT > 0
+#define MGC_DFIFO_ALL_SIZE (MGC_DFIFO_REMAIN / MGC_DFIFO_ALL_COUNT)
+#else
+#define MGC_DFIFO_ALL_SIZE 0
+#endif
+/* set value for remaining */
+#if MGC_DFIFO_ALL_SIZE >= 4096
+#define MGC_DFIFO_ALL_VAL 9
+#elif MGC_DFIFO_ALL_SIZE >= 2048
+#define MGC_DFIFO_ALL_VAL 8
+#elif MGC_DFIFO_ALL_SIZE >= 1024
+#define MGC_DFIFO_ALL_VAL 7
+#elif MGC_DFIFO_ALL_SIZE >= 512
+#define MGC_DFIFO_ALL_VAL 6
+#elif MGC_DFIFO_ALL_SIZE >= 256
+#define MGC_DFIFO_ALL_VAL 5
+#elif MGC_DFIFO_ALL_SIZE >= 128
+#define MGC_DFIFO_ALL_VAL 4
+#elif MGC_DFIFO_ALL_SIZE >= 64
+#define MGC_DFIFO_ALL_VAL 3
+#elif MGC_DFIFO_ALL_SIZE >= 32
+#define MGC_DFIFO_ALL_VAL 2
+#elif MGC_DFIFO_ALL_SIZE >= 16
+#define MGC_DFIFO_ALL_VAL 1
+#else
+#define MGC_DFIFO_ALL_VAL 0
+#endif
+
+#endif				/* MUSB_C_DYNFIFO_DEF */
+
+#endif	/* __MUSB_LINUX_CONFIG_H__ */
Index: linux-2.6.10/drivers/usb/musb/plat_uds.c
===================================================================
--- /dev/null
+++ linux-2.6.10/drivers/usb/musb/plat_uds.c
@@ -0,0 +1,1910 @@
+/*****************************************************************
+ * Copyright 2005 Mentor Graphics Corporation
+ * Copyright (C) 2005-2006 by Texas Instruments
+ *
+ * This file is part of the Inventra Controller Driver for Linux.
+ *
+ * The Inventra Controller Driver for Linux is free software; you
+ * can redistribute it and/or modify it under the terms of the GNU
+ * General Public License version 2 as published by the Free Software
+ * Foundation.
+ *
+ * The Inventra Controller Driver for Linux is distributed in
+ * the hope that it will be useful, but WITHOUT ANY WARRANTY;
+ * without even the implied warranty of MERCHANTABILITY or
+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public
+ * License for more details.
+ *
+ * You should have received a copy of the GNU General Public License
+ * along with The Inventra Controller Driver for Linux ; if not,
+ * write to the Free Software Foundation, Inc., 59 Temple Place,
+ * Suite 330, Boston, MA  02111-1307  USA
+ *
+ * ANY DOWNLOAD, USE, REPRODUCTION, MODIFICATION OR DISTRIBUTION
+ * OF THIS DRIVER INDICATES YOUR COMPLETE AND UNCONDITIONAL ACCEPTANCE
+ * OF THOSE TERMS.THIS DRIVER IS PROVIDED "AS IS" AND MENTOR GRAPHICS
+ * MAKES NO WARRANTIES, EXPRESS OR IMPLIED, RELATED TO THIS DRIVER.
+ * MENTOR GRAPHICS SPECIFICALLY DISCLAIMS ALL IMPLIED WARRANTIES
+ * OF MERCHANTABILITY; FITNESS FOR A PARTICULAR PURPOSE AND
+ * NON-INFRINGEMENT.  MENTOR GRAPHICS DOES NOT PROVIDE SUPPORT
+ * SERVICES OR UPDATES FOR THIS DRIVER, EVEN IF YOU ARE A MENTOR
+ * GRAPHICS SUPPORT CUSTOMER.
+ ******************************************************************/
+
+/*
+ * Inventra (Multipoint) Dual-Role Controller Driver for Linux.
+ *
+ * This consists of a Host Controller Driver (HCD) and a peripheral
+ * controller driver implementing the "Gadget" API; OTG support is
+ * in the works.  These are normal Linux-USB controller drivers which
+ * use IRQs and have no dedicated thread.
+ *
+ * This version of the driver has only been used with products from
+ * Texas Instruments.  Those products integrate the Inventra logic
+ * with other DMA, IRQ, and bus modules, as well as other logic that
+ * needs to be reflected in this driver.
+ *
+ *
+ * NOTE:  the original Mentor code here was pretty much a collection
+ * of mechanisms that don't seem to have been fully integrated/working
+ * for any Linux kernel version.  This version aims at Linux 2.6.10, and
+ * plans for integration with more current kernels.  Key open issues
+ * include:
+ *
+ *  - Lack of host-side transaction scheduling, for all transfer types.
+ *    The hardware doesn't do it; instead, software must.
+ *
+ *    This is not an issue for OTG devices that don't support external
+ *    hubs, but for more "normal" USB hosts it's a user issue that the
+ *    "multipoint" support doesn't scale in the expected ways.  That
+ *    includes DaVinci EVM in a common non-OTG mode.
+ *
+ *      * Control and bulk use dedicated endpoints, and there's as
+ *        yet no mechanism to either (a) reclaim the hardware when
+ *        peripherals are NAKing, which gets complicated with bulk
+ *        endpoints, or (b) use more than a single bulk endpoint in
+ *        each direction.
+ *
+ *        RESULT:  one device may be perceived as blocking another one.
+ *
+ *      * Interrupt and isochronous will dynamically allocate endpoint
+ *        hardware, but (a) there's no record keeping for bandwidth;
+ *        (b) in the common case that few endpoints are available, there
+ *	  is no mechanism to reuse endpoints to talk to multiple devices.
+ *
+ *	  RESULT:  At one extreme, bandwidth can be overcommitted in
+ *	  some hardware configurations, no faults will be reported.
+ *	  At the other extreme, the bandwidth capabilities which do
+ *	  exist tend to be severely undercommitted.  You can't yet hook
+ *	  up both a keyboard and a mouse to an external USB hub.
+ *
+ *      * Host side doesn't understand that hardware endpoints have two
+ *        directions, so it uses only half the resources available on
+ *        chips like DaVinci or TUSB 6010.
+ *
+ *	  RESULT:  On DaVinci (and TUSB 6010), only one external device may
+ *	  use periodic transfers, other than the hub used to connect it.
+ *	  (And if it were to understand, there would still be limitations
+ *	  because of the lack of periodic endpoint scheduling.)
+ *
+ *  - Host-side doesn't use the HCD framework, even the older version in
+ *    the 2.6.10 kernel, which doesn't provide per-endpoint URB queues.
+ *
+ *    RESULT:  code bloat, because it provides its own root hub;
+ *    correctness issues.
+ *
+ *  - Provides its own OTG bits.  These are untested, and many of them
+ *    seem to be superfluous code bloat given what usbcore does.  (They
+ *    have now been partially removed.)
+ */
+
+/*
+ * This gets many kinds of configuration information:
+ *	- Kconfig for everything user-configurable
+ *	- <asm/arch/hdrc_cnf.h> for SOC or family details
+ *	- platform_device for addressing, irq, and platform_data
+ *	- platform_data is mostly for board-specific informarion
+ *
+ * Most of the conditional compilation will (someday) vanish.
+ */
+
+#include <linux/config.h>
+#include <linux/module.h>
+#include <linux/pci.h>
+#include <linux/kernel.h>
+#include <linux/sched.h>
+#include <linux/slab.h>
+#include <linux/init.h>
+#include <linux/list.h>
+// #include <linux/platform_device.h>
+// #include <linux/clk.h>
+#include <asm/hardware/clock.h>
+
+#include <asm/io.h>
+#include <asm/arch/hardware.h>
+#include <asm/arch/memory.h>
+
+#ifdef	CONFIG_ARM
+#include <asm/mach-types.h>
+#endif
+
+// #ifdef CONFIG_USB_MUSB_HDRC_HCD
+#include <linux/usb.h>
+#include "../core/hcd.h"
+// #endif
+
+#if MUSB_DEBUG > 0
+unsigned MGC_DebugLevel = MUSB_DEBUG;
+#endif
+
+#include "musbdefs.h"
+// #ifdef CONFIG_USB_MUSB_HDRC_HCD
+#include "musb_host.h"
+// #endif
+
+
+#ifdef CONFIG_ARCH_DAVINCI
+#include "davinci.h"
+#endif
+
+#include "tusb_6010.h"
+
+
+/***************************** CONSTANTS ********************************/
+
+#define DRIVER_AUTHOR "Mentor Graphics Corp. and Texas Instruments"
+#define DRIVER_DESC "Inventra Dual-Role USB Controller Driver"
+
+#define MUSB_VERSION_BASE "2.2a/db-0.4.8"
+
+#ifndef MUSB_VERSION_SUFFIX
+#define MUSB_VERSION_SUFFIX	 ""
+#endif
+#define MUSB_VERSION	MUSB_VERSION_BASE MUSB_VERSION_SUFFIX
+
+#define DRIVER_INFO DRIVER_DESC "v" MUSB_VERSION
+
+static const char longname[] = DRIVER_INFO;
+const char musb_driver_name[] = "musb_hdrc";
+
+/* this module is always GPL, the gadget might not... */
+MODULE_DESCRIPTION(DRIVER_INFO);
+MODULE_AUTHOR(DRIVER_AUTHOR);
+MODULE_LICENSE("GPL");
+
+/* time (millseconds) to wait before a restart */
+#define MUSB_RESTART_TIME        5000
+
+/* how many babbles to allow before giving up */
+#define MUSB_MAX_BABBLE_COUNT    10
+
+
+extern void MGC_HdrcEnableTXDMA(struct musb * pThis, u8 bEnd);
+
+/*************************************************************************
+ * HDRC functions
+**************************************************************************/
+
+static void otg_input_changed(struct musb * pThis, u8 devctl, u8 reset,
+			 u8 connection, u8 suspend)
+{
+#ifdef CONFIG_USB_MUSB_OTG
+	struct otg_machine	*otgm = &pThis->OtgMachine;
+	MGC_OtgMachineInputs Inputs;
+
+	/* reading suspend state from Power register does NOT work */
+	memset(&Inputs, 0, sizeof(Inputs));
+
+	Inputs.bSession = (devctl & MGC_M_DEVCTL_SESSION) ? TRUE : FALSE;
+	Inputs.bSuspend = suspend;
+	Inputs.bConnection = connection;
+	Inputs.bReset = reset;
+	Inputs.bConnectorId = (devctl & MGC_M_DEVCTL_BDEVICE) ? TRUE : FALSE;
+
+	MGC_OtgMachineInputsChanged(otgm, &Inputs);
+#endif
+}
+
+static void otg_input_changed_X(struct musb * pThis, u8 bVbusError, u8 bConnect)
+{
+#ifdef CONFIG_USB_MUSB_OTG
+	MGC_OtgMachineInputs Inputs;
+	void __iomem *pBase = pThis->pRegs;
+	u8 devctl = musb_readb(pBase, MGC_O_HDRC_DEVCTL);
+	u8 power = musb_readb(pBase, MGC_O_HDRC_POWER);
+
+	DBG(2, "<== power %02x, devctl %02x%s%s\n", power, devctl,
+			bConnect ? ", bcon" : "",
+			bVbusError ? ", vbus_error" : "");
+
+	/* speculative */
+	memset(&Inputs, 0, sizeof(Inputs));
+	Inputs.bSession = (devctl & MGC_M_DEVCTL_SESSION) ? TRUE : FALSE;
+	Inputs.bConnectorId = (devctl & MGC_M_DEVCTL_BDEVICE) ? TRUE : FALSE;
+	Inputs.bReset = (power & MGC_M_POWER_RESET) ? TRUE : FALSE;
+	Inputs.bConnection = bConnect;
+	Inputs.bVbusError = bVbusError;
+	Inputs.bSuspend = (power & MGC_M_POWER_SUSPENDM) ? TRUE : FALSE;
+	MGC_OtgMachineInputsChanged(&(pThis->OtgMachine), &Inputs);
+#endif				/* CONFIG_USB_MUSB_OTG */
+}
+
+#ifdef CONFIG_USB_MUSB_HDRC_HCD
+/*
+ * Timer completion callback
+ */
+static void musb_timer_done(unsigned long pParam)
+{
+	u8 power;
+	struct musb *pThis = (void *) pParam;
+	void __iomem *pBase = pThis->pRegs;
+	unsigned long	flags;
+
+	spin_lock_irqsave(&pThis->Lock, flags);
+	switch (pThis->xceiv.state) {
+	case OTG_STATE_A_HOST:
+		DBG(2, "finish RESUME signaling\n");
+		power = musb_readb(pBase, MGC_O_HDRC_POWER);
+		musb_writeb(pBase, MGC_O_HDRC_POWER,
+				power & ~MGC_M_POWER_RESUME);
+		MGC_VirtualHubPortResumed(&pThis->RootHub, 0);
+		otg_input_changed_X(pThis, FALSE, FALSE);
+		break;
+	case OTG_STATE_A_WAIT_VRISE:
+		DBG(2, "restart (?)\n");
+		musb_start((struct musb *) pParam);
+		break;
+	default:
+		DBG(1, "<== in state %d\n", pThis->xceiv.state);
+		break;
+	}
+	spin_unlock_irqrestore(&pThis->Lock, flags);
+}
+#endif
+
+#ifndef CONFIG_USB_TUSB_6010
+/*
+ * Load an endpoint's FIFO
+ */
+void musb_write_fifo(struct musb_hw_ep *hw_ep, u16 wCount, const u8 *pSource)
+{
+	void __iomem *fifo = hw_ep->fifo;
+
+	prefetch((u8 *)pSource);
+
+	DBG(4, "%cX ep%d fifo %p count %d buf %p\n",
+			'T', hw_ep->bLocalEnd, fifo, wCount, pSource);
+
+	/* we can't assume unaligned reads work */
+	if (likely((0x01 & (unsigned long) pSource) == 0)) {
+		u16	index = 0;
+
+		/* best case is 32bit-aligned source address */
+		if ((0x02 & (unsigned long) pSource) == 0) {
+			if (wCount >= 4) {
+				writesl(fifo, pSource + index, wCount >> 2);
+				index += wCount & ~0x03;
+			}
+			if (wCount & 0x02) {
+				musb_writew(fifo, 0, *(u16*)&pSource[index]);
+				index += 2;
+			}
+		} else {
+			if (wCount >= 2) {
+				writesw(fifo, pSource + index, wCount >> 1);
+				index += wCount & ~0x01;
+			}
+		}
+		if (wCount & 0x01)
+			musb_writeb(fifo, 0, pSource[index]);
+	} else  {
+		/* byte aligned */
+		writesb(fifo, pSource, wCount);
+	}
+}
+
+/*
+ * Unload an endpoint's FIFO
+ */
+void musb_read_fifo(struct musb_hw_ep *hw_ep, u16 wCount, u8 *pDest)
+{
+	void __iomem *fifo = hw_ep->fifo;
+
+	DBG(4, "%cX ep%d fifo %p count %d buf %p\n",
+			'R', hw_ep->bLocalEnd, fifo, wCount, pDest);
+
+	/* we can't assume unaligned writes work */
+	if (likely((0x01 & (unsigned long) pDest) == 0)) {
+		u16	index = 0;
+
+		/* best case is 32bit-aligned destination address */
+		if ((0x02 & (unsigned long) pDest) == 0) {
+			if (wCount >= 4) {
+				readsl(fifo, pDest, wCount >> 2);
+				index = wCount & ~0x03;
+			}
+			if (wCount & 0x02) {
+				*(u16*)&pDest[index] = musb_readw(fifo, 0);
+				index += 2;
+			}
+		} else {
+			if (wCount >= 2) {
+				readsw(fifo, pDest, wCount >> 1);
+				index = wCount & ~0x01;
+			}
+		}
+		if (wCount & 0x01)
+			pDest[index] = musb_readb(fifo, 0);
+	} else  {
+		/* byte aligned */
+		readsb(fifo, pDest, wCount);
+	}
+}
+
+#endif	/* normal PIO */
+
+
+/*
+ * Interrupt Service Routine to record USB "global" interrupts.
+ * Since these do not happen often and signify things of
+ * paramount importance, it seems OK to check them individually;
+ * the order of the tests is specified in the manual
+ *
+ * @param pThis instance pointer
+ * @param bIntrUSB register contents
+ * @param devctl
+ * @param power
+ */
+static irqreturn_t musb_stage0_irq(struct musb * pThis, u8 bIntrUSB,
+				    u8 devctl, u8 power)
+{
+	irqreturn_t handled = IRQ_NONE;
+#ifdef CONFIG_USB_MUSB_HDRC_HCD
+	void __iomem *pBase = pThis->pRegs;
+#endif
+
+	DBG(3, "<== Power=%02x, DevCtl=%02x, bIntrUSB=0x%x\n", power, devctl,
+	    bIntrUSB);
+
+	/* in host mode when a device resume me (from power save)
+	 * in device mode when the host resume me; it shold not change
+	 * "identity".
+	 */
+	if (bIntrUSB & MGC_M_INTR_RESUME) {
+		handled = IRQ_HANDLED;
+		DBG(3, "RESUME\n");
+
+		if (devctl & MGC_M_DEVCTL_HM) {
+#ifdef CONFIG_USB_MUSB_HDRC_HCD
+			/* REVISIT:  this is where SRP kicks in, yes? */
+			MUSB_HST_MODE(pThis);	/* unnecessary */
+			power &= ~MGC_M_POWER_SUSPENDM;
+			musb_writeb(pBase, MGC_O_HDRC_POWER,
+				   power | MGC_M_POWER_RESUME);
+
+			/* should now be A_SUSPEND */
+			pThis->xceiv.state = OTG_STATE_A_HOST;
+			mod_timer(&pThis->Timer, jiffies +
+					msecs_to_jiffies(50));
+#endif
+		} else {
+#ifdef CONFIG_USB_GADGET_MUSB_HDRC
+			MUSB_DEV_MODE(pThis);	/* unnecessary */
+#endif
+			musb_g_resume(pThis);
+		}
+	}
+
+#ifdef CONFIG_USB_MUSB_HDRC_HCD
+	/* see manual for the order of the tests */
+	if (bIntrUSB & MGC_M_INTR_SESSREQ) {
+		DBG(1, "SESSION_REQUEST (%d)\n", pThis->xceiv.state);
+
+		/* IRQ arrives from ID pin sense or (later, if VBUS power
+		 * is removed) SRP.  responses are time critical:
+		 *  - turn on VBUS (with silicon-specific mechanism)
+		 *  - go through A_WAIT_VRISE
+		 *  - ... to A_WAIT_BCON.
+		 * a_wait_vrise_tmout triggers VBUS_ERROR transitions
+		 */
+		musb_writeb(pBase, MGC_O_HDRC_DEVCTL, MGC_M_DEVCTL_SESSION);
+		pThis->bEnd0Stage = MGC_END0_START;
+		pThis->xceiv.state = OTG_STATE_A_IDLE;
+		MUSB_HST_MODE(pThis);
+
+		handled = IRQ_HANDLED;
+
+#ifdef CONFIG_USB_MUSB_OTG
+		{
+		MGC_OtgMachineInputs Inputs;
+		memset(&Inputs, 0, sizeof(Inputs));
+		Inputs.bSession = TRUE;
+		Inputs.bConnectorId = FALSE;
+		Inputs.bReset = FALSE;
+		Inputs.bConnection = FALSE;
+		Inputs.bSuspend = FALSE;
+		MGC_OtgMachineInputsChanged(&(pThis->OtgMachine), &Inputs);
+		}
+#endif
+	}
+
+	if (bIntrUSB & MGC_M_INTR_VBUSERROR) {
+
+		// MGC_OtgMachineInputsChanged(otgm, &Inputs);
+		// ... may need to abort otg timer ...
+
+		DBG(1, "VBUS_ERROR (%02x)\n", devctl);
+
+		/* after hw goes to A_IDLE, try connecting again */
+		pThis->xceiv.state = OTG_STATE_A_IDLE;
+		musb_writeb(pBase, MGC_O_HDRC_DEVCTL, MGC_M_DEVCTL_SESSION);
+		return IRQ_HANDLED;
+	}
+
+	if (bIntrUSB & MGC_M_INTR_CONNECT) {
+		u8	speed = USB_SPEED_FULL;
+
+		handled = IRQ_HANDLED;
+
+		pThis->bEnd0Stage = MGC_END0_START;
+
+#ifdef CONFIG_USB_MUSB_OTG
+		/* flush endpoints when transitioning from Device Mode */
+		if (is_peripheral_active(pThis)) {
+			// REVISIT HNP; just force disconnect
+		}
+		pThis->bDelayPortPowerOff = FALSE;
+#endif
+
+		/* high vs full speed is just a guess until after reset */
+		if (devctl & MGC_M_DEVCTL_LSDEV)
+			speed = USB_SPEED_LOW;
+
+		pThis->bRootSpeed = speed;
+		MUSB_HST_MODE(pThis);
+
+		/* indicate new connection to OTG machine */
+		switch (pThis->xceiv.state) {
+		case OTG_STATE_B_WAIT_ACON:
+			pThis->xceiv.state = OTG_STATE_B_HOST;
+			break;
+		default:
+			DBG(2, "connect in state %d\n", pThis->xceiv.state);
+			/* FALLTHROUGH */
+		case OTG_STATE_A_WAIT_BCON:
+		case OTG_STATE_A_WAIT_VRISE:
+			pThis->xceiv.state = OTG_STATE_A_HOST;
+			break;
+		}
+		DBG(1, "CONNECT (host state %d)\n", pThis->xceiv.state);
+		otg_input_changed(pThis, devctl, FALSE, TRUE, FALSE);
+		MGC_VirtualHubPortConnected(&pThis->RootHub, 0, speed);
+	}
+#endif	/* CONFIG_USB_MUSB_HDRC_HCD */
+
+	/* saved one bit: bus reset and babble share the same bit;
+	 * If I am host is a babble! i must be the only one allowed
+	 * to reset the bus; when in otg mode it means that I have
+	 * to switch to device
+	 */
+	if (bIntrUSB & MGC_M_INTR_RESET) {
+		if (devctl & MGC_M_DEVCTL_HM) {
+			DBG(1, "BABBLE\n");
+
+			/* REVISIT it's unclear how to handle this.  Mentor's
+			 * code stopped the whole USB host, which is clearly
+			 * very wrong.  For now, just expect the hardware is
+			 * sane, so babbling devices also trigger a normal
+			 * endpoint i/o fault (with automatic recovery).
+			 * (A "babble" IRQ seems quite pointless...)
+			 */
+
+		} else {
+			DBG(1, "BUS RESET\n");
+
+			musb_g_reset(pThis);
+
+			/* reading state from Power register doesn't work */
+			otg_input_changed(pThis, devctl, TRUE, FALSE,
+						 (power & MGC_M_POWER_SUSPENDM)
+						 ? TRUE : FALSE);
+		}
+
+		handled = IRQ_HANDLED;
+	}
+
+	return handled;
+}
+
+/*
+ * Interrupt Service Routine to record USB "global" interrupts.
+ * Since these do not happen often and signify things of
+ * paramount importance, it seems OK to check them individually;
+ * the order of the tests is specified in the manual
+ *
+ * @param pThis instance pointer
+ * @param bIntrUSB register contents
+ * @param devctl
+ * @param power
+ */
+static irqreturn_t musb_stage2_irq(struct musb * pThis, u8 bIntrUSB,
+				    u8 devctl, u8 power)
+{
+	irqreturn_t handled = IRQ_NONE;
+
+#ifdef CONFIG_USB_MUSB_HDRC_HCD
+	/* FIXME peripherals can use SOF IRQs too */
+
+	u8 bEnd;
+	u16 wFrame;
+	void __iomem *pBase = pThis->pRegs;
+
+	if (bIntrUSB & MGC_M_INTR_SOF) {
+		struct musb_hw_ep	*ep;
+
+		DBG(6, "START_OF_FRAME\n");
+		handled = IRQ_HANDLED;
+
+		/* start any periodic Tx transfers waiting for current frame */
+		wFrame = musb_readw(pBase, MGC_O_HDRC_FRAME);
+		ep = pThis->aLocalEnd;
+		for (bEnd = 1; (bEnd < pThis->bEndCount)
+					&& (pThis->wEndMask >= (1 << bEnd));
+				bEnd++, ep++) {
+			// FIXME handle framecounter wraps (12 bits)
+			// eliminate duplicated StartUrb logic
+			if (ep->dwWaitFrame >= wFrame) {
+				ep->dwWaitFrame = 0;
+				printk("SOF --> periodic TX%s on %d\n",
+					ep->pDmaChannel ? " DMA" : "",
+					bEnd);
+				if (!ep->pDmaChannel)
+					MGC_HdrcStartTx(pThis, bEnd);
+				else
+					MGC_HdrcEnableTXDMA(pThis, bEnd);
+			}
+		}		/* end of for loop */
+	}
+#endif
+
+	if ((bIntrUSB & MGC_M_INTR_DISCONNECT) && !pThis->bIgnoreDisconnect) {
+		DBG(1, "DISCONNECT as %s, devctl %02x\n",
+				MUSB_MODE(pThis), devctl);
+		handled = IRQ_HANDLED;
+
+		/* need to check it against pThis, because devctl is going
+		 * to report ID low as soon as the device gets disconnected
+		 */
+		if (is_host_active(pThis))
+			musb_root_disconnect(pThis);
+		else
+			musb_g_disconnect(pThis);
+
+		/* REVISIT all OTG state machine transitions */
+		otg_input_changed_X(pThis, FALSE, FALSE);
+	}
+
+	if (bIntrUSB & MGC_M_INTR_SUSPEND) {
+		DBG(1, "SUSPEND, devctl %02x\n", devctl);
+		handled = IRQ_HANDLED;
+
+		/* peripheral suspend, may trigger HNP */
+		if (!(devctl & MGC_M_DEVCTL_HM)) {
+			musb_g_suspend(pThis);
+			otg_input_changed(pThis, devctl, FALSE, FALSE, TRUE);
+		}
+	}
+
+	return handled;
+}
+
+/*
+* Program the HDRC to start (enable interrupts, etc.).
+*/
+void musb_start(struct musb * pThis)
+{
+	void __iomem *pBase = pThis->pRegs;
+	u8 state;
+
+	DBG(2, "<==\n");
+
+	/* TODO: always set ISOUPDATE in POWER (periph mode) and leave it on! */
+
+	/*  Set INT enable registers, enable interrupts */
+	musb_writew(pBase, MGC_O_HDRC_INTRTXE, pThis->wEndMask);
+	musb_writew(pBase, MGC_O_HDRC_INTRRXE, pThis->wEndMask & 0xfffe);
+	musb_writeb(pBase, MGC_O_HDRC_INTRUSBE, 0xf7);
+
+	musb_platform_enable(pThis);
+
+	musb_writeb(pBase, MGC_O_HDRC_TESTMODE, 0);
+
+	/* enable high-speed/low-power and start session */
+	musb_writeb(pBase, MGC_O_HDRC_POWER,
+		   MGC_M_POWER_SOFTCONN | MGC_M_POWER_HSENAB);
+
+	switch (pThis->board_mode) {
+	case MUSB_HOST:
+	case MUSB_OTG:
+		musb_writeb(pBase, MGC_O_HDRC_DEVCTL, MGC_M_DEVCTL_SESSION);
+		break;
+	case MUSB_PERIPHERAL:
+		state = musb_readb(pBase, MGC_O_HDRC_DEVCTL);
+		musb_writeb(pBase, MGC_O_HDRC_DEVCTL,
+			   state & ~MGC_M_DEVCTL_SESSION);
+		break;
+	}
+
+	if (musb_in_tusb())
+		tusb_enable(pThis);
+}
+
+
+static void musb_generic_disable(struct musb *pThis)
+{
+	void	*__iomem pBase = pThis->pRegs;
+	u16	temp;
+
+	/* disable interrupts */
+	musb_writeb(pBase, MGC_O_HDRC_INTRUSBE, 0);
+	musb_writew(pBase, MGC_O_HDRC_INTRTX, 0);
+	musb_writew(pBase, MGC_O_HDRC_INTRRX, 0);
+
+	/* off */
+	musb_writeb(pBase, MGC_O_HDRC_DEVCTL, 0);
+
+	/*  flush pending interrupts */
+	temp = musb_readb(pBase, MGC_O_HDRC_INTRUSB);
+	temp = musb_readw(pBase, MGC_O_HDRC_INTRTX);
+	temp = musb_readw(pBase, MGC_O_HDRC_INTRRX);
+
+}
+
+/*
+ * Make the HDRC stop (disable interrupts, etc.);
+ * called with controller locked, irqs blocked
+ * acts as a NOP unless some role activated the hardware
+ */
+void musb_stop(struct musb * pThis)
+{
+	/* stop IRQs, timers, ... */
+	musb_platform_disable(pThis);
+	musb_generic_disable(pThis);
+	DBG(3, "HDRC disabled\n");
+
+#ifdef CONFIG_USB_MUSB_OTG
+	if (is_otg_enabled(pThis))
+		MGC_OtgMachineDestroy(&pThis->OtgMachine);
+#endif
+
+	/* FIXME
+	 *  - mark host and/or peripheral drivers unusable/inactive
+	 *  - disable DMA (and enable it in HdrcStart)
+	 *  - make sure we can musb_start() after musb_stop(); with
+	 *    OTG mode, gadget driver module rmmod/modprobe cycles that
+	 *  - ...
+	 */
+
+	/* flush endpoints */
+#ifdef CONFIG_USB_MUSB_HDRC_HCD
+	if (is_host_enabled(pThis)) {
+		u8 bEnd;
+
+		del_timer_sync(&pThis->Timer);
+		MGC_VirtualHubStop(&pThis->RootHub);
+
+		// FIXME just force root disconnect, before disable
+		// ... that will handle the OTG "rmmod gadget_driver"
+		// case more correctly, making the root hub vanish from
+		// userspace visibility ... may be awkward ...
+		for (bEnd = 0; bEnd < min(16, (int)pThis->bEndCount); bEnd++) {
+			MGC_HdrcStopEnd(pThis, bEnd);
+		}
+	}
+#endif
+}
+
+static void musb_shutdown(struct device *dev)
+{
+	struct musb	*musb = dev_get_drvdata(dev);
+	unsigned long	flags;
+
+	spin_lock_irqsave(&musb->Lock, flags);
+	musb_stop(musb);
+	MUSB_ERR_MODE(musb, MUSB_ERR_SHUTDOWN);
+	spin_unlock_irqrestore(&musb->Lock, flags);
+}
+
+
+#ifdef MUSB_C_DYNFIFO_DEF
+
+/*
+ * We don't currently use dynamic fifo setup capability to do anything
+ * more than selecting one of a bunch of predefined configurations.
+ */
+static ushort __initdata fifo_mode = 1/*2*/;
+
+/* "modprobe ... fifo_mode=1" etc */
+module_param (fifo_mode, ushort, 0);
+MODULE_PARM_DESC(fifo_mode, "initial endpoint configuration");
+
+
+#define DYN_FIFO_SIZE (1<<(MUSB_C_RAM_BITS+2))
+
+enum fifo_style { FIFO_RXTX, FIFO_TX, FIFO_RX } __attribute__ ((packed));
+enum buf_mode { BUF_SINGLE, BUF_DOUBLE } __attribute__ ((packed));
+
+struct fifo_cfg {
+	u8		hw_ep_num;
+	enum fifo_style	style;
+	enum buf_mode	mode;
+	u16		maxpacket;
+};
+
+/*
+ * tables defining fifo_mode values.  define more if you like.
+ */
+
+/* mode 0 - fits in 2KB */
+static struct fifo_cfg __initdata mode_0_cfg[] = {
+{ .hw_ep_num = 1, .style = FIFO_TX,   .maxpacket = 512, },
+{ .hw_ep_num = 2, .style = FIFO_RX,   .maxpacket = 512, },
+{ .hw_ep_num = 3, .style = FIFO_RXTX, .maxpacket = 256, },
+{ .hw_ep_num = 4, .style = FIFO_RXTX, .maxpacket = 256, },
+};
+
+/* mode 1 - fits in 4KB */
+static struct fifo_cfg __initdata mode_1_cfg[] = {
+{ .hw_ep_num = 1, .style = FIFO_TX,   .maxpacket = 512, .mode = BUF_DOUBLE, },
+{ .hw_ep_num = 2, .style = FIFO_RX,   .maxpacket = 512, .mode = BUF_DOUBLE, },
+{ .hw_ep_num = 3, .style = FIFO_RXTX, .maxpacket = 256, },
+{ .hw_ep_num = 4, .style = FIFO_RXTX, .maxpacket = 256, },
+};
+
+/* mode 2 - fits in 4KB */
+static struct fifo_cfg __initdata mode_2_cfg[] = {
+{ .hw_ep_num = 1, .style = FIFO_TX,   .maxpacket = 512, },
+{ .hw_ep_num = 1, .style = FIFO_RX,   .maxpacket = 512, },
+{ .hw_ep_num = 2, .style = FIFO_TX,   .maxpacket = 512, },
+{ .hw_ep_num = 2, .style = FIFO_RX,   .maxpacket = 512, },
+{ .hw_ep_num = 3, .style = FIFO_RXTX, .maxpacket = 256, },
+{ .hw_ep_num = 4, .style = FIFO_RXTX, .maxpacket = 256, },
+};
+
+/* mode 3 - fits in 4KB */
+static struct fifo_cfg __initdata mode_3_cfg[] = {
+{ .hw_ep_num = 1, .style = FIFO_TX,   .maxpacket = 512, .mode = BUF_DOUBLE, },
+{ .hw_ep_num = 1, .style = FIFO_RX,   .maxpacket = 512, .mode = BUF_DOUBLE, },
+{ .hw_ep_num = 2, .style = FIFO_TX,   .maxpacket = 512, },
+{ .hw_ep_num = 2, .style = FIFO_RX,   .maxpacket = 512, },
+{ .hw_ep_num = 3, .style = FIFO_RXTX, .maxpacket = 256, },
+{ .hw_ep_num = 4, .style = FIFO_RXTX, .maxpacket = 256, },
+};
+
+
+/*
+ * configure a fifo; for non-shared endpoints, this may be called
+ * once for a tx fifo and once for an rx fifo.
+ *
+ * returns negative errno or offset for next fifo.
+ */
+static int __init
+fifo_setup(struct musb *musb, struct musb_hw_ep  *hw_ep,
+		const struct fifo_cfg *cfg, u16 offset)
+{
+	void	*__iomem mbase = musb->pRegs;
+	int	size = 0;
+	u16	maxpacket = cfg->maxpacket;
+	u16	c_off = offset >> 3;
+	u8	c_size;
+
+	/* expect hw_ep has already been zero-initialized */
+
+	size = ffs(max(maxpacket, (u16) 8)) - 1;
+	maxpacket = 1 << size;
+
+	c_size = size - 3;
+	if (cfg->mode == BUF_DOUBLE) {
+		if ((offset + (maxpacket << 1)) > DYN_FIFO_SIZE)
+			return -EMSGSIZE;
+		c_size |= MGC_M_FIFOSZ_DPB;
+	} else {
+		if ((offset + maxpacket) > DYN_FIFO_SIZE)
+			return -EMSGSIZE;
+	}
+
+	/* configure the FIFO */
+	musb_writeb(mbase, MGC_O_HDRC_INDEX, hw_ep->bLocalEnd);
+
+	switch (cfg->style) {
+	case FIFO_TX:
+		musb_writeb(mbase, MGC_O_HDRC_TXFIFOSZ, c_size);
+		musb_writew(mbase, MGC_O_HDRC_TXFIFOADD, c_off);
+		hw_ep->tx_double_buffered = !!(c_size & MGC_M_FIFOSZ_DPB);
+		hw_ep->wMaxPacketSizeTx = maxpacket;
+#ifdef CONFIG_USB_MUSB_HDRC_HCD
+		/* reserve some OUT endpoint for bulk */
+		if (!musb->bulk_tx_end
+				&& hw_ep != musb->bulk_rx_end
+				&& maxpacket >= 512) {
+			musb->bulk_tx_end = hw_ep;
+			hw_ep->out_traffic_type = PIPE_BULK;;
+			hw_ep->bIsClaimed = 1;
+		}
+#endif
+		break;
+	case FIFO_RX:
+		musb_writeb(mbase, MGC_O_HDRC_RXFIFOSZ, c_size);
+		musb_writew(mbase, MGC_O_HDRC_RXFIFOADD, c_off);
+		hw_ep->rx_double_buffered = !!(c_size & MGC_M_FIFOSZ_DPB);
+		hw_ep->wMaxPacketSizeRx = maxpacket;
+#ifdef CONFIG_USB_MUSB_HDRC_HCD
+		/* reserve some IN endpoint for bulk */
+		if (!musb->bulk_rx_end
+				&& hw_ep != musb->bulk_tx_end
+				&& maxpacket >= 512) {
+			musb->bulk_rx_end = hw_ep;
+			hw_ep->in_traffic_type = PIPE_BULK;;
+			hw_ep->bIsClaimed = 1;
+		}
+#endif
+		break;
+	case FIFO_RXTX:
+		musb_writeb(mbase, MGC_O_HDRC_TXFIFOSZ, c_size);
+		musb_writew(mbase, MGC_O_HDRC_TXFIFOADD, c_off);
+		hw_ep->rx_double_buffered = !!(c_size & MGC_M_FIFOSZ_DPB);
+		hw_ep->wMaxPacketSizeRx = maxpacket;
+
+		musb_writeb(mbase, MGC_O_HDRC_RXFIFOSZ, c_size);
+		musb_writew(mbase, MGC_O_HDRC_RXFIFOADD, c_off);
+		hw_ep->tx_double_buffered = hw_ep->rx_double_buffered;
+		hw_ep->wMaxPacketSizeTx = maxpacket;
+
+		hw_ep->bIsSharedFifo = TRUE;
+#ifdef CONFIG_USB_MUSB_HDRC_HCD
+		/* reserve EP0 endpoint for control */
+		if (hw_ep->bLocalEnd == 0) {
+			hw_ep->bIsClaimed = 1;
+			hw_ep->in_traffic_type = PIPE_CONTROL;
+			hw_ep->out_traffic_type = hw_ep->in_traffic_type;
+		}
+#endif
+		break;
+	}
+
+	/* NOTE rx and tx endpoint irqs aren't managed separately,
+	 * which happens to be ok
+	 */
+	musb->wEndMask |= (1 << hw_ep->bLocalEnd);
+
+	return offset + (maxpacket << ((c_size & MGC_M_FIFOSZ_DPB) ? 1 : 0));
+}
+
+static struct fifo_cfg __initdata ep0_cfg = {
+	.style = FIFO_RXTX, .maxpacket = 64,
+};
+
+static int __init ep_config_from_table(struct musb *musb)
+{
+	const struct fifo_cfg	*cfg;
+	unsigned		n;
+	int			offset;
+	struct musb_hw_ep	*hw_ep = musb->aLocalEnd;
+
+	switch (fifo_mode) {
+	default:
+		fifo_mode = 0;
+		/* FALLTHROUGH */
+	case 0:
+		cfg = mode_0_cfg;
+		n = ARRAY_SIZE(mode_0_cfg);
+		break;
+	case 1:
+		cfg = mode_1_cfg;
+		n = ARRAY_SIZE(mode_1_cfg);
+		break;
+	case 2:
+		cfg = mode_2_cfg;
+		n = ARRAY_SIZE(mode_2_cfg);
+		break;
+	case 3:
+		cfg = mode_3_cfg;
+		n = ARRAY_SIZE(mode_3_cfg);
+		break;
+	}
+
+	printk(KERN_DEBUG "%s: setup fifo_mode %d\n",
+			musb_driver_name, fifo_mode);
+
+
+	offset = fifo_setup(musb, hw_ep, &ep0_cfg, 0);
+	// assert(offset > 0)
+
+	while (n--) {
+		u8	epn = cfg->hw_ep_num;
+
+		if (epn >= MUSB_C_NUM_EPS) {
+			pr_debug( "%s: invalid ep %d\n",
+					musb_driver_name, epn);
+			return -EINVAL;
+		}
+		offset = fifo_setup(musb, hw_ep + epn, cfg++, offset);
+		if (offset < 0) {
+			pr_debug( "%s: mem overrun, ep %d\n",
+					musb_driver_name, epn);
+			return -EINVAL;
+		}
+		epn++;
+		musb->bEndCount = max(epn, musb->bEndCount);
+	}
+
+#ifdef CONFIG_USB_MUSB_HDRC_HCD
+	/* for now, bulk uses two reserved endpoints */
+	if (!musb->bulk_rx_end ||!musb->bulk_tx_end) {
+		pr_debug( "%s: missing bulk TX or RX\n", musb_driver_name);
+		return -EINVAL;
+	}
+#endif
+
+	return 0;
+}
+
+#else
+
+/*
+ * ep_config_from_hw - when MUSB_C_DYNFIFO_DEF is false
+ * @param pThis the controller
+ */
+static int __init ep_config_from_hw(struct musb *pThis)
+{
+	u8 bEnd = 0, reg;
+	struct musb_hw_ep *pEnd;
+	void *pBase = pThis->pRegs;
+	/* how many of a given size/direction found: */
+	u8 b2kTxEndCount = 0;
+	u8 b2kRxEndCount = 0;
+	u8 b1kTxEndCount = 0;
+	u8 b1kRxEndCount = 0;
+	/* the smallest 2k or 1k ends in Tx or Rx direction: */
+	u8 b2kTxEnd = 0;
+	u8 b2kRxEnd = 0;
+	u8 b1kTxEnd = 0;
+	u8 b1kRxEnd = 0;
+	/* for tracking smallest: */
+	u16 w2kTxSize = 0;
+	u16 w1kTxSize = 0;
+	u16 w2kRxSize = 0;
+	u16 w1kRxSize = 0;
+
+	DBG(2, "<== static silicon ep config\n");
+
+	for (bEnd = 1; bEnd < MUSB_C_NUM_EPS; bEnd++) {
+		MGC_SelectEnd(pBase, bEnd);
+		pEnd = &(pThis->aLocalEnd[bEnd]);
+
+		/* read from core */
+		reg = MGC_ReadCsr8(pBase, MGC_O_HDRC_FIFOSIZE, bEnd);
+		if (!reg) {
+			/* 0's returned when no more endpoints */
+			break;
+		}
+
+		pEnd->wMaxPacketSizeTx = 1 << (reg & 0x0f);
+		/* shared TX/RX FIFO? */
+		if ((reg & 0xf0) == 0xf0) {
+			pEnd->wMaxPacketSizeRx = 1 << (reg & 0x0f);
+			pEnd->bIsSharedFifo = TRUE;
+		} else {
+			pEnd->wMaxPacketSizeRx = 1 << ((reg & 0xf0) >> 4);
+			pEnd->bIsSharedFifo = FALSE;
+		}
+
+		/* track certain sizes to try to reserve a bulk resource */
+		if (pEnd->wMaxPacketSizeTx >= 2048) {
+			b2kTxEndCount++;
+			if (!b2kTxEnd || (pEnd->wMaxPacketSizeTx < w2kTxSize)) {
+				b2kTxEnd = bEnd;
+				w2kTxSize = pEnd->wMaxPacketSizeTx;
+			}
+		}
+
+		if (pEnd->wMaxPacketSizeRx >= 2048) {
+			b2kRxEndCount++;
+			if (!b2kRxEnd || (pEnd->wMaxPacketSizeRx < w2kRxSize)) {
+				b2kRxEnd = bEnd;
+				w2kRxSize = pEnd->wMaxPacketSizeRx;
+			}
+		}
+
+		if (pEnd->wMaxPacketSizeTx >= 1024) {
+			b1kTxEndCount++;
+			if (!b1kTxEnd || (pEnd->wMaxPacketSizeTx < w1kTxSize)) {
+				b1kTxEnd = bEnd;
+				w1kTxSize = pEnd->wMaxPacketSizeTx;
+			}
+		}
+
+		if (pEnd->wMaxPacketSizeRx >= 1024) {
+			b1kRxEndCount++;
+			if (!b1kRxEnd || (pEnd->wMaxPacketSizeRx < w1kTxSize)) {
+				b1kRxEnd = bEnd;
+				w1kRxSize = pEnd->wMaxPacketSizeRx;
+			}
+		}
+
+		pThis->bEndCount++;
+		pThis->wEndMask |= (1 << bEnd);
+	}			/* init queues etc. etc. etc. */
+
+#ifdef CONFIG_USB_MUSB_HDRC_HCD
+	/* if possible, reserve the smallest 2k-capable Tx end for bulk */
+	if (b2kTxEnd && (b2kTxEndCount > 1)) {
+		pThis->bulk_tx_end = pThis->aLocalEnd + b2kTxEnd;
+		INFO("Reserved end %d for bulk double-buffered Tx\n", b2kTxEnd);
+	}
+	/* ...or try 1k */
+	else if (b1kTxEnd && (b1kTxEndCount > 1)) {
+		pThis->bulk_tx_end = pThis->aLocalEnd + b1kTxEnd;
+		INFO("Reserved end %d for bulk Tx\n", b1kTxEnd);
+	}
+
+	/* if possible, reserve the smallest 2k-capable Rx end for bulk */
+	if (b2kRxEnd && (b2kRxEndCount > 1)) {
+		pThis->bulk_rx_end = pThis->aLocalEnd + b2kRxEnd;
+		INFO("Reserved end %d for bulk double-buffered Rx\n", b2kRxEnd);
+	}
+	/* ...or try 1k */
+	else if (b1kRxEnd && (b1kRxEndCount > 1)) {
+		pThis->bulk_rx_end = pThis->aLocalEnd + b1kRxEnd;
+		INFO("Reserved end %d for bulk Rx\n", b1kRxEnd);
+	}
+#endif
+
+	return 0;
+}
+#endif
+
+enum { MUSB_CONTROLLER_MHDRC, MUSB_CONTROLLER_HDRC, };
+
+/* Initialize MUSB (M)HDRC part of the USB hardware subsystem;
+ * configure endpoints, or take their config from silicon
+ */
+static int __init musb_core_init(u16 wType, struct musb *pThis)
+{
+#ifdef MUSB_AHB_ID
+	u32 dwData;
+#endif
+	u8 reg;
+	char *type;
+	u16 wRelease, wRelMajor, wRelMinor;
+	char aInfo[78], aRevision[32], aDate[12];
+	void __iomem	*pBase = pThis->pRegs;
+	int		status = 0;
+	int		i;
+
+	/* log core options */
+	MGC_SelectEnd(pBase, 0);
+	reg = MGC_ReadCsr8(pBase, MGC_O_HDRC_CONFIGDATA, 0);
+
+	strcpy(aInfo, (reg & MGC_M_CONFIGDATA_UTMIDW) ? "UTMI-16" : "UTMI-8");
+	if (reg & MGC_M_CONFIGDATA_DYNFIFO) {
+		strcat(aInfo, ", dyn FIFOs");
+	}
+	if (reg & MGC_M_CONFIGDATA_MPRXE) {
+		pThis->bBulkCombine = TRUE;
+		strcat(aInfo, ", bulk combine");
+#ifndef C_MP_RX
+		dev_dbg(pThis->controller, "ignoring bulk combine feature\n");
+#endif
+	}
+	if (reg & MGC_M_CONFIGDATA_MPTXE) {
+		pThis->bBulkSplit = TRUE;
+		strcat(aInfo, ", bulk split");
+#ifndef C_MP_TX
+		dev_dbg(pThis->controller, "ignoring bulk split feature\n");
+#endif
+	}
+	if (reg & MGC_M_CONFIGDATA_HBRXE) {
+		strcat(aInfo, ", HB-ISO Rx");
+	}
+	if (reg & MGC_M_CONFIGDATA_HBTXE) {
+		strcat(aInfo, ", HB-ISO Tx");
+	}
+	if (reg & MGC_M_CONFIGDATA_SOFTCONE) {
+		strcat(aInfo, ", SoftConn");
+	}
+
+	printk(KERN_DEBUG "%s: ConfigData=0x%02x (%s)\n",
+			musb_driver_name, reg, aInfo);
+
+#ifdef MUSB_AHB_ID
+	dwData = musb_readl(pBase, 0x404);
+	sprintf(aDate, "%04d-%02x-%02x", (dwData & 0xffff),
+		(dwData >> 16) & 0xff, (dwData >> 24) & 0xff);
+	/* FIXME ID2 and ID3 are unused */
+	dwData = musb_readl(pBase, 0x408);
+	printk("ID2=%lx\n", (long unsigned)dwData);
+	dwData = musb_readl(pBase, 0x40c);
+	printk("ID3=%lx\n", (long unsigned)dwData);
+	reg = musb_readb(pBase, 0x400);
+	wType = ('M' == reg) ? MUSB_CONTROLLER_MHDRC : MUSB_CONTROLLER_HDRC;
+#else
+	aDate[0] = 0;
+#endif
+	if (MUSB_CONTROLLER_MHDRC == wType) {
+		pThis->bIsMultipoint = 1;
+		type = "M";
+	} else {
+		pThis->bIsMultipoint = 0;
+		type = "";
+	}
+
+	/* log release info */
+	wRelease = musb_readw(pBase, MGC_O_HDRC_HWVERS);
+	wRelMajor = (wRelease >> 10) & 0x1f;
+	wRelMinor = wRelease & 0x3ff;
+	snprintf(aRevision, 32, "%d.%d%s", wRelMajor,
+		 wRelMinor, (wRelease & 0x8000) ? "RC" : "");
+	printk(KERN_DEBUG "%s: %sHDRC RTL version %s %s\n",
+			musb_driver_name, type, aRevision, aDate);
+
+	/* configure ep0 */
+	pThis->aLocalEnd[0].wMaxPacketSizeTx = MGC_END0_FIFOSIZE;
+	pThis->aLocalEnd[0].wMaxPacketSizeRx = MGC_END0_FIFOSIZE;
+
+	/* discover endpoint configuration */
+	pThis->bEndCount = 1;
+	pThis->wEndMask = 1;
+
+#ifdef MUSB_C_DYNFIFO_DEF
+	if (!(reg & MGC_M_CONFIGDATA_DYNFIFO)) {
+		ERR("Dynamic FIFOs not detected; reconfigure software\n");
+		return -ENODEV;
+	} else
+		status = ep_config_from_table(pThis);
+#else
+	if (reg & MGC_M_CONFIGDATA_DYNFIFO) {
+		ERR("Dynamic FIFOs detected; reconfigure software\n");
+		return -ENODEV;
+	} else
+		status = ep_config_from_hw(pThis);
+#endif
+
+	if (status < 0)
+		return status;
+
+	/* finish init, and print endpoint config */
+	for (i = 0; i < pThis->bEndCount; i++) {
+		struct musb_hw_ep	*hw_ep = pThis->aLocalEnd + i;
+
+		hw_ep->fifo = MGC_FIFO_OFFSET(i) + pBase;
+		hw_ep->regs = MGC_END_OFFSET(i, 0) + pBase;
+
+		if (hw_ep->wMaxPacketSizeTx) {
+			printk(KERN_DEBUG
+				"%s: hw_ep %d%s, %smax %d\n",
+				musb_driver_name, i,
+				hw_ep->bIsSharedFifo ? "shared" : "tx",
+				hw_ep->tx_double_buffered
+					? "doublebuffer, " : "",
+				hw_ep->wMaxPacketSizeTx);
+		}
+		if (hw_ep->wMaxPacketSizeRx && !hw_ep->bIsSharedFifo) {
+			printk(KERN_DEBUG
+				"%s: hw_ep %d%s, %smax %d\n",
+				musb_driver_name, i,
+				"rx",
+				hw_ep->rx_double_buffered
+					? "doublebuffer, " : "",
+				hw_ep->wMaxPacketSizeRx);
+		}
+		if (!(hw_ep->wMaxPacketSizeTx || hw_ep->wMaxPacketSizeRx))
+			DBG(1, "hw_ep %d not configured\n", i);
+	}
+
+	return 0;
+}
+
+/* -------------------------------- MEMORY ----------------------------- */
+
+/* many common platforms have dma-coherent caches, which means that it's
+ * safe to use kmalloc() memory for all i/o buffers without using any
+ * cache flushing calls.  (unless you're trying to share cache lines
+ * between dma and non-dma activities, which is a slow idea in any case.)
+ */
+
+#if	defined(CONFIG_X86)
+#define USE_KMALLOC	1
+
+#elif	defined(CONFIG_PPC) && !defined(CONFIG_NOT_COHERENT_CACHE)
+#define USE_KMALLOC	1
+
+#elif	defined(CONFIG_MIPS) && !defined(CONFIG_DMA_NONCOHERENT)
+#define USE_KMALLOC	1
+
+/* NOTE: there are other cases, including an x86-64 one ...  */
+
+#endif
+
+#ifndef	USE_KMALLOC
+/* also use kmalloc when DMA is disabled! */
+#define USE_KMALLOC	!is_dma_capable()
+#endif
+
+/* Allocate a dma-coherent buffer */
+void *musb_alloc_buffer(struct musb *musb,
+			    size_t bytes, gfp_t gfp_flags, dma_addr_t * dma)
+{
+	void *addr;
+
+	if (USE_KMALLOC) {
+		addr = kmalloc(bytes, gfp_flags);
+		if (addr)
+			*dma = virt_to_phys(addr);
+	} else {
+		/* this allocates 2^X pages; the problem is that X is never
+		 * negative.  e.g. allocating 32 bytes wastes most of page...
+		 * the host side has some private dma pools to get rid of
+		 * most of that cost.
+		 * ... we explicitly force that allocation here to shut
+		 * up messages from the ARM allocator
+		 */
+#ifdef CONFIG_USB_GADGET_MUSB_HDRC
+		/* FIXME for dual-role configs, peripheral side should use
+		 * the same buffer pools the host side will, when it switches
+		 * over to the standard hcd framework ...
+		 */
+#endif
+		addr = dma_alloc_coherent(musb->controller,
+				(bytes < PAGE_SIZE) ? PAGE_SIZE : bytes,
+				dma, gfp_flags);
+	}
+	if (!addr)
+		*dma = DMA_ADDR_INVALID;
+	return addr;
+}
+
+/* Free memory previously allocated with AllocBufferMemory */
+void musb_free_buffer(struct musb *musb,
+			  size_t bytes, void *address, dma_addr_t dma)
+{
+	if (!USE_KMALLOC)
+		dma_free_coherent(musb->controller,
+				(bytes < PAGE_SIZE) ? PAGE_SIZE : bytes,
+				address, dma);
+	else
+		kfree(address);
+}
+
+/*************************************************************************
+ * Linux driver hooks
+**************************************************************************/
+
+#if 0
+
+static irqreturn_t generic_interrupt(int irq, void *__hci, struct pt_regs *r)
+{
+	unsigned long	flags;
+	irqreturn_t	retval = IRQ_NONE;
+	struct musb	*musb = __hci;
+
+	spin_lock_irqsave(&musb->Lock, flags);
+
+	musb->int_usb = musb_readb(musb->pRegs, MGC_O_HDRC_INTRUSB);
+	musb->int_tx = musb_readw(musb->pRegs, MGC_O_HDRC_INTRTX);
+	musb->int_rx = musb_readw(musb->pRegs, MGC_O_HDRC_INTRRX);
+	musb->int_regs = r;
+
+	if (musb->int_tx || musb->int_tx || musb->int_rx)
+		retval = musb_interrupt(musb);
+
+	spin_unlock_irqrestore(&musb->Lock, flags);
+
+	return retval;
+}
+
+#endif
+
+/*
+ * handle all the irqs defined by the HDRC core. for now we expect:  other
+ * irq sources (phy, dma, etc) will be handled first, musb->int_* values
+ * will be assigned, and the irq will already have been acked.
+ *
+ * called in irq context with spinlock held, irqs blocked
+ */
+irqreturn_t musb_interrupt(struct musb *musb)
+{
+	irqreturn_t	retval = IRQ_NONE;
+	u8		devctl, power;
+	int		ep_num;
+	u32		reg;
+
+	devctl = musb_readb(musb->pRegs, MGC_O_HDRC_DEVCTL);
+	power = musb_readb(musb->pRegs, MGC_O_HDRC_POWER);
+
+	DBG(3, "<== IRQ %s usb%04x tx%04x rx%04x\n",
+		(devctl & MGC_M_DEVCTL_HM) ? "host" : "peripheral",
+		musb->int_usb, musb->int_tx, musb->int_rx);
+
+	/* ignore requests when in error */
+	if (MUSB_IS_ERR(musb)) {
+		WARN("irq in error\n");
+		musb_platform_disable(musb);
+		return IRQ_NONE;
+	}
+
+	/* the core can interrupt us for multiple reasons; docs have
+	 * a generic interrupt flowchart to follow
+	 */
+	if (musb->int_usb)
+		retval |= musb_stage0_irq(musb, musb->int_usb,
+				devctl, power);
+
+	/* "stage 1" is handling endpoint irqs */
+
+	/* handle endpoint 0 first */
+	if (musb->int_tx & 1) {
+		if (devctl & MGC_M_DEVCTL_HM)
+			retval |= musb_h_ep0_irq(musb);
+		else
+			retval |= musb_g_ep0_irq(musb);
+	}
+
+	/* RX on endpoints 1-15 */
+	reg = musb->int_rx >> 1;
+	ep_num = 1;
+	while (reg) {
+		if (reg & 1) {
+			/* REVISIT just retval = ep->rx_irq(...) */
+			retval = IRQ_HANDLED;
+			if (devctl & MGC_M_DEVCTL_HM)
+				musb_host_rx(musb, ep_num);
+			else
+				musb_g_rx(musb, ep_num);
+		}
+
+		reg >>= 1;
+		ep_num++;
+	}
+
+	/* TX on endpoints 1-15 */
+	reg = musb->int_tx >> 1;
+	ep_num = 1;
+	while (reg) {
+		if (reg & 1) {
+			/* REVISIT just retval |= ep->tx_irq(...) */
+			retval = IRQ_HANDLED;
+			if (devctl & MGC_M_DEVCTL_HM)
+				musb_host_tx(musb, ep_num);
+			else
+				musb_g_tx(musb, ep_num);
+		}
+		reg >>= 1;
+		ep_num++;
+	}
+
+	/* finish handling "global" interrupts after handling fifos */
+	if (musb->int_usb)
+		retval |= musb_stage2_irq(musb,
+				musb->int_usb, devctl, power);
+
+	return retval;
+}
+
+
+#ifndef CONFIG_USB_INVENTRA_FIFO
+static int __initdata use_dma = is_dma_capable();
+
+/* "modprobe ... use_dma=0" etc */
+module_param(use_dma, bool, 0);
+MODULE_PARM_DESC(use_dma, "enable/disable use of DMA");
+
+/*
+ * DMA support
+ */
+
+static int musb_dma_completion(void *pPrivateData,
+		u8 bLocalEnd, u8 bTransmit)
+{
+	struct musb	*pThis = pPrivateData;
+	const void	__iomem *pBase = pThis->pRegs;
+	u8		devctl = musb_readb(pBase, MGC_O_HDRC_DEVCTL);
+
+	/* called with controller lock already held */
+
+	if (!bLocalEnd) {
+#ifndef CONFIG_USB_TI_CPPI_DMA
+		/* endpoint 0 */
+		if (devctl & MGC_M_DEVCTL_HM)
+			MGC_HdrcServiceDefaultEnd(pThis);
+		else
+			musb_g_ep0_irq(pThis);
+#endif
+	} else {
+		/* endpoints 1..15 */
+		if (bTransmit) {
+			if (devctl & MGC_M_DEVCTL_HM)
+				musb_host_tx(pThis, bLocalEnd);
+			else
+				musb_g_tx(pThis, bLocalEnd);
+		} else {
+			/* receive */
+			if (devctl & MGC_M_DEVCTL_HM)
+				musb_host_rx(pThis, bLocalEnd);
+			else
+				musb_g_rx(pThis, bLocalEnd);
+		}
+	}
+
+	return 0;
+}
+
+#else
+#define	musb_dma_completion	NULL
+#define use_dma			is_dma_capable()
+#endif
+
+/* --------------------------------------------------------------------------
+ * Init support
+ */
+
+static struct musb *__init allocate_instance(void __iomem *mbase)
+{
+	struct musb		*pThis;
+	struct musb_hw_ep	*ep;
+	int			epnum;
+
+	/* allocate */
+	pThis = kzalloc(sizeof *pThis, GFP_KERNEL);
+	if (!pThis)
+		return NULL;
+
+	pThis->pRegs = mbase;
+	pThis->ctrl_base = mbase;
+	pThis->nIrq = -ENODEV;
+	for (epnum = 0, ep = pThis->aLocalEnd;
+			epnum < MUSB_C_NUM_EPS;
+			epnum++, ep++) {
+
+		ep->musb = pThis;
+		ep->bLocalEnd = epnum;
+
+#ifdef CONFIG_USB_MUSB_HDRC_HCD
+		/* busctl regs too? */
+		INIT_LIST_HEAD(&(ep->urb_list));
+		init_timer(&pThis->RootHub.Timer);
+#endif
+	}
+	return pThis;
+}
+
+static void musb_free(struct musb *musb)
+{
+	/* this has multiple entry modes. it handles fault cleanup after
+	 * probe(), where things may be partially set up, as well as rmmod
+	 * cleanup after everything's been de-activated.
+	 */
+
+#ifdef CONFIG_USB_MUSB_HDRC_HCD
+	if (musb->pBus) {
+		struct usb_bus	*bus = musb->pBus;
+
+		MGC_VirtualHubStop(&musb->RootHub);
+		if (bus->root_hub) {
+			/* this also disconnects any active children */
+			usb_disconnect(&bus->root_hub);
+		}
+		usb_deregister_bus(bus);
+	}
+#endif
+#ifdef CONFIG_USB_GADGET_MUSB_HDRC
+	musb_gadget_cleanup(musb);
+#endif
+
+	if (musb->nIrq >= 0)
+		free_irq(musb->nIrq, musb);
+	if (is_dma_capable() && musb->pDmaController) {
+		musb->pDmaController->pfDmaStopController(
+					musb->pDmaController->pPrivateData);
+		dma_controller_factory.pfDestroyDmaController(
+					musb->pDmaController);
+	}
+	musb_platform_exit(musb);
+	if (musb->clock) {
+		clk_disable(musb->clock);
+		clk_put(musb->clock);
+	}
+
+	/* FIXME make sure all the different faces of this driver
+	 * coordinate their refcounting, so the same release() is
+	 * called when the host or gadget (or whatever) is the last
+	 * one released
+	 */
+	kfree(musb);
+}
+
+/*
+ * Perform generic per-controller initialization.
+ *
+ * @pDevice: the controller (already clocked, etc)
+ * @nIrq: irq
+ * @pRegs: virtual address of controller registers,
+ * 	not yet corrected for platform-specific offsets
+ */
+static int __init
+musb_init_controller(struct device *dev, int nIrq, void __iomem *ctrl)
+{
+	int			status;
+	struct musb		*pThis;
+	struct musb_hdrc_platform_data *plat = dev->platform_data;
+
+	/* The driver might handle more features than the board; OK.
+	 * Fail when the board needs a feature that's not enabled.
+	 */
+	if (!plat) {
+		dev_dbg(dev, "no platform_data?\n");
+		return -ENODEV;
+	}
+	switch (plat->mode) {
+	case MUSB_HOST:
+#ifdef CONFIG_USB_MUSB_HDRC_HCD
+		break;
+#else
+		goto bad_config;
+#endif
+	case MUSB_PERIPHERAL:
+#ifdef CONFIG_USB_GADGET_MUSB_HDRC
+		break;
+#else
+		goto bad_config;
+#endif
+	case MUSB_OTG:
+#ifdef CONFIG_USB_MUSB_OTG
+		break;
+#else
+	bad_config:
+#endif
+	default:
+		dev_dbg(dev, "incompatible Kconfig role setting\n");
+		return -EINVAL;
+	}
+
+	/* allocate */
+	pThis = allocate_instance(ctrl);
+	if (!pThis)
+		return -ENOMEM;
+
+	pThis->controller = dev;
+	dev_set_drvdata(dev, pThis);
+
+	spin_lock_init(&pThis->Lock);
+	pThis->board_mode = plat->mode;
+
+	/* assume vbus is off */
+
+	/* platform adjusts pThis->pRegs if needed,
+	 * and activates clocks
+	 */
+	status = musb_platform_init(pThis);
+	if (status < 0)
+		goto fail;
+
+	if (use_dma && dev->dma_mask) {
+		pThis->pDmaController =
+			dma_controller_factory.pfNewDmaController(
+					musb_dma_completion,
+					pThis, pThis->pRegs);
+		if (pThis->pDmaController)
+			pThis->pDmaController->pfDmaStartController(
+					pThis->pDmaController->pPrivateData);
+	}
+
+
+	/* ideally this would be abstracted in platform setup */
+	if (!is_dma_capable() || !pThis->pDmaController)
+		dev->dma_mask = NULL;
+
+	/* be sure interrupts are disabled before connecting ISR */
+	musb_platform_disable(pThis);
+
+	/* setup musb parts of the core (especially endpoints) */
+	status = musb_core_init(plat->multipoint
+			   ? MUSB_CONTROLLER_MHDRC
+			   : MUSB_CONTROLLER_HDRC, pThis);
+	if (status < 0)
+		goto fail;
+
+	/* attach to the IRQ */
+	if (request_irq (nIrq, pThis->isr, 0, dev->bus_id, pThis)) {
+		dev_err(dev, "request_irq %d failed!\n", nIrq);
+		status = -ENODEV;
+		goto fail;
+	}
+	pThis->nIrq = nIrq;
+
+	pr_info("%s: USB %s mode controller at %p using %s, IRQ %d\n",
+			musb_driver_name,
+			({char *s;
+			switch (pThis->board_mode) {
+			case MUSB_HOST:		s = "Host"; break;
+			case MUSB_PERIPHERAL:	s = "Peripheral"; break;
+			default:		s = "OTG"; break;
+			}; s; }),
+			ctrl,
+			(is_dma_capable() && pThis->pDmaController)
+				? "DMA" : "PIO",
+			pThis->nIrq);
+
+// FIXME:
+//  - convert to the HCD framework
+//  - if (board_mode == MUSB_OTG) do startup with peripheral
+//  - ... involves refcounting updates
+
+#ifdef CONFIG_USB_MUSB_HDRC_HCD
+	/* host side needs more setup, except for no-host modes */
+	if (pThis->board_mode != MUSB_PERIPHERAL) {
+		struct usb_bus	*bus;
+
+		/* allocate and register bus */
+		bus = usb_alloc_bus(&musb_host_bus_ops);
+		if (!bus) {
+			dev_dbg(dev, "usb_alloc_bus fail\n");
+			status = -ENOMEM;
+			goto fail;
+		}
+		pThis->pBus = bus;
+
+		init_timer(&pThis->Timer);
+		pThis->Timer.function = musb_timer_done;
+		pThis->Timer.data = (unsigned long) pThis;
+
+		/* register the bus */
+		bus->controller = dev;
+		bus->bus_name = dev->bus_id;
+		if (pThis->board_mode == MUSB_OTG)
+			bus->otg_port = 1;
+		pThis->pBus->hcpriv = (void *)pThis;
+		pThis->xceiv.host = bus;
+
+		/* FIXME root hub setup changed in 2.6.current kernels
+		 * even without involving the hcd framework ...
+		 */
+
+		/* FIXME:  hcd framework allocates the bus ...
+		 * else bus->release(bus) method looks necessary
+		 */
+
+		status = usb_register_bus(bus);
+		if (status < 0) {
+			kfree(bus);
+			pThis->pBus = NULL;
+			goto fail;
+		}
+
+		/* init virtual root hub */
+		if (!MGC_VirtualHubInit(&pThis->RootHub, pThis->pBus,
+					 pThis)) {
+			dev_dbg(dev, "Virtual Hub init failed\n");
+			status = -ENODEV;
+			goto fail;
+		}
+	}
+#endif				/* CONFIG_USB_MUSB_HDRC_HCD */
+
+#ifdef CONFIG_USB_MUSB_OTG
+	/* if present, this gets used even on non-otg boards */
+	MGC_OtgMachineInit(&pThis->OtgMachine, pThis);
+#endif
+
+	/* For the host-only role, we can activate right away.
+	 * Otherwise, wait till the gadget driver hooks up.
+	 *
+	 * REVISIT switch to compile-time is_role_host() etc
+	 * to get rid of #ifdeffery
+	 */
+	switch (pThis->board_mode) {
+#ifdef CONFIG_USB_MUSB_HDRC_HCD
+	case MUSB_HOST:
+		MUSB_HST_MODE(pThis);
+		pThis->xceiv.state = OTG_STATE_A_IDLE;
+		status = usb_register_root_hub(pThis->RootHub.pDevice, dev);
+
+#if 0
+		/* FIXME 2.6.10 doesn't budget root hub power correctly, AND
+		 * can only modify budgets after hub driver binds
+		 */
+		if (status == 0)
+			hub_set_power_budget(pThis->RootHub.pDevice,
+					     2 * (plat->power ? : 250));
+#endif
+
+		DBG(1, "%s mode, status %d, devctl %02x %c\n",
+			"HOST", status,
+			musb_readb(pThis->pRegs, MGC_O_HDRC_DEVCTL),
+			(musb_readb(pThis->pRegs, MGC_O_HDRC_DEVCTL)
+					& MGC_M_DEVCTL_BDEVICE
+				? 'B' : 'A'));
+		break;
+#endif
+#ifdef CONFIG_USB_GADGET_MUSB_HDRC
+	case MUSB_PERIPHERAL:
+		MUSB_DEV_MODE(pThis);
+		status = musb_gadget_setup(pThis);
+
+		DBG(1, "%s mode, status %d, dev%02x\n",
+			"PERIPHERAL", status,
+			musb_readb(pThis->pRegs, MGC_O_HDRC_DEVCTL));
+		break;
+#endif
+#ifdef CONFIG_USB_MUSB_OTG
+	case MUSB_OTG:
+		MUSB_OTG_MODE(pThis);
+		status = musb_gadget_setup(pThis);
+
+		DBG(1, "%s mode, status %d, dev%02x\n",
+			"OTG", status,
+			musb_readb(pThis->pRegs, MGC_O_HDRC_DEVCTL));
+#endif
+		break;
+	}
+
+	if (status == 0)
+		musb_debug_create("driver/musb_hdrc", pThis);
+	else {
+fail:
+		musb_free(pThis);
+	}
+	return status;
+}
+
+/*-------------------------------------------------------------------------*/
+
+/* all implementations (PCI bridge to FPGA, VLYNQ, etc) should just
+ * bridge to a platform device; this driver then suffices.
+ */
+
+static int __init musb_probe(struct device *dev)
+{
+	struct platform_device *pdev = to_platform_device(dev);
+	int irq = platform_get_irq(pdev, 0);
+	struct resource *iomem;
+	void __iomem *base;
+
+	iomem = platform_get_resource(pdev, IORESOURCE_MEM, 0);
+	if (!iomem || irq == 0)
+		return -ENODEV;
+
+	base = ioremap(iomem->start, iomem->end - iomem->start + 1);
+	if (!base) {
+		dev_err(dev, "ioremap failed\n");
+		return -ENOMEM;
+	}
+
+	return musb_init_controller(dev, irq, base);
+}
+
+static int __exit musb_remove(struct device *dev)
+{
+	struct musb	*musb = dev_get_drvdata(dev);
+
+	/* this gets called on rmmod.
+	 *  - Host mode: host may still be hactive
+	 *  - Peripheral mode: peripheral is deactivated (or never-activated)
+	 *  - OTG mode: both roles are deactivated (or never-activated)
+	 */
+	musb_shutdown(musb->controller);
+	musb_debug_delete("driver/musb_hdrc", musb);
+	musb_free(musb);
+
+	dev_set_drvdata(dev, NULL);
+	return 0;
+}
+
+#ifdef	CONFIG_PM
+
+/* REVISIT when power savings matter on DaVinci, look at turning
+ * off its phy clock during system suspend.
+ */
+
+static int musb_suspend(struct device *dev, u32 state, u32 level)
+{
+	struct musb	*musb = dev_get_drvdata(dev);
+	unsigned long	flags;
+
+	if (level != SUSPEND_POWER_DOWN || !musb->clock)
+		return 0;
+
+	spin_lock_irqsave(&musb->Lock, flags);
+
+	if (is_peripheral_active(musb)) {
+		/* FIXME force disconnect unless we know USB will wake
+		 * the system up quickly enough to respond ...
+		 */
+	} else if (is_host_active(musb)) {
+		/* we know all the children are suspended; sometimes
+		 * they will even be wakeup-enabled
+		 */
+	}
+
+	clk_disable(musb->clock);
+	spin_unlock_irqrestore(&musb->Lock, flags);
+	return 0;
+}
+
+static int musb_resume(struct device *dev, u32 level)
+{
+	struct musb	*musb = dev_get_drvdata(dev);
+	unsigned long	flags;
+
+	if (level != RESUME_POWER_ON || !musb->clock)
+		return 0;
+
+	spin_lock_irqsave(&musb->Lock, flags);
+	clk_enable(musb->clock);
+	/* for static cmos like DaVinci, register values were preserved
+	 * unless for some reason the whole soc powered down and we're
+	 * not treating that as a whole-system restart (e.g. swsusp)
+	 */
+	spin_unlock_irqrestore(&musb->Lock, flags);
+	return 0;
+}
+
+#else
+#define	musb_suspend	NULL
+#define	musb_resume	NULL
+#endif
+
+static struct device_driver musb_driver = {
+	.name		= (char *)musb_driver_name,
+	.bus		= &platform_bus_type,
+	.owner		= THIS_MODULE,
+	.probe		= musb_probe,
+	.remove		= __exit_p(musb_remove),
+	.shutdown	= musb_shutdown,
+	.suspend	= musb_suspend,
+	.resume		= musb_resume,
+};
+
+/*-------------------------------------------------------------------------*/
+
+static int __init musb_init(void)
+{
+#ifdef CONFIG_USB_MUSB_HDRC_HCD
+	if (usb_disabled())
+		return 0;
+#endif
+
+	pr_info("%s: version " MUSB_VERSION " "
+#ifdef CONFIG_USB_INVENTRA_FIFO
+	       "[pio]"
+#elif defined(CONFIG_USB_TI_CPPI_DMA)
+	       "[cppi-dma]"
+#elif defined(CONFIG_USB_INVENTRA_DMA)
+	       "[musb-dma]"
+#else
+	       "[?]"
+#endif
+	       " "
+#ifdef CONFIG_USB_MUSB_OTG
+		"[otg: peripheral+host]"
+#elif defined(CONFIG_USB_GADGET_MUSB_HDRC)
+		"[peripheral]"
+#elif defined(CONFIG_USB_MUSB_HDRC_HCD)
+		"[host]"
+#endif
+	       " [debug=%d]\n",
+	       musb_driver_name, MGC_GetDebugLevel());
+	return driver_register(&musb_driver);
+}
+
+/* make us init after usbcore and before usb
+ * gadget and host-side drivers start to register
+
+subsys_initcall(musb_init); */
+device_initcall(musb_init);
+
+static void __exit musb_cleanup(void)
+{
+	driver_unregister(&musb_driver);
+}
+module_exit(musb_cleanup);
Index: linux-2.6.10/drivers/usb/musb/tusb_6010.c
===================================================================
--- /dev/null
+++ linux-2.6.10/drivers/usb/musb/tusb_6010.c
@@ -0,0 +1,414 @@
+/*
+ * TUSB6010 USB 2.0 OTG Dual Role controller
+ *
+ * Copyright (C) 2006 Nokia Corporation
+ * Jarkko Nikula <jarkko.nikula@nokia.com>
+ * Tony Lindgren <tony@atomide.com>
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License version 2 as
+ * published by the Free Software Foundation.
+ *
+ * Notes:
+ * - Driver assumes that interface to external host (main CPU) is
+ *   configured for NOR FLASH interface instead of VLYNQ serial
+ *   interface.
+ */
+
+#include <linux/config.h>
+#include <linux/module.h>
+#include <linux/kernel.h>
+#include <linux/errno.h>
+#include <linux/init.h>
+#include <linux/usb.h>
+#include <linux/platform_device.h>
+
+#include "musbdefs.h"
+#include "tusb_6010.h"
+
+
+/*
+ * TUSB 6010 may use a parallel bus that doesn't support byte ops;
+ * so both loading and unloading FIFOs need explicit byte counts.
+ */
+
+void musb_write_fifo(struct musb_hw_ep *hw_ep, u16 len, const u8 *buf)
+{
+	void __iomem *ep_conf = hw_ep->regs;
+	void __iomem *fifo = hw_ep->fifo;
+	u8 epnum = hw_ep->bLocalEnd;
+	int i, remain;
+	u32 val;
+
+	u8 *bufp = buf;
+
+	prefetch(buf);
+
+	DBG(3, "%cX ep%d count %d bufp %p\n", 'T', epnum, len, bufp);
+
+	/* Direction and size of FIFO operation. See also comment
+	 * in tusb_6010.h for TUSB_EP_OUT_CONF */
+	if (epnum)
+		musb_writel(ep_conf, TUSB_EP_OUT_OFFSET,
+			    TUSB_EP_OUT_CONFIG_XFR_SIZE(len));
+	else
+		musb_writel(ep_conf, 0, TUSB_EP0_CONFIG_DIR_OUT |
+			    TUSB_EP0_CONFIG_XFR_SIZE(len));
+
+	/* Write full 32-bit blocks from buffer to FIFO */
+	for (i = 0; i < (len / 4); i++ ) {
+		val = *(u32 *)bufp;
+		musb_writel(fifo, 0, val);
+		bufp += 4;
+	}
+
+	remain = len - (i * 4);
+	if (remain) {
+		/* Write rest of 1-3 bytes from buffer into FIFO */
+		memcpy(&val, bufp, remain);
+		musb_writel(fifo, 0, val);
+	}
+}
+
+void musb_read_fifo(struct musb_hw_ep *hw_ep, u16 len, u8 *buf)
+{
+	void __iomem *ep_conf = hw_ep->regs;
+	void __iomem *fifo = hw_ep->fifo;
+	u8 epnum = hw_ep->bLocalEnd;
+	int i, remain;
+	u32 val;
+
+	DBG(3, "%cX ep%d count %d buf %p\n", 'T', epnum, len, buf);
+
+	/* Direction and size of FIFO operation. See also comment
+	 * in tusb_6010.h for TUSB_EP_IN_CONF */
+	if (epnum)
+		musb_writel(ep_conf, TUSB_EP_IN_OFFSET,
+			    TUSB_EP_IN_CONFIG_XFR_SIZE(len));
+	else
+		musb_writel(ep_conf, 0, TUSB_EP0_CONFIG_DIR_IN |
+			    TUSB_EP0_CONFIG_XFR_SIZE(len));
+
+	/* Read full 32-bit blocks from FIFO to buffer */
+	for (i = 0; i < (len / 4); i++ ) {
+		u32 val = musb_readl(fifo, 0);
+		*(u32 *)buf = val;
+
+		/* REVISIT: Remove this once things work reliably */
+		if (unlikely((u16)val == 0xdead)) {
+			printk(KERN_ERR "tusb: FIFO dead: "
+					  "ep%d count %d buf %p\n",
+						epnum, len, buf);
+		}
+
+		buf += 4;
+	}
+
+	remain = len - (i * 4);
+	if (remain) {
+		/* Read rest of 1-3 bytes from FIFO */
+		val = musb_readl(fifo, 0);
+		memcpy(buf, &val, remain);
+	}
+}
+
+irqreturn_t tusb_interrupt(int irq, void *__hci, struct pt_regs *r)
+{
+	struct musb	* musb = __hci;
+	void __iomem	* base = musb->ctrl_base;
+	void		__iomem *musb_base = musb->pRegs;
+	unsigned long	flags;
+	u32		dma_src, int_src, otg_stat, musb_src = 0;
+
+	spin_lock_irqsave(&musb->Lock, flags);
+
+	dma_src = musb_readl(base, TUSB_DMA_INT_SRC);
+	int_src = musb_readl(base, TUSB_INT_SRC);
+	otg_stat = musb_readl(base, TUSB_DEV_OTG_STAT);
+
+	musb->int_usb = 0;
+	musb->int_rx = 0;
+	musb->int_tx = 0;
+	musb->int_regs = r;
+
+	if (otg_stat & TUSB_DEV_OTG_STAT_ID_STATUS) {
+		/* ID pin is up. Either A-plug was removed or TUSB6010
+		 * is in peripheral mode */
+
+		/* Still in pheripheral mode? */
+		if ((int_src & TUSB_INT_SRC_ID_STATUS_CHNG)) {
+			DBG(3, "tusb: Status change\n");
+			//return IRQ_HANDLED;
+		}
+	}
+
+	/* Connect and disconnect */
+	if (int_src & TUSB_INT_SRC_USB_IP_CONN) {
+		DBG(3, "tusb: Connected\n");
+	}
+	else if (int_src & TUSB_INT_SRC_USB_IP_DISCON) {
+		DBG(3, "tusb: Disconnected\n");
+	}
+
+	/* VBUS state change */
+	if ((int_src & TUSB_INT_SRC_VBUS_SENSE_CHNG) ||
+	    (int_src & TUSB_INT_SRC_USB_IP_VBUS_ERR))
+	{
+		DBG(3, "tusb: VBUS changed. VBUS state %d\n",
+		    (otg_stat & TUSB_DEV_OTG_STAT_VBUS_SENSE) ? 1 : 0);
+		if (!(otg_stat & TUSB_DEV_OTG_STAT_VBUS_SENSE) &&
+		    !(otg_stat & TUSB_DEV_OTG_STAT_ID_STATUS)) {
+			/* VBUS went off and ID pin is down */
+			DBG(3, "tusb: No VBUS, starting session\n");
+			/* Start session again, VBUS will be enabled */
+			musb_writeb(musb_base, MGC_O_HDRC_DEVCTL,
+				MGC_M_DEVCTL_SESSION);
+		}
+	}
+
+	/* ID pin change */
+	if (int_src & TUSB_INT_SRC_ID_STATUS_CHNG) {
+		DBG(3, "tusb: ID pin changed. State is %d\n",
+		    (musb_readl(base, TUSB_DEV_OTG_STAT) &
+		     TUSB_DEV_OTG_STAT_ID_STATUS) ? 1 : 0);
+	}
+
+	/* OTG timer expiration */
+	if (int_src & TUSB_INT_SRC_OTG_TIMEOUT) {
+		DBG(3, "tusb: OTG timer expired\n");
+		musb_writel(base, TUSB_DEV_OTG_TIMER,
+			    musb_readl(base, TUSB_DEV_OTG_TIMER) |
+			    TUSB_DEV_OTG_TIMER_ENABLE);
+	}
+
+	/* EP interrupts. In OCP mode tusb6010 mirrors the MUSB * interrupts */
+	if (int_src & (TUSB_INT_SRC_USB_IP_TX | TUSB_INT_SRC_USB_IP_RX)) {
+		musb_src = musb_readl(base, TUSB_USBIP_INT_SRC);
+		musb_writel(base, TUSB_USBIP_INT_CLEAR, musb_src);
+		musb->int_rx = (((musb_src >> 16) & 0xffff) << 1);
+		musb->int_tx = (musb_src & 0xffff);
+	}
+	musb->int_usb = (int_src & 0xff);
+	if (musb->int_usb || musb->int_rx || musb->int_tx)
+		musb_interrupt(musb);
+
+	/* Acknowledge TUSB interrupts. Clear only non-reserved bits */
+	if (int_src & TUSB_INT_SRC_CLEAR_MASK) {
+		musb_writel(base, TUSB_INT_SRC_CLEAR,
+			    int_src & TUSB_INT_SRC_CLEAR_MASK);
+	}
+
+	spin_unlock_irqrestore(&musb->Lock, flags);
+
+	return IRQ_HANDLED;
+}
+
+
+/*
+ * Enables TUSB6010. Caller must take care of locking.
+ * REVISIT:
+ * - Check what is unnecessary in MGC_HdrcStart()
+ * - Interrupt should really be IRQT_FALLING level sensitive
+ */
+void tusb_enable(struct musb * musb)
+{
+	void __iomem * base = musb->ctrl_base;
+
+	/* Setup TUSB6010 main interrupt mask. Enable all interrupts except
+	 * reserved ones and VLYNQ invalid access */
+	musb_writel(base, TUSB_INT_MASK,
+		TUSB_INT_SRC_RESERVED_MASK |
+		TUSB_INT_SRC_INVALID_ACCESS_MASK(0xf));
+
+	/* Setup subsystem interrupt masks */
+	musb_writel(base, TUSB_USBIP_INT_MASK, 0);
+	musb_writel(base, TUSB_DMA_INT_MASK, 0);
+	musb_writel(base, TUSB_GPIO_INT_MASK, 0x1ff);
+
+	/* Clear all subsystem interrups */
+	musb_writel(base, TUSB_USBIP_INT_CLEAR, 0x7fffffff);
+	musb_writel(base, TUSB_DMA_INT_CLEAR, 0x7fffffff);
+	musb_writel(base, TUSB_GPIO_INT_CLEAR, 0x1ff);
+
+	/* Acknowledge pending interrupt(s) */
+	musb_writel(base, TUSB_INT_SRC_CLEAR,
+		    ~TUSB_INT_SRC_RESERVED_MASK);
+
+#if 0
+	/* Set OTG timer for about one second */
+	musb_writel(base, TUSB_DEV_OTG_TIMER,
+		TUSB_DEV_OTG_TIMER_ENABLE |
+		TUSB_DEV_OTG_TIMER_VAL(0x3c00000));
+#endif
+
+	/* Only 0 clock cycles for minimum interrupt de-assertion time and
+	 * interrupt polarity active low seems to work reliably here */
+	musb_writel(base, TUSB_INT_CTRL_CONF,
+		    TUSB_INT_CTRL_CONF_INT_RELCYC(0));
+
+	set_irq_type(musb->nIrq, __IRQT_LOWLVL);
+}
+
+/*
+ * Disables TUSB6010. Caller must take care of locking.
+ * REVISIT:
+ * - Check what is unnecessary in MGC_HdrcDisable()
+ * - Really disable the interrupts we want to disable
+ * - Deal with wake-up and gpio interrupts
+ */
+static void tusb_disable(struct musb * musb)
+{
+	set_irq_type(musb->nIrq, IRQT_NOEDGE);
+}
+
+/*
+ * Sets up TUSB6010 CPU interface specific signals and registers
+ * Note: Settings optimized for OMAP24xx
+ */
+static void tusb_setup_cpu_interface(struct musb * musb)
+{
+	void __iomem * base = musb->ctrl_base;
+
+	/* Disable GPIO[7:0] pullups (used as output DMA requests) */
+	musb_writel(base, TUSB_PULLUP_1_CTRL, 0x000000FF);
+	/* Disable all pullups on NOR IF, DMAREQ0 and DMAREQ1 */
+	musb_writel(base, TUSB_PULLUP_2_CTRL, 0x01FFFFFF);
+
+	/* Turn GPIO[5:0] to DMAREQ[5:0] signals */
+	musb_writel(base, TUSB_GPIO_CONF, TUSB_GPIO_CONF_DMAREQ(0x3f));
+
+	/* Burst size 16x16 bits, all six DMA requests enabled, DMA request
+	 * de-assertion time 2 system clocks */
+	musb_writel(base, TUSB_DMA_REQ_CONF,
+		TUSB_DMA_REQ_CONF_BURST_SIZE(2) |
+		TUSB_DMA_REQ_CONF_DMA_REQ_EN(0x2f) |
+		TUSB_DMA_REQ_CONF_DMA_REQ_ASSER(2));
+
+	/* Set 0 wait count for synchronous burst access */
+	musb_writel(base, TUSB_WAIT_COUNT, 0);
+}
+
+#define TUSB_REV_MAJOR(reg_val)		((reg_val >> 4) & 0xf)
+#define TUSB_REV_MINOR(reg_val)		(reg_val & 0xf)
+
+static void tusb_print_revision(struct musb * musb)
+{
+	void __iomem * base = musb->ctrl_base;
+
+	pr_info("tusb: Revisions: %s%i.%i %s%i.%i %s%i.%i %s%i.%i\n",
+		"prcm",
+		TUSB_REV_MAJOR(musb_readl(base, TUSB_PRCM_REV)),
+		TUSB_REV_MINOR(musb_readl(base, TUSB_PRCM_REV)),
+		"int",
+		TUSB_REV_MAJOR(musb_readl(base, TUSB_INT_CTRL_REV)),
+		TUSB_REV_MINOR(musb_readl(base, TUSB_INT_CTRL_REV)),
+		"gpio",
+		TUSB_REV_MAJOR(musb_readl(base, TUSB_GPIO_REV)),
+		TUSB_REV_MINOR(musb_readl(base, TUSB_GPIO_REV)),
+		"dma",
+		TUSB_REV_MAJOR(musb_readl(base, TUSB_DMA_CTRL_REV)),
+		TUSB_REV_MINOR(musb_readl(base, TUSB_DMA_CTRL_REV)));
+}
+
+static int tusb_start(struct musb * musb)
+{
+	void __iomem * base = musb->ctrl_base;
+	int ret;
+	unsigned long flags;
+
+	ret = tusb_power(1);
+	if (ret != 0) {
+		printk(KERN_ERR "tusb: Cannot enable TUSB6010\n");
+		goto err;
+	}
+
+	spin_lock_irqsave(&musb->Lock, flags);
+
+	if (musb_readl(base, TUSB_PROD_TEST_RESET) !=
+		TUSB_PROD_TEST_RESET_VAL) {
+		printk(KERN_ERR "tusb: Unable to detect TUSB6010\n");
+		goto err;
+	}
+
+	tusb_print_revision(musb);
+
+	/* The uint bit for "USB non-PDR interrupt enable" has to be 1 when
+	 * NOR FLASH interface is used */
+	musb_writel(base, TUSB_VLYNQ_CTRL, 8);
+
+	/* Select PHY free running 60MHz as a system clock */
+	musb_writel(base, TUSB_PRCM_CONF, TUSB_PRCM_CONF_SYS_CLKSEL(1));
+
+	/* VBus valid timer 1us, disable DFT/Debug and VLYNQ clocks for
+	 * power saving, enable VBus detect and session end comparators,
+	 * enable IDpullup */
+	musb_writel(base, TUSB_PRCM_MNGMT,
+		TUSB_PRCM_MNGMT_VBUS_VALID_TIMER(0xa) |
+		TUSB_PRCM_MNGMT_VBUS_VALID_FLT_EN |
+		TUSB_PRCM_MNGMT_DFT_CLK_DIS |
+		TUSB_PRCM_MNGMT_VLYNQ_CLK_DIS |
+		TUSB_PRCM_MNGMT_OTG_SESS_END_EN |
+		TUSB_PRCM_MNGMT_OTG_VBUS_DET_EN |
+		TUSB_PRCM_MNGMT_OTG_ID_PULLUP);
+
+	/* Workaround for enabling IDpullup, VBus detect and session end
+	 * comparators in case of silicon bug (which is to be fixed) where they
+	 * cannot be enabled in Device PRCM Management Register */
+	musb_writel(base, TUSB_PHY_OTG_CTRL_ENABLE,
+		musb_readl(base, TUSB_PHY_OTG_CTRL_ENABLE) |
+		TUSB_PHY_OTG_CTRL_WRPROTECT |
+		TUSB_PHY_OTG_CTRL_OTG_ID_PULLUP |
+		TUSB_PHY_OTG_CTRL_OTG_VBUS_DET_EN |
+		TUSB_PHY_OTG_CTRL_OTG_SESS_END_EN);
+	musb_writel(base, TUSB_PHY_OTG_CTRL,
+		musb_readl(base, TUSB_PHY_OTG_CTRL) |
+		TUSB_PHY_OTG_CTRL_WRPROTECT |
+		TUSB_PHY_OTG_CTRL_OTG_ID_PULLUP |
+		TUSB_PHY_OTG_CTRL_OTG_VBUS_DET_EN |
+		TUSB_PHY_OTG_CTRL_OTG_SESS_END_EN);
+
+	tusb_setup_cpu_interface(musb);
+
+	spin_unlock_irqrestore(&musb->Lock, flags);
+
+	return 0;
+
+err:
+	tusb_power(0);
+	return -ENODEV;
+}
+
+void tusb_stop(struct musb * musb)
+{
+	tusb_power(0);
+}
+
+void musb_platform_enable(struct musb *musb)
+{
+}
+
+void musb_platform_disable(struct musb *musb)
+{
+}
+
+
+int __init musb_platform_init(struct musb *musb)
+{
+	int		ret;
+
+
+	/* Offsets from base: VLYNQ at 0x000, MUSB regs at 0x400,
+	 * FIFOs at 0x600, TUSB at 0x800
+	 */
+	musb->pRegs += TUSB_BASE_OFFSET;
+
+	ret = tusb_start(musb);
+	if (ret) {
+		printk(KERN_ERR "Could not start tusb6010 (%d)\n",
+				ret);
+		return -ENODEV;
+	}
+	musb->isr = tusb_interrupt;
+	return ret;
+}
+
Index: linux-2.6.10/drivers/usb/musb/tusb_6010.h
===================================================================
--- /dev/null
+++ linux-2.6.10/drivers/usb/musb/tusb_6010.h
@@ -0,0 +1,352 @@
+/*
+ * Definitions for TUSB6010 USB 2.0 OTG Dual Role controller
+ *
+ * Copyright (C) 2006 Nokia Corporation
+ * Jarkko Nikula <jarkko.nikula@nokia.com>
+ * Tony Lindgren <tony@atomide.com>
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License version 2 as
+ * published by the Free Software Foundation.
+ */
+
+#ifndef __TUSB_6010_H__
+#define __TUSB_6010_H__
+
+#ifdef CONFIG_USB_TUSB_6010
+#define musb_in_tusb()			1
+struct musb;
+extern int tusb_power(int state);
+extern int tusb_start(struct musb * musb);
+extern void tusb_stop(struct musb * musb);
+extern void tusb_enable(struct musb * musb);
+extern void tusb_disable(struct musb * musb);
+extern irqreturn_t tusb_interrupt(int irq, void *ctx, struct pt_regs *r);
+
+#else
+#define musb_in_tusb()			0
+
+#define tusb_power(m)			(-ENODEV)
+#define tusb_start(m)			(-ENODEV)
+#define tusb_stop(m)			do { } while(0)
+#define tusb_enable(m)			do { } while(0)
+#define tusb_disable(m)			do { } while(0)
+#define tusb_interrupt			NULL
+#endif
+
+/* VLYNQ control register. 32-bit at offset 0x000 */
+#define TUSB_VLYNQ_CTRL			0x004
+
+/* Mentor Graphics OTG core registers. 8,- 16- and 32-bit at offset 0x400 */
+#define TUSB_BASE_OFFSET		0x400
+
+/* FIFO registers 32-bit at offset 0x600 */
+#define TUSB_FIFO_BASE			0x600
+
+/* Device System & Control registers. 32-bit at offset 0x800 */
+#define TUSB_SYS_REG_BASE		0x800
+#define TUSB_DEV_CONF			(TUSB_SYS_REG_BASE) + 0x000
+#define TUSB_PHY_OTG_CTRL_ENABLE	(TUSB_SYS_REG_BASE) + 0x004
+#define TUSB_PHY_OTG_CTRL		(TUSB_SYS_REG_BASE) + 0x008
+#define TUSB_DEV_OTG_STAT		(TUSB_SYS_REG_BASE) + 0x00c
+#define TUSB_DEV_OTG_TIMER		(TUSB_SYS_REG_BASE) + 0x010
+#define TUSB_PRCM_REV			(TUSB_SYS_REG_BASE) + 0x014
+#define TUSB_PRCM_CONF			(TUSB_SYS_REG_BASE) + 0x018
+#define TUSB_PRCM_MNGMT			(TUSB_SYS_REG_BASE) + 0x01c
+#define TUSB_PULLUP_1_CTRL		(TUSB_SYS_REG_BASE) + 0x030
+#define TUSB_PULLUP_2_CTRL		(TUSB_SYS_REG_BASE) + 0x034
+#define TUSB_INT_CTRL_REV		(TUSB_SYS_REG_BASE) + 0x038
+#define TUSB_INT_CTRL_CONF		(TUSB_SYS_REG_BASE) + 0x03c
+#define TUSB_USBIP_INT_SRC		(TUSB_SYS_REG_BASE) + 0x040
+#define TUSB_USBIP_INT_SET		(TUSB_SYS_REG_BASE) + 0x044
+#define TUSB_USBIP_INT_CLEAR		(TUSB_SYS_REG_BASE) + 0x048
+#define TUSB_USBIP_INT_MASK		(TUSB_SYS_REG_BASE) + 0x04c
+#define TUSB_DMA_INT_SRC		(TUSB_SYS_REG_BASE) + 0x050
+#define TUSB_DMA_INT_SET		(TUSB_SYS_REG_BASE) + 0x054
+#define TUSB_DMA_INT_CLEAR		(TUSB_SYS_REG_BASE) + 0x058
+#define TUSB_DMA_INT_MASK		(TUSB_SYS_REG_BASE) + 0x05c
+#define TUSB_GPIO_INT_SRC		(TUSB_SYS_REG_BASE) + 0x060
+#define TUSB_GPIO_INT_SET		(TUSB_SYS_REG_BASE) + 0x064
+#define TUSB_GPIO_INT_CLEAR		(TUSB_SYS_REG_BASE) + 0x068
+#define TUSB_GPIO_INT_MASK		(TUSB_SYS_REG_BASE) + 0x06c
+#define TUSB_INT_SRC			(TUSB_SYS_REG_BASE) + 0x070
+#define TUSB_INT_SRC_SET		(TUSB_SYS_REG_BASE) + 0x074
+#define TUSB_INT_SRC_CLEAR		(TUSB_SYS_REG_BASE) + 0x078
+#define TUSB_INT_MASK			(TUSB_SYS_REG_BASE) + 0x07c
+#define TUSB_GPIO_REV			(TUSB_SYS_REG_BASE) + 0x080
+#define TUSB_GPIO_CONF			(TUSB_SYS_REG_BASE) + 0x084
+#define TUSB_DMA_CTRL_REV		(TUSB_SYS_REG_BASE) + 0x100
+#define TUSB_DMA_REQ_CONF		(TUSB_SYS_REG_BASE) + 0x104
+#define TUSB_EP0_CONF			(TUSB_SYS_REG_BASE) + 0x108
+
+#define TUSB_EP_OUT_OFFSET		0x10c
+#define TUSB_EP_IN_OFFSET		0x14c
+#define TUSB_EP_MAX_FIFO_CONF_OFFSET	0x188
+
+/* Note that the documentation claims that EP_IN_CONF is at 0x10c and
+ * EP_OUT_CONF is at 0x14c. In reality EP_IN_CONF is at 0x14c and EP_OUT_CONF
+ * at 0x10c */
+#define TUSB_EP_IN_CONF(ep)		(TUSB_SYS_REG_BASE) + \
+					0x14c + (((ep - 1) & 0xf) << 2)
+#define TUSB_EP_OUT_CONF(ep)		(TUSB_SYS_REG_BASE) + \
+					0x10c + (((ep - 1) & 0xf) << 2)
+#define TUSB_EP_MAX_FIFO_CONF(ep)	(TUSB_SYS_REG_BASE) + \
+					0x188 + (((ep - 1) & 0xf) << 2)
+
+#define TUSB_WAIT_COUNT			(TUSB_SYS_REG_BASE) + 0x1c8
+#define TUSB_SCRATCH_PAD		(TUSB_SYS_REG_BASE) + 0x1c4
+#define TUSB_PROD_TEST_RESET		(TUSB_SYS_REG_BASE) + 0x1d8
+
+/* Device System & Control register bitfields */
+#define TUSB_DEV_CONF_USB_HOST_MODE		(1 << 16)
+#define TUSB_DEV_CONF_PROD_TEST_MODE		(1 << 15)
+#define TUSB_DEV_CONF_SOFT_ID			(1 << 1)
+#define TUSB_DEV_CONF_ID_SEL			(1 << 0)
+#define TUSB_PHY_OTG_CTRL_WRPROTECT		(0xa5 << 24)
+#define TUSB_PHY_OTG_CTRL_OTG_ID_PULLUP		(1 << 23)
+#define TUSB_PHY_OTG_CTRL_OTG_VBUS_DET_EN	(1 << 19)
+#define TUSB_PHY_OTG_CTRL_OTG_SESS_END_EN	(1 << 18)
+#define TUSB_PHY_OTG_CTRL_TESTM2		(1 << 17)
+#define TUSB_PHY_OTG_CTRL_TESTM1		(1 << 16)
+#define TUSB_PHY_OTG_CTRL_TESTM0		(1 << 15)
+#define TUSB_PHY_OTG_CTRL_TX_DATA2		(1 << 14)
+#define TUSB_PHY_OTG_CTRL_TX_GZ2		(1 << 13)
+#define TUSB_PHY_OTG_CTRL_TX_ENABLE2		(1 << 12)
+#define TUSB_PHY_OTG_CTRL_DM_PULLDOWN		(1 << 11)
+#define TUSB_PHY_OTG_CTRL_DP_PULLDOWN		(1 << 10)
+#define TUSB_PHY_OTG_CTRL_OSC_EN		(1 << 9)
+#define TUSB_PHY_OTG_CTRL_PHYREF_CLKSEL(v)	(((v) & 3) << 7)
+#define TUSB_PHY_OTG_CTRL_PD			(1 << 6)
+#define TUSB_PHY_OTG_CTRL_PLL_ON		(1 << 5)
+#define TUSB_PHY_OTG_CTRL_EXT_RPU		(1 << 4)
+#define TUSB_PHY_OTG_CTRL_PWR_GOOD		(1 << 3)
+#define TUSB_PHY_OTG_CTRL_RESET			(1 << 2)
+#define TUSB_PHY_OTG_CTRL_SUSPENDM		(1 << 1)
+#define TUSB_PHY_OTG_CTRL_CLK_MODE		(1 << 0)
+#define TUSB_DEV_OTG_STAT_VBUS_SENSE		(1 << 4)
+#define TUSB_DEV_OTG_STAT_ID_STATUS		(1 << 3)
+#define TUSB_DEV_OTG_STAT_LINE_STATE		(3 << 0)
+#define TUSB_DEV_OTG_STAT_DP_ENABLE		(1 << 1)
+#define TUSB_DEV_OTG_STAT_DM_ENABLE		(1 << 0)
+#define TUSB_DEV_OTG_TIMER_ENABLE		(1 << 31)
+#define TUSB_DEV_OTG_TIMER_VAL(v)		((v) & 0x07ffffff)
+#define TUSB_PRCM_CONF_SFW_CPEN			(1 << 24)
+#define TUSB_PRCM_CONF_SYS_CLKSEL(v)		(((v) & 3) << 16)
+#define TUSB_PRCM_MNGMT_SRP_FIX_TIMER(v)	(((v) & 0xf) << 25)
+#define TUSB_PRCM_MNGMT_SRP_FIX_EN		(1 << 24)
+#define TUSB_PRCM_MNGMT_VBUS_VALID_TIMER(v)	(((v) & 0xf) << 20)
+#define TUSB_PRCM_MNGMT_VBUS_VALID_FLT_EN	(1 << 19)
+#define TUSB_PRCM_MNGMT_DFT_CLK_DIS		(1 << 18)
+#define TUSB_PRCM_MNGMT_VLYNQ_CLK_DIS		(1 << 17)
+#define TUSB_PRCM_MNGMT_OTG_SESS_END_EN		(1 << 10)
+#define TUSB_PRCM_MNGMT_OTG_VBUS_DET_EN		(1 << 9)
+#define TUSB_PRCM_MNGMT_OTG_ID_PULLUP		(1 << 8)
+#define TUSB_PRCM_MNGMT_5V_CPEN			(1 << 2)
+#define TUSB_INT_CTRL_CONF_INT_RELCYC(v)	(((v) & 0x7) << 18)
+#define TUSB_INT_CTRL_CONF_INT_POLARITY		(1 << 17)
+#define TUSB_INT_CTRL_CONF_INT_MODE		(1 << 16)
+#define TUSB_INT_SRC_RESERVED_MASK		0x07fe2f00
+#define TUSB_INT_SRC_CLEAR_MASK			0xf801d0f7
+#define TUSB_INT_SRC_INVALID_ACCESS_MASK(v)	(((v) & 0x1f) << 27)
+#define TUSB_INT_SRC_TXRX_DMA_DONE		(1 << 24)
+#define TUSB_INT_SRC_USB_IP_CORE		(1 << 17)
+#define TUSB_INT_SRC_OTG_TIMEOUT		(1 << 16)
+#define TUSB_INT_SRC_VBUS_SENSE_CHNG		(1 << 15)
+#define TUSB_INT_SRC_ID_STATUS_CHNG		(1 << 14)
+#define TUSB_INT_SRC_DEV_WAKEUP			(1 << 13)
+#define TUSB_INT_SRC_DEV_READY			(1 << 12)
+#define TUSB_INT_SRC_USB_IP_TX			(1 << 9)
+#define TUSB_INT_SRC_USB_IP_RX			(1 << 8)
+#define TUSB_INT_SRC_USB_IP_VBUS_ERR		(1 << 7)
+#define TUSB_INT_SRC_USB_IP_VBUS_REQ		(1 << 6)
+#define TUSB_INT_SRC_USB_IP_DISCON		(1 << 5)
+#define TUSB_INT_SRC_USB_IP_CONN		(1 << 4)
+#define TUSB_INT_SRC_USB_IP_SOF			(1 << 3)
+#define TUSB_INT_SRC_USB_IP_RST_BABBLE		(1 << 2)
+#define TUSB_INT_SRC_USB_IP_RESUME		(1 << 1)
+#define TUSB_INT_SRC_USB_IP_SUSPEND		(1 << 0)
+#define TUSB_GPIO_CONF_DMAREQ(v)		(((v) & 0x3f) << 24)
+#define TUSB_DMA_REQ_CONF_BURST_SIZE(v)		(((v) & 3) << 26)
+#define TUSB_DMA_REQ_CONF_DMA_REQ_EN(v)		(((v) & 0x3f) << 20)
+#define TUSB_DMA_REQ_CONF_DMA_REQ_ASSER(v)	(((v) & 0xf) << 16)
+#define TUSB_EP0_CONFIG_SW_EN			(1 << 8)
+#define TUSB_EP0_CONFIG_DIR_OUT			(1 << 7)
+#define TUSB_EP0_CONFIG_DIR_IN			0
+#define TUSB_EP0_CONFIG_XFR_SIZE(v)		((v) & 0x7f)
+#define TUSB_EP_IN_CONFIG_SW_EN			(1 << 31)
+#define TUSB_EP_IN_CONFIG_XFR_SIZE(v)		((v) & 0x7fffffff)
+#define TUSB_EP_OUT_CONFIG_SW_EN		(1 << 31)
+#define TUSB_EP_OUT_CONFIG_XFR_SIZE(v)		((v) & 0x7fffffff)
+#define TUSB_PROD_TEST_RESET_VAL		0xa596
+#define TUSB_EP_FIFO(ep)			(TUSB_FIFO_BASE + (ep) * 0x20)
+
+/*----------------------------------------------------------------------------*/
+
+#ifdef CONFIG_USB_TUSB_6010
+
+/* configuration parameters specific to this silicon */
+
+/* Number of Tx endpoints. Legal values are 1 - 16 (this value includes EP0) */
+#define MUSB_C_NUM_EPT 5
+
+/* Number of Rx endpoints. Legal values are 1 - 16 (this value includes EP0) */
+#define MUSB_C_NUM_EPR 5
+
+/* Endpoint 1 to 15 direction types. C_EP1_DEF is defined if either Tx endpoint
+ * 1 or Rx endpoint 1 are used.
+ */
+#define MUSB_C_EP1_DEF
+
+/* C_EP1_TX_DEF is defined if Tx endpoint 1 is used */
+#define MUSB_C_EP1_TX_DEF
+
+/* C_EP1_RX_DEF is defined if Rx endpoint 1 is used */
+#define MUSB_C_EP1_RX_DEF
+
+/* C_EP1_TOR_DEF is defined if Tx endpoint 1 and Rx endpoint 1 share a FIFO */
+/* #define C_EP1_TOR_DEF */
+
+/* C_EP1_TAR_DEF is defined if both Tx endpoint 1 and Rx endpoint 1 are used
+ * and do not share a FIFO.
+ */
+#define MUSB_C_EP1_TAR_DEF
+
+/* Similarly for all other used endpoints */
+#define MUSB_C_EP2_DEF
+#define MUSB_C_EP2_TX_DEF
+#define MUSB_C_EP2_RX_DEF
+#define MUSB_C_EP2_TAR_DEF
+#define MUSB_C_EP3_DEF
+#define MUSB_C_EP3_TX_DEF
+#define MUSB_C_EP3_RX_DEF
+#define MUSB_C_EP3_TAR_DEF
+#define MUSB_C_EP4_DEF
+#define MUSB_C_EP4_TX_DEF
+#define MUSB_C_EP4_RX_DEF
+#define MUSB_C_EP4_TAR_DEF
+
+/* Endpoint 1 to 15 FIFO address bits. Legal values are 3 to 13 - corresponding
+ * to FIFO sizes of 8 to 8192 bytes. If an Tx endpoint shares a FIFO with an Rx
+ * endpoint then the Rx FIFO size must be the same as the Tx FIFO size. All
+ * endpoints 1 to 15 must be defined, unused endpoints should be set to 2.
+ */
+#define MUSB_C_EP1T_BITS 5
+#define MUSB_C_EP1R_BITS 5
+#define MUSB_C_EP2T_BITS 5
+#define MUSB_C_EP2R_BITS 5
+#define MUSB_C_EP3T_BITS 3
+#define MUSB_C_EP3R_BITS 3
+#define MUSB_C_EP4T_BITS 3
+#define MUSB_C_EP4R_BITS 3
+
+#define MUSB_C_EP5T_BITS 2
+#define MUSB_C_EP5R_BITS 2
+#define MUSB_C_EP6T_BITS 2
+#define MUSB_C_EP6R_BITS 2
+#define MUSB_C_EP7T_BITS 2
+#define MUSB_C_EP7R_BITS 2
+#define MUSB_C_EP8T_BITS 2
+#define MUSB_C_EP8R_BITS 2
+#define MUSB_C_EP9T_BITS 2
+#define MUSB_C_EP9R_BITS 2
+#define MUSB_C_EP10T_BITS 2
+#define MUSB_C_EP10R_BITS 2
+#define MUSB_C_EP11T_BITS 2
+#define MUSB_C_EP11R_BITS 2
+#define MUSB_C_EP12T_BITS 2
+#define MUSB_C_EP12R_BITS 2
+#define MUSB_C_EP13T_BITS 2
+#define MUSB_C_EP13R_BITS 2
+#define MUSB_C_EP14T_BITS 2
+#define MUSB_C_EP14R_BITS 2
+#define MUSB_C_EP15T_BITS 2
+#define MUSB_C_EP15R_BITS 2
+
+/* Define the following constant if the USB2.0 Transceiver Macrocell data width
+ * is 16-bits.
+ */
+/* #define C_UTM_16 */
+
+/* Define this constant if the CPU uses big-endian byte ordering. */
+/* #define C_BIGEND */
+
+/* Define the following constant if any Tx endpoint is required to support
+ * multiple bulk packets.
+ */
+/* #define C_MP_TX */
+
+/* Define the following constant if any Rx endpoint is required to support
+ * multiple bulk packets.
+ */
+/* #define C_MP_RX */
+
+/* Define the following constant if any Tx endpoint is required to support high
+ * bandwidth ISO.
+ */
+/* #define C_HB_TX */
+
+/* Define the following constant if any Rx endpoint is required to support high
+ * bandwidth ISO.
+ */
+/* #define C_HB_RX */
+
+/* Define the following constant if software connect/disconnect control is
+ * required.
+ */
+#define MUSB_C_SOFT_CON
+
+/* Define the following constant if Vendor Control Registers are required. */
+/* #define C_VEND_REG */
+
+/* Vendor control register widths. */
+#define MUSB_C_VCTL_BITS 4
+#define MUSB_C_VSTAT_BITS 8
+
+/* Define the following constant to include a DMA controller. */
+/* #define C_DMA */
+
+/* Define the following constant if 2 or more DMA channels are required. */
+/* #define C_DMA2 */
+
+/* Define the following constant if 3 or more DMA channels are required. */
+/* #define C_DMA3 */
+
+/* Define the following constant if 4 or more DMA channels are required. */
+/* #define C_DMA4 */
+
+/* Define the following constant if 5 or more DMA channels are required. */
+/* #define C_DMA5 */
+
+/* Define the following constant if 6 or more DMA channels are required. */
+/* #define C_DMA6 */
+
+/* Define the following constant if 7 or more DMA channels are required. */
+/* #define C_DMA7 */
+
+/* Define the following constant if 8 or more DMA channels are required. */
+/* #define C_DMA8 */
+
+/* Enable Dynamic FIFO Sizing */
+#define MUSB_C_DYNFIFO_DEF
+
+/* Derived constants. The following constants are derived from the previous
+ * configuration constants
+ */
+
+/* Total number of endpoints. Legal values are 2 - 16. This must be equal to
+ * the larger of C_NUM_EPT, C_NUM_EPR
+ */
+#define MUSB_C_NUM_EPS 5
+
+/* C_EPMAX_BITS is equal to the largest endpoint FIFO word address bits */
+#define MUSB_C_EPMAX_BITS 11
+
+/* C_RAM_BITS is the number of address bits required to address the RAM (32-bit
+ * addresses).  It is defined as log2 of the sum of 2** of all the endpoint FIFO
+ * dword address bits (rounded up).
+ */
+#define MUSB_C_RAM_BITS 10
+
+#endif /* CONFIG_USB_TUSB_6010 */
+
+#endif /* __TUSB_6010_H__ */
Index: linux-2.6.10/drivers/usb/musb/virthub.c
===================================================================
--- /dev/null
+++ linux-2.6.10/drivers/usb/musb/virthub.c
@@ -0,0 +1,800 @@
+/*****************************************************************
+ * Copyright 2005 Mentor Graphics Corporation
+ * Copyright (C) 2005-2006 by Texas Instruments
+ *
+ * This file is part of the Inventra Controller Driver for Linux.
+ *
+ * The Inventra Controller Driver for Linux is free software; you
+ * can redistribute it and/or modify it under the terms of the GNU
+ * General Public License version 2 as published by the Free Software
+ * Foundation.
+ *
+ * The Inventra Controller Driver for Linux is distributed in
+ * the hope that it will be useful, but WITHOUT ANY WARRANTY;
+ * without even the implied warranty of MERCHANTABILITY or
+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public
+ * License for more details.
+ *
+ * You should have received a copy of the GNU General Public License
+ * along with The Inventra Controller Driver for Linux ; if not,
+ * write to the Free Software Foundation, Inc., 59 Temple Place,
+ * Suite 330, Boston, MA  02111-1307  USA
+ *
+ * ANY DOWNLOAD, USE, REPRODUCTION, MODIFICATION OR DISTRIBUTION
+ * OF THIS DRIVER INDICATES YOUR COMPLETE AND UNCONDITIONAL ACCEPTANCE
+ * OF THOSE TERMS.THIS DRIVER IS PROVIDED "AS IS" AND MENTOR GRAPHICS
+ * MAKES NO WARRANTIES, EXPRESS OR IMPLIED, RELATED TO THIS DRIVER.
+ * MENTOR GRAPHICS SPECIFICALLY DISCLAIMS ALL IMPLIED WARRANTIES
+ * OF MERCHANTABILITY; FITNESS FOR A PARTICULAR PURPOSE AND
+ * NON-INFRINGEMENT.  MENTOR GRAPHICS DOES NOT PROVIDE SUPPORT
+ * SERVICES OR UPDATES FOR THIS DRIVER, EVEN IF YOU ARE A MENTOR
+ * GRAPHICS SUPPORT CUSTOMER.
+ ******************************************************************/
+
+#include <linux/config.h>
+#include <linux/module.h>
+#include <linux/kernel.h>
+#include <linux/sched.h>
+#include <linux/slab.h>
+#include <linux/errno.h>
+#include <linux/init.h>
+#include <linux/time.h>
+#include <linux/timer.h>
+
+#include <linux/usb.h>
+
+#include "../core/hcd.h"
+
+#include "musbdefs.h"
+#include "musb_host.h"
+
+/* FIXME most of this file will vanish when we convert this driver
+ * over to the standard 2.6 hcd framework
+ */
+
+/****************************** GLOBALS *********************************/
+
+/* device descriptor */
+static const u8 rh_dev_desc[] = {
+	USB_DT_DEVICE_SIZE,
+	USB_DT_DEVICE,
+	0x00, 0x02,		/* bcdUSB */
+	USB_CLASS_HUB,		/* bDeviceClass */
+	0,			/* bDeviceSubClass */
+	1,			/* bDeviceProtocol (single TT) */
+	64,			/* bMaxPacketSize0 */
+	0xd6, 0x4,		/* idVendor */
+	0, 0,			/* idProduct */
+	0, 0,			/* bcdDevice */
+	0,			/* iManufacturer */
+	0,			/* iProduct */
+	0,			/* iSerialNumber */
+	1			/* bNumConfigurations */
+};
+
+/* Configuration descriptor */
+static const u8 rh_config_desc[] = {
+	USB_DT_CONFIG_SIZE,
+	USB_DT_CONFIG,
+	USB_DT_CONFIG_SIZE + USB_DT_INTERFACE_SIZE + USB_DT_ENDPOINT_SIZE, 0,
+	0x01,			/* bNumInterfaces */
+	0x01,			/* bConfigurationValue */
+	0x00,			/* iConfiguration */
+	0xE0,			/* bmAttributes (self-powered, remote wake) */
+	0x00,			/* MaxPower */
+
+	/* interface */
+	USB_DT_INTERFACE_SIZE,
+	USB_DT_INTERFACE,
+	0x00,			/* bInterfaceNumber */
+	0x00,			/* bAlternateSetting */
+	0x01,			/* bNumEndpoints */
+	USB_CLASS_HUB,		/* bInterfaceClass */
+	0x00,			/* bInterfaceSubClass */
+	0x00,			/* bInterfaceProtocol */
+	0x00,			/* iInterface */
+
+	/* endpoint */
+	USB_DT_ENDPOINT_SIZE,
+	USB_DT_ENDPOINT,
+	USB_DIR_IN | 1,		/* bEndpointAddress: IN Endpoint 1 */
+	USB_ENDPOINT_XFER_INT,	/* bmAttributes: Interrupt */
+	(MGC_VIRTUALHUB_MAX_PORTS + 8) / 8, 0,	/* wMaxPacketSize */
+	12			/* bInterval: 256 ms */
+};
+
+/***************************** FUNCTIONS ********************************/
+
+/*
+ * assumes pHub to be locked!
+ */
+static void MGC_VirtualHubCheckIrq(struct virtual_root *pHub, struct urb *pUrb,
+				      int status)
+{
+	int nLength, nPort;
+	u8 bData, bBit;
+	u8 *pData;
+
+	/* how many bits are needed/possible */
+	nLength = min(pUrb->transfer_buffer_length * 8, 1 +
+			min((u8)MGC_VIRTUALHUB_MAX_PORTS, pHub->bPortCount));
+	bData = 0;
+	bBit = 1;
+	pData = (u8 *) pUrb->transfer_buffer;
+
+	/* hub status bit would indicate overcurrent or power lost */
+
+	/* count 1..N to accomodate hub status bit */
+	for (nPort = 1; nPort <= nLength; nPort++) {
+		if (pHub->aPortStatusChange[nPort - 1].wChange) {
+			bData |= 1 << bBit;
+		}
+		if (++bBit > 7) {
+			*pData++ = bData;
+			bData = bBit = 0;
+		}
+	}
+
+	if (bBit) {
+		*pData++ = bData;
+	}
+
+	pUrb->actual_length = (int)pData - (int)pUrb->transfer_buffer;
+	if (pUrb->actual_length && pUrb->complete) {
+		DBG(4, "completing hub interrupt URB\n");
+
+		/* REVISIT root hub completions (all of them!) ... they don't
+		 * handle usb_kill_urb() correctly, and have other issues.
+		 */
+		pUrb->status = status;
+		pUrb->hcpriv = NULL;
+
+		spin_unlock(&pHub->Lock);
+		pUrb->complete(pUrb, NULL);
+		spin_lock(&pHub->Lock);
+	}
+}
+
+/*
+ * Timer expiration function to complete the interrupt URB on changes
+ *
+ * REVISIT better to not use a timer, be purely irq-driven.
+ */
+static void rh_timer(unsigned long ptr)
+{
+	struct virtual_root	*pHub = (struct virtual_root *) ptr;
+	struct urb		*pUrb;
+	unsigned long		flags;
+
+	spin_lock_irqsave(&pHub->Lock, flags);
+	pUrb = pHub->pUrb;
+
+	if (pUrb && (pUrb->hcpriv == pHub)) {
+		u8 bPort;
+
+		for (bPort = 0; bPort < pHub->bPortCount; bPort++) {
+			if (pHub->aPortStatusChange[bPort].wChange) {
+				MGC_VirtualHubCheckIrq(pHub, pUrb, 0);
+				break;
+			}
+		}
+
+		/* re-activate timer only when the urb is still mine;
+		 * pUrb->hcpriv is set to NULL on port disconnect
+		 */
+		mod_timer(&pHub->Timer, jiffies
+				+ msecs_to_jiffies(pHub->wInterval));
+	} else {
+		DBG(3, "pUrb=%p, for me =%d\n", pUrb,
+			(pUrb) ? ((pUrb->hcpriv) ? 1 : 0) : -1);
+	}
+
+	spin_unlock_irqrestore(&pHub->Lock, flags);
+}
+
+/*
+ * Initialize the virtual hub.
+ * @param pHub
+ * @param pBus
+ * @param pPortServices
+ */
+u8 MGC_VirtualHubInit(struct virtual_root *pHub, struct usb_bus *pBus,
+		      struct musb *musb)
+{
+	/* allocate device */
+	pHub->pDevice = usb_alloc_dev(NULL, pBus, 0);
+	if (!pHub->pDevice) {
+		ERR("Cannot allocate root hub\n");
+		return FALSE;
+	}
+
+	pHub->pBus = pBus;
+	pHub->pDevice->speed = USB_SPEED_HIGH;
+
+	spin_lock_init(&pHub->Lock);
+	pHub->pUrb = NULL;
+	pHub->musb = musb;
+	pHub->bPortCount = 1;
+
+	// DONE WITH ALLOCATION: init_timer(&pHub->Timer);
+	pHub->Timer.function = rh_timer;
+	pHub->Timer.data = (unsigned long)pHub;
+
+	pHub->aPortStatusChange[0].wStatus = 0;
+	pHub->aPortStatusChange[0].wChange = 0;
+
+	return TRUE;
+}
+
+void MGC_VirtualHubStop(struct virtual_root *pHub)
+{
+	/* stop interrupt timer */
+	del_timer_sync(&pHub->Timer);
+}
+
+static inline void set_active(struct musb *musb)
+{
+	unsigned long flags;
+
+	spin_lock_irqsave(&musb->Lock, flags);
+	musb_start(musb);
+	spin_unlock_irqrestore(&musb->Lock, flags);
+}
+
+static void musb_port_suspend(struct musb *pThis, u8 bSuspend)
+{
+	u8 power;
+	unsigned long flags;
+	void __iomem *pBase = pThis->pRegs;
+
+	DBG(2, "<==\n");
+
+	spin_lock_irqsave(&pThis->Lock, flags);
+	if (!is_host_active(pThis))
+		goto done;
+
+	power = musb_readb(pBase, MGC_O_HDRC_POWER);
+
+	if (bSuspend) {
+		DBG(3, "Root port suspended\n");
+		musb_writeb(pBase, MGC_O_HDRC_POWER,
+				power | MGC_M_POWER_SUSPENDM);
+	} else if (power & MGC_M_POWER_SUSPENDM) {
+		DBG(3, "Root port resumed\n");
+		power &= ~(MGC_M_POWER_SUSPENDM | MGC_M_POWER_RESUME);
+		musb_writeb(pBase, MGC_O_HDRC_POWER,
+				power | MGC_M_POWER_RESUME);
+		/* FIXME don't call mdelay; usbcore should time this... */
+		mdelay(10);
+		musb_writeb(pBase, MGC_O_HDRC_POWER, power);
+	}
+
+done:
+	spin_unlock_irqrestore(&pThis->Lock, flags);
+}
+
+static void musb_port_reset_done(struct virtual_root *pHub, u8 bHubSpeed);
+
+static void musb_port_reset(struct musb *pThis, u8 bReset)
+{
+	u8 power;
+	unsigned long flags;
+	void __iomem *pBase = pThis->pRegs;
+
+#ifdef CONFIG_USB_MUSB_OTG
+	/* REVISIT this looks wrong for HNP */
+	u8 devctl = musb_readb(pBase, MGC_O_HDRC_DEVCTL);
+	if (pThis->bDelayPortPowerOff || !(devctl & MGC_M_DEVCTL_HM)) {
+//		return;
+		DBG(1, "what?\n");
+	}
+#endif
+
+	spin_lock_irqsave(&pThis->Lock, flags);
+	if (!is_host_active(pThis))
+		goto done;
+
+	/* NOTE:  caller guarantees it will turn off the reset when
+	 * the appropriate amount of time has passed
+	 */
+	power = musb_readb(pBase, MGC_O_HDRC_POWER);
+	if (bReset) {
+		pThis->bIgnoreDisconnect = TRUE;
+		power &= 0xf0;
+		musb_writeb(pBase, MGC_O_HDRC_POWER,
+				power | MGC_M_POWER_RESET);
+	} else {
+		DBG(3, "root port reset stopped\n");
+		musb_writeb(pBase, MGC_O_HDRC_POWER,
+				power & ~MGC_M_POWER_RESET);
+
+		pThis->bIgnoreDisconnect = FALSE;
+
+		/* check for high-speed and set in root device if so */
+		power = musb_readb(pBase, MGC_O_HDRC_POWER);
+		if (power & MGC_M_POWER_HSMODE) {
+			DBG(4, "high-speed device connected\n");
+			pThis->bRootSpeed = USB_SPEED_HIGH;
+		}
+
+		musb_port_reset_done(&(pThis->RootHub), pThis->bRootSpeed);
+	}
+
+done:
+	spin_unlock_irqrestore(&pThis->Lock, flags);
+}
+
+
+int MGC_VirtualHubSubmitUrb(struct virtual_root *pHub, struct urb *pUrb)
+{
+	u8 bRecip;		/* from standard request */
+	u8 bReqType;		/* from standard request */
+	u8 bType;		/* requested descriptor type */
+	u16 wValue;		/* from standard request */
+	u16 wIndex;		/* from standard request */
+	u16 wLength;		/* from standard request */
+	u8 bPort;
+	const struct usb_ctrlrequest *pRequest;
+	u16 wSize = 0xffff;
+	u8 *pData = (u8 *) pUrb->transfer_buffer;
+	unsigned int pipe = pUrb->pipe;
+	unsigned long	flags;
+
+	spin_lock_irqsave(&pHub->Lock, flags);
+	usb_get_urb(pUrb);
+
+	pUrb->hcpriv = pHub;
+	pUrb->status = -EINPROGRESS;
+	if (usb_pipeint(pipe)) {
+		DBG(6, "is periodic status/change event\n");
+
+		/* this is the one for periodic status/change events */
+		pHub->pUrb = pUrb;
+		pHub->wInterval = HZ/4;
+		spin_unlock_irqrestore(&pHub->Lock, flags);
+		return 0;
+	}
+
+	/* REVISIT  when we convert to using the usbcore root hub support,
+	 * most of this will vanish.  At that time, review the rest of this
+	 * code for correctness (against the usb 2.0 hub spec).
+	 */
+
+	/* handle hub requests/commands */
+	pRequest = (const struct usb_ctrlrequest *)pUrb->setup_packet;
+	bReqType = pRequest->bRequestType & USB_TYPE_MASK;
+	bRecip = pRequest->bRequestType & USB_RECIP_MASK;
+	wValue = le16_to_cpu(pRequest->wValue);
+	wIndex = le16_to_cpu(pRequest->wIndex);
+	wLength = le16_to_cpu(pRequest->wLength);
+
+	DBG(4, "ROOT SETUP req%02x.%02x v%04x i%04x l%d\n",
+		 pRequest->bRequestType, pRequest->bRequest,
+		 wValue, wIndex, wLength);
+
+	/* otg hosts mustn't change any root hub status until entering
+	 * OTG_STATE_A_IDLE or OTG_STATE_B_HOST.  strictly speaking we should
+	 * return errors for such requests, but let's avoid trouble...
+	 */
+	if (!is_host_active(pHub->musb)
+			&& !(pRequest->bRequestType & USB_DIR_IN)) {
+		wSize = 0;
+		goto fakeit;
+	}
+
+	switch (pRequest->bRequest) {
+	case USB_REQ_GET_STATUS:
+		DBG(5, "GET_STATUS(), bType=%02x, bRecip=%02x, wIndex=%04x\n",
+			bReqType, bRecip, wIndex);
+
+		if (USB_TYPE_STANDARD == bReqType) {
+			/* self-powered */
+			pData[0] = (USB_RECIP_DEVICE == bRecip) ? 1 : 0;
+			pData[1] = 0;
+			wSize = 2;
+		} else if (USB_TYPE_CLASS == bReqType) {
+			if ((USB_RECIP_OTHER == bRecip)
+					&& wIndex
+					&& (wIndex <= pHub->bPortCount)) {
+				MGC_HubPortStatusChange *p;
+
+				p = pHub->aPortStatusChange + (wIndex - 1);
+
+				/* this same mechanism is used by other hcds,
+				 * but we should probably also track how much
+				 * time has passed (in case something other
+				 * than khubd issues this GET_STATUS request)
+				 */
+				if (p->wStatus & USB_PORT_STAT_RESET) {
+					p->wStatus &= ~USB_PORT_STAT_RESET;
+					musb_port_reset(pHub->musb, FALSE);
+				}
+
+				/* REVISIT assumes 2-byte alignment */
+
+				/* port status/change report */
+				*(u16*)(pData + 0) = cpu_to_le16(p->wStatus);
+				*(u16*)(pData + 2) = cpu_to_le16(p->wChange);
+
+				/* reset change (TODO: lock) */
+				pHub->aPortStatusChange[wIndex - 1].wChange = 0;
+				wSize = 4;
+			} else {
+				/* hub status */
+				memset(pData, 0, 4);
+				wSize = 4;
+			}
+
+			DBG(5, "status %04x change %04x\n",
+					pHub->aPortStatusChange[0].wStatus,
+					pHub->aPortStatusChange[0].wChange);
+		}
+		break;
+
+	case USB_REQ_CLEAR_FEATURE:
+		bPort = (u8) (wIndex & 0xff) - 1;
+		if ((USB_TYPE_STANDARD == bReqType)
+			&& (USB_RECIP_ENDPOINT == bRecip)) {
+			wSize = 0;
+			DBG(5, "clear END POINT feature!\n");
+		} else if (USB_TYPE_CLASS == bReqType) {
+
+			if (USB_RECIP_OTHER == bRecip) {
+				bPort = (u8) (wIndex & 0xff) - 1;
+				switch (wValue) {
+				case USB_PORT_FEAT_CONNECTION:
+				case USB_PORT_FEAT_OVER_CURRENT:
+				case USB_PORT_FEAT_POWER:
+				case USB_PORT_FEAT_INDICATOR:
+					DBG(5, "clear feat 0x%02x port %d\n",
+						wValue, bPort);
+					wSize = 0;
+					break;
+				case USB_PORT_FEAT_ENABLE:
+					DBG(5, "enable port %d\n", bPort);
+					wSize = 0;
+					break;
+				case USB_PORT_FEAT_SUSPEND:
+					DBG(5, "suspend port %d\n", bPort);
+					musb_port_suspend(pHub->musb, FALSE);
+					wSize = 0;
+					break;
+				case USB_PORT_FEAT_RESET:
+					DBG(5, "reset port %d\n", bPort);
+					musb_port_reset(pHub->musb, FALSE);
+					wSize = 0;
+					break;
+
+					/* acknowledge changes: */
+				case USB_PORT_FEAT_C_CONNECTION:
+					DBG(5, "ack connect chg port %d\n",
+						bPort);
+					pHub->aPortStatusChange[bPort].wChange
+						&= ~USB_PORT_STAT_C_CONNECTION;
+					wSize = 0;
+					break;
+				case USB_PORT_FEAT_C_ENABLE:
+					DBG(5, "ack enable chg %d\n", bPort);
+					pHub->aPortStatusChange[bPort].wChange
+						&= ~USB_PORT_STAT_C_ENABLE;
+					wSize = 0;
+					break;
+				case USB_PORT_FEAT_C_SUSPEND:
+					DBG(5, "ack suspend chg %d\n", bPort);
+					pHub->aPortStatusChange[bPort].wChange
+						&= ~USB_PORT_STAT_C_SUSPEND;
+					wSize = 0;
+					break;
+				case USB_PORT_FEAT_C_RESET:
+					DBG(5, "ack reset chg %d\n", bPort);
+					pHub->aPortStatusChange[bPort].wChange
+						&= ~USB_PORT_STAT_C_RESET;
+					wSize = 0;
+					break;
+				case USB_PORT_FEAT_C_OVER_CURRENT:
+					DBG(5, "ack overcurrent chg port %d\n",
+						bPort);
+					/*
+					pHub->aPortStatusChange[bPort].wChange
+						&= ~USB_PORT_STAT_C_OVERCURRENT;
+					*/
+					wSize = 0;
+					break;
+
+				default:
+					DBG(1, "clear feature 0x%02x on "
+							"port=%d unknown\n",
+							wValue, bPort);
+					break;
+				}
+			} else {
+				DBG(5, "clear wValue=%d on port=%d\n", wValue,
+					bPort);
+				switch (wValue) {
+				case C_HUB_LOCAL_POWER:
+				case C_HUB_OVER_CURRENT:
+					wSize = 0;
+					break;
+				}
+			}
+		} else {
+			DBG(1, "CLR_FEAT type=0x%x, wValue=0x%x, wIndex=0x%x\n",
+				bReqType, wValue, (wIndex & 0xff));
+		}
+		break;
+
+	case USB_REQ_SET_FEATURE:
+		if ((USB_TYPE_CLASS == bReqType)
+				&& (USB_RECIP_OTHER == bRecip)) {
+			bPort = (u8) (wIndex & 0xff) - 1;
+			DBG(5, "SET_PORT_FEATURE(0x%02x), port %d\n", wValue,
+				bPort);
+			switch (wValue) {
+			case USB_PORT_FEAT_SUSPEND:
+				DBG(5, "suspend port %d\n", bPort);
+				musb_port_suspend(pHub->musb, TRUE);
+				pHub->aPortStatusChange[bPort].wStatus |=
+					USB_PORT_STAT_SUSPEND;
+				wSize = 0;
+				break;
+
+			case USB_PORT_FEAT_RESET:
+				DBG(5, "reset port %d\n", bPort);
+				pHub->aPortStatusChange[bPort].wStatus |=
+					USB_PORT_STAT_RESET;
+				pHub->aPortStatusChange[bPort].wStatus |=
+					USB_PORT_STAT_ENABLE;
+				pHub->aPortStatusChange[bPort].wChange |=
+					USB_PORT_STAT_C_RESET;
+				musb_port_reset(pHub->musb, TRUE);
+				wSize = 0;
+				break;
+
+			case USB_PORT_FEAT_POWER:
+				DBG(5, "power port %d\n", bPort);
+				/* REVISIT: doing it this way seems like an
+				 * unclean fit for the hub and bus models,
+				 * especially without deactivation...
+				 */
+				set_active(pHub->musb);
+				pHub->aPortStatusChange[bPort].wStatus |=
+					USB_PORT_STAT_POWER;
+				wSize = 0;
+				break;
+
+			case USB_PORT_FEAT_ENABLE:
+				DBG(5, "enable port %d\n", bPort);
+				pHub->aPortStatusChange[bPort].wStatus |=
+					USB_PORT_STAT_ENABLE;
+				wSize = 0;
+				break;
+			}
+		} else {
+			DBG(1, "SET_FEATURE(%04x), but feature unknown\n",
+				wValue);
+		}
+		break;
+
+	case USB_REQ_SET_ADDRESS:
+		DBG(5, "SET_ADDRESS(%x) \n", wValue & 0x7f);
+		wSize = 0;
+		break;
+
+	case USB_REQ_GET_DESCRIPTOR:
+		if (USB_TYPE_CLASS == bReqType) {
+			DBG(5, "GET_CLASS_DESCRIPTOR()\n");
+
+			pData[0] = 9;
+			pData[1] = 0x29;
+			pData[2] = pHub->bPortCount;
+			/* min characteristics */
+			/* individual port power switching (given
+			 * platform_data->set_vbus); no overcurrent
+			 */
+			pData[3] = 0x11;
+			pData[4] = 0;
+			/* REVISIT ... report platform_data->potpgt */
+			/* PowerOn2PowerGood */
+			pData[5] = 50;
+			/* no current */
+			pData[6] = 0;
+			/* removable ports */
+			pData[7] = 0;
+			/* reserved */
+			pData[8] = 0xff;
+			wSize = pData[0];
+		} else {
+			bType = (u8) (wValue >> 8);
+			DBG(5, "GET_DESCRIPTOR(%d)\n", bType);
+			switch (bType) {
+			case USB_DT_DEVICE:	/* 1 */
+				wSize = min(wLength, (u16) rh_dev_desc[0]);
+				memcpy(pData, rh_dev_desc, wSize);
+				break;
+			case USB_DT_CONFIG:	/* 2 */
+				wSize = min(wLength, (u16) rh_config_desc[2]);
+				memcpy(pData, rh_config_desc, wSize);
+				break;
+			}
+		}
+		break;
+
+	case USB_REQ_GET_CONFIGURATION:
+		DBG(5, "GET_CONFIG() => 1\n");
+		pData[0] = 1;
+		wSize = 1;
+		break;
+
+	case USB_REQ_SET_CONFIGURATION:
+		DBG(5, "SET_CONFIG(%04x)\n", wValue);
+		wSize = 0;
+		break;
+
+	}			/* END: switch on request type */
+
+fakeit:
+	if (0xffff == wSize) {
+		pUrb->status = -EPIPE;
+	} else {
+		pUrb->actual_length = wSize;
+		pUrb->status = 0;
+	}
+
+	spin_unlock_irqrestore(&pHub->Lock, flags);
+
+	DBG((pUrb->status < 0) ? 3 : 4,
+			"URB status %d, len %d\n",
+			pUrb->status, pUrb->actual_length);
+	pUrb->hcpriv = NULL;
+	pUrb->complete(pUrb, NULL);
+	usb_put_urb(pUrb);
+
+	return 0;
+}
+
+/* Implementation */
+int MGC_VirtualHubUnlinkUrb(struct virtual_root *pHub, struct urb *pUrb)
+{
+	unsigned long	flags;
+
+	spin_lock_irqsave(&pHub->Lock, flags);
+	if (pUrb && (pHub->pUrb == pUrb) && (pUrb->hcpriv == pHub)) {
+		/* NOTE:  this path should support usb_kill_urb()... */
+		pUrb->status = -ECONNRESET;
+		pUrb->hcpriv = NULL;
+		pHub->pUrb = NULL;
+		pUrb->complete(pUrb, NULL);
+		usb_put_urb(pUrb);
+	}
+
+	spin_unlock_irqrestore(&pHub->Lock, flags);
+	return 0;
+}
+
+/*
+ * assumes bPortIndex < MGC_VIRTUALHUB_MAX_PORTS
+ * AND pHub->Lock to be... locked :)
+ */
+static inline void musb_port_speed(struct virtual_root *pHub, u8 bSpeed)
+{
+	u16 wSpeedMask = 0;
+
+	switch (bSpeed) {
+	case USB_SPEED_LOW:
+		wSpeedMask = USB_PORT_STAT_LOW_SPEED;
+		break;
+	case USB_SPEED_HIGH:
+		wSpeedMask = USB_PORT_STAT_HIGH_SPEED;
+		break;
+	}
+
+	pHub->aPortStatusChange[0].wStatus &=
+		~(USB_PORT_STAT_LOW_SPEED | USB_PORT_STAT_HIGH_SPEED);
+	pHub->aPortStatusChange[0].wStatus |= wSpeedMask;
+}
+
+static void musb_port_reset_done(struct virtual_root *pHub, u8 bHubSpeed)
+{
+	DBG(4, "port %d reset complete\n", 0);
+	musb_port_speed(pHub, bHubSpeed);
+
+	pHub->aPortStatusChange[0].wStatus &=
+		~USB_PORT_STAT_RESET;
+	pHub->aPortStatusChange[0].wStatus |=
+		USB_PORT_STAT_ENABLE;
+	pHub->aPortStatusChange[0].wChange =
+		USB_PORT_STAT_C_RESET | USB_PORT_STAT_C_ENABLE;
+}
+
+/*
+ * Connect a port on the virtual hub.
+ *
+ * @param pHub the virtual hub
+ * @param bPortIndex the port that has been disconnected
+ * @param bSpeed the port speed
+ */
+void MGC_VirtualHubPortConnected(struct virtual_root *pHub, u8 bPortIndex,
+				 u8 bSpeed)
+{
+	struct urb *pUrb;
+
+	DBG(2, "<== port %d connected, core reports speed=%d\n", bPortIndex,
+		bSpeed);
+
+	if (bPortIndex < MGC_VIRTUALHUB_MAX_PORTS) {
+		unsigned long	flags;
+
+		spin_lock_irqsave(&pHub->Lock, flags);
+
+		pUrb = pHub->pUrb;
+		musb_port_speed(pHub, bSpeed);
+		pHub->aPortStatusChange[bPortIndex].wStatus |=
+			USB_PORT_STAT_CONNECTION;
+		pHub->aPortStatusChange[bPortIndex].wChange |=
+			USB_PORT_STAT_C_CONNECTION;
+
+		if (pUrb && ((!pUrb->hcpriv) || (pUrb->hcpriv == pHub))) {
+			pUrb->hcpriv = pHub;
+			mod_timer(&pHub->Timer, jiffies);
+		}
+
+		spin_unlock_irqrestore(&pHub->Lock, flags);
+	}
+}
+
+/* caller irqlocked musb */
+void musb_root_disconnect(struct musb *musb)
+{
+	unsigned long	flags;
+
+	spin_lock_irqsave(&musb->RootHub.Lock, flags);
+	musb->RootHub.aPortStatusChange[0].wStatus &=
+		~(USB_PORT_STAT_CONNECTION
+		| USB_PORT_STAT_ENABLE
+		| USB_PORT_STAT_LOW_SPEED
+		| USB_PORT_STAT_HIGH_SPEED
+		| USB_PORT_STAT_TEST
+		 );
+	musb->RootHub.aPortStatusChange[0].wChange |=
+		USB_PORT_STAT_C_CONNECTION;
+	mod_timer(&musb->RootHub.Timer, jiffies);
+	spin_unlock_irqrestore(&musb->RootHub.Lock, flags);
+
+	switch (musb->xceiv.state) {
+	case OTG_STATE_A_HOST:
+		musb->xceiv.state = OTG_STATE_A_WAIT_BCON;
+		break;
+	case OTG_STATE_A_WAIT_VFALL:
+		musb->xceiv.state = OTG_STATE_B_IDLE;
+		break;
+	default:
+		DBG(1, "host disconnect, state %d\n", musb->xceiv.state);
+	}
+
+	if (musb->pRootDevice)
+		usb_set_device_state(musb->pRootDevice,
+				USB_STATE_NOTATTACHED);
+	else
+		DBG(1, "disconnect with NO DEVICE CONNECTED?\n");
+	usb_put_dev(musb->pRootDevice);
+	musb->pRootDevice = NULL;
+}
+
+
+/* caller irqlocked musb */
+void MGC_VirtualHubPortResumed(struct virtual_root *pHub, u8 bPortIndex)
+{
+	unsigned long	flags;
+
+	DBG(3, "Resume port %d\n", bPortIndex);
+	if (bPortIndex >= MGC_VIRTUALHUB_MAX_PORTS) {
+		return;
+	}
+
+	spin_lock_irqsave(&pHub->Lock, flags);
+	pHub->aPortStatusChange[bPortIndex].wStatus &=
+		~USB_PORT_STAT_SUSPEND;
+	pHub->aPortStatusChange[bPortIndex].wChange |=
+		USB_PORT_STAT_C_SUSPEND;
+	spin_unlock_irqrestore(&pHub->Lock, flags);
+}
Index: linux-2.6.10/drivers/usb/musb/virthub.h
===================================================================
--- /dev/null
+++ linux-2.6.10/drivers/usb/musb/virthub.h
@@ -0,0 +1,126 @@
+/******************************************************************
+ * Copyright 2005 Mentor Graphics Corporation
+ * Copyright (C) 2005-2006 by Texas Instruments
+ *
+ * This file is part of the Inventra Controller Driver for Linux.
+ *
+ * The Inventra Controller Driver for Linux is free software; you
+ * can redistribute it and/or modify it under the terms of the GNU
+ * General Public License version 2 as published by the Free Software
+ * Foundation.
+ *
+ * The Inventra Controller Driver for Linux is distributed in
+ * the hope that it will be useful, but WITHOUT ANY WARRANTY;
+ * without even the implied warranty of MERCHANTABILITY or
+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public
+ * License for more details.
+ *
+ * You should have received a copy of the GNU General Public License
+ * along with The Inventra Controller Driver for Linux ; if not,
+ * write to the Free Software Foundation, Inc., 59 Temple Place,
+ * Suite 330, Boston, MA  02111-1307  USA
+ *
+ * ANY DOWNLOAD, USE, REPRODUCTION, MODIFICATION OR DISTRIBUTION
+ * OF THIS DRIVER INDICATES YOUR COMPLETE AND UNCONDITIONAL ACCEPTANCE
+ * OF THOSE TERMS.THIS DRIVER IS PROVIDED "AS IS" AND MENTOR GRAPHICS
+ * MAKES NO WARRANTIES, EXPRESS OR IMPLIED, RELATED TO THIS DRIVER.
+ * MENTOR GRAPHICS SPECIFICALLY DISCLAIMS ALL IMPLIED WARRANTIES
+ * OF MERCHANTABILITY; FITNESS FOR A PARTICULAR PURPOSE AND
+ * NON-INFRINGEMENT.  MENTOR GRAPHICS DOES NOT PROVIDE SUPPORT
+ * SERVICES OR UPDATES FOR THIS DRIVER, EVEN IF YOU ARE A MENTOR
+ * GRAPHICS SUPPORT CUSTOMER.
+ ******************************************************************/
+
+#ifndef __MUSB_LINUX_VIRTUALHUB_H__
+#define __MUSB_LINUX_VIRTUALHUB_H__
+
+#include <linux/spinlock.h>
+#include <linux/timer.h>
+
+struct urb;
+struct usb_bus;
+
+
+/** Maximum number of ports to accomodate */
+#define MGC_VIRTUALHUB_MAX_PORTS	1
+
+
+/**
+ * MGC_HubPortStatusChange.
+ * @field wStatus status
+ * @field wChange change
+ */
+typedef struct {
+	u16 wStatus;
+	u16 wChange;
+} MGC_HubPortStatusChange;
+
+struct virtual_root {
+	spinlock_t Lock;
+	struct usb_bus *pBus;
+	struct usb_device *pDevice;
+	void *pUrb;
+	struct musb	*musb;
+	struct timer_list Timer;
+	MGC_HubPortStatusChange aPortStatusChange[MGC_VIRTUALHUB_MAX_PORTS];
+	u8 bPortCount;
+	u16 wInterval;
+};
+
+
+/****************************** FUNCTIONS ********************************/
+
+/**
+ * Initialize a virtual hub.
+ * @param pHub hub struct pointer; struct filled on success
+ * @param pDevice pointer to bus
+ * @return TRUE on success
+ * @return FALSE on failure
+ */
+extern u8 MGC_VirtualHubInit(struct virtual_root * pHub,
+			     struct usb_bus *pBus,
+			     struct musb *musb);
+
+/**
+ * Stop a virtual hub
+ */
+extern void MGC_VirtualHubStop(struct virtual_root * pHub);
+
+/**
+ * Submit an URB to a virtual hub.
+ * @param pHub pointer to hub initialized by successful MGC_VirtualHubInit
+ * @param pUrb URB pointer
+ * @return Linux status code
+ * @see #MGC_VirtualHubInit
+ */
+extern int MGC_VirtualHubSubmitUrb(struct virtual_root * pHub, struct urb *pUrb);
+
+/**
+ * Unlink an URB from a virtual hub.
+ * @param pHub pointer to hub initialized by successful MGC_VirtualHubInit
+ * @param pUrb URB pointer
+ * @return Linux status code
+ * @see #MGC_VirtualHubInit
+ */
+extern int MGC_VirtualHubUnlinkUrb(struct virtual_root * pHub, struct urb *pUrb);
+
+/**
+ * A device has effectively been connected to a virtual hub port
+ * @param pHub pointer to hub initialized by successful MGC_VirtualHubInit
+ * @param bPortIndex 0-based index of port with connected device
+ * @param bSpeed device speed (0=>low, 1=>full, 2=>high)
+ * @see #MGC_VirtualHubInit
+ */
+extern void MGC_VirtualHubPortConnected(struct virtual_root * pHub,
+					u8 bPortIndex, u8 bSpeed);
+
+/**
+ * A device has effectively resumed a virtual hub port
+ * @param pHub pointer to hub initialized by successful MGC_VirtualHubInit
+ * @param bPortIndex 0-based index of port of resume
+ * @see #MGC_VirtualHubInit
+ */
+extern void MGC_VirtualHubPortResumed(struct virtual_root * pHub, u8 bPortIndex);
+
+
+#endif				/* multiple inclusion protection */
Index: linux-2.6.10/include/asm-arm/arch-davinci/hdrc_cnf.h
===================================================================
--- /dev/null
+++ linux-2.6.10/include/asm-arm/arch-davinci/hdrc_cnf.h
@@ -0,0 +1,165 @@
+/*
+ * USB High-Speed Multi-Point Dual-Role Controller Configuration
+ *
+ * Copyright Mentor Graphics Corporation and Licensors 2004
+ * Copyright (C) 2006 by Texas Instruments
+ *
+ * This file contains configuration constants for the (m)hdrc
+ * silicon as integrated into DaVinci CPUs.
+ */
+
+#ifndef	__ARCH_MUSB_HDRC_CNF
+#define	__ARCH_MUSB_HDRC_CNF
+
+/* ** Number of Tx endpoints ** */
+/* Legal values are 1 - 16 (this value includes EP0) */
+#define MUSB_C_NUM_EPT 5
+
+/* ** Number of Rx endpoints ** */
+/* Legal values are 1 - 16 (this value includes EP0) */
+#define MUSB_C_NUM_EPR 5
+
+/* ** Endpoint 1 to 15 direction types ** */
+/* C_EP1_DEF is defined if either Tx endpoint 1 or Rx endpoint 1 are used */
+#define MUSB_C_EP1_DEF
+
+/* C_EP1_TX_DEF is defined if Tx endpoint 1 is used */
+#define MUSB_C_EP1_TX_DEF
+
+/* C_EP1_RX_DEF is defined if Rx endpoint 1 is used */
+#define MUSB_C_EP1_RX_DEF
+
+/* C_EP1_TOR_DEF is defined if Tx endpoint 1 and Rx endpoint 1 share a FIFO */
+/*`define C_EP1_TOR_DEF */
+
+/* C_EP1_TAR_DEF is defined if both Tx endpoint 1 and Rx endpoint 1 are used */
+/* and do not share a FIFO */
+#define MUSB_C_EP1_TAR_DEF
+
+/* Similarly for all other used endpoints */
+#define MUSB_C_EP2_DEF
+#define MUSB_C_EP2_TX_DEF
+#define MUSB_C_EP2_RX_DEF
+#define MUSB_C_EP2_TAR_DEF
+#define MUSB_C_EP3_DEF
+#define MUSB_C_EP3_TX_DEF
+#define MUSB_C_EP3_RX_DEF
+#define MUSB_C_EP3_TAR_DEF
+#define MUSB_C_EP4_DEF
+#define MUSB_C_EP4_TX_DEF
+#define MUSB_C_EP4_RX_DEF
+#define MUSB_C_EP4_TAR_DEF
+
+/* ** Endpoint 1 to 15 FIFO address bits ** */
+/* Legal values are 3 to 13 - corresponding to FIFO sizes of 8 to 8192 bytes. */
+/* If an Tx endpoint shares a FIFO with an Rx endpoint then the Rx FIFO size */
+/* must be the same as the Tx FIFO size. */
+/* All endpoints 1 to 15 must be defined, unused endpoints should be set to 2. */
+#define MUSB_C_EP1T_BITS 5
+#define MUSB_C_EP1R_BITS 5
+#define MUSB_C_EP2T_BITS 5
+#define MUSB_C_EP2R_BITS 5
+#define MUSB_C_EP3T_BITS 3
+#define MUSB_C_EP3R_BITS 3
+#define MUSB_C_EP4T_BITS 3
+#define MUSB_C_EP4R_BITS 3
+
+#define MUSB_C_EP5T_BITS 2
+#define MUSB_C_EP5R_BITS 2
+#define MUSB_C_EP6T_BITS 2
+#define MUSB_C_EP6R_BITS 2
+#define MUSB_C_EP7T_BITS 2
+#define MUSB_C_EP7R_BITS 2
+#define MUSB_C_EP8T_BITS 2
+#define MUSB_C_EP8R_BITS 2
+#define MUSB_C_EP9T_BITS 2
+#define MUSB_C_EP9R_BITS 2
+#define MUSB_C_EP10T_BITS 2
+#define MUSB_C_EP10R_BITS 2
+#define MUSB_C_EP11T_BITS 2
+#define MUSB_C_EP11R_BITS 2
+#define MUSB_C_EP12T_BITS 2
+#define MUSB_C_EP12R_BITS 2
+#define MUSB_C_EP13T_BITS 2
+#define MUSB_C_EP13R_BITS 2
+#define MUSB_C_EP14T_BITS 2
+#define MUSB_C_EP14R_BITS 2
+#define MUSB_C_EP15T_BITS 2
+#define MUSB_C_EP15R_BITS 2
+
+/* Define the following constant if the USB2.0 Transceiver Macrocell data width is 16-bits. */
+/* `define C_UTM_16 */
+
+/* Define this constant if the CPU uses big-endian byte ordering. */
+/*`define C_BIGEND */
+
+/* Define the following constant if any Tx endpoint is required to support multiple bulk packets. */
+/* `define C_MP_TX */
+
+/* Define the following constant if any Rx endpoint is required to support multiple bulk packets. */
+/* `define C_MP_RX */
+
+/* Define the following constant if any Tx endpoint is required to support high bandwidth ISO. */
+/* `define C_HB_TX */
+
+/* Define the following constant if any Rx endpoint is required to support high bandwidth ISO. */
+/* `define C_HB_RX */
+
+/* Define the following constant if software connect/disconnect control is required. */
+#define MUSB_C_SOFT_CON
+
+/* Define the following constant if Vendor Control Registers are required. */
+/* `define C_VEND_REG */
+
+/* Vendor control register widths. */
+#define MUSB_C_VCTL_BITS 4
+#define MUSB_C_VSTAT_BITS 8
+
+
+/* Define the following constant to include a DMA controller. */
+/*`define C_DMA */
+
+/* Define the following constant if 2 or more DMA channels are required. */
+/*`define C_DMA2 */
+
+/* Define the following constant if 3 or more DMA channels are required. */
+/*`define C_DMA3 */
+
+/* Define the following constant if 4 or more DMA channels are required. */
+/*`define C_DMA4 */
+
+/* Define the following constant if 5 or more DMA channels are required. */
+/*`define C_DMA5 */
+
+/* Define the following constant if 6 or more DMA channels are required. */
+/*`define C_DMA6 */
+
+/* Define the following constant if 7 or more DMA channels are required. */
+/*`define C_DMA7 */
+
+/* Define the following constant if 8 or more DMA channels are required. */
+/*`define C_DMA8 */
+
+
+/* ** Enable Dynamic FIFO Sizing ** */
+#define MUSB_C_DYNFIFO_DEF
+
+/* ** Derived constants ** */
+/* The following constants are derived from the previous configuration constants */
+
+/* Total number of endpoints
+ * Legal values are 2 - 16
+ * This must be equal to the larger of C_NUM_EPT, C_NUM_EPR
+ */
+#define MUSB_C_NUM_EPS 5
+
+/* C_EPMAX_BITS is equal to the largest endpoint FIFO word address bits */
+#define MUSB_C_EPMAX_BITS 11
+
+/* C_RAM_BITS is the number of address bits required to address the RAM (32-bit
+ * addresses).  It is defined as log2 of the sum of 2** of all the endpoint FIFO
+ * dword address bits (rounded up).
+ */
+#define MUSB_C_RAM_BITS 10
+
+#endif	/* __ARCH_MUSB_HDRC_CNF */
Index: linux-2.6.10/include/linux/usb_musb.h
===================================================================
--- /dev/null
+++ linux-2.6.10/include/linux/usb_musb.h
@@ -0,0 +1,39 @@
+/*
+ * This is used to for host and peripheral modes of the driver for
+ * Inventra (Multidrop) Highspeed Dual-Role Controllers:  (M)HDRC.
+ *
+ * Board initialization should put one of these into dev->platform_data,
+ * probably on some platform_device named "musb_hdrc".  It encapsulates
+ * key configuration differences between boards.
+ */
+
+/* The USB role is defined by the connector used on the board, so long as
+ * standards are being followed.  (Developer boards sometimes won't.)
+ */
+enum musb_mode {
+	MUSB_UNDEFINED = 0,
+	MUSB_HOST,		/* A or Mini-A connector */
+	MUSB_PERIPHERAL,	/* B or Mini-B connector */
+	MUSB_OTG		/* Mini-AB connector */
+};
+
+struct musb_hdrc_platform_data {
+	/* MUSB_HOST, MUSB_PERIPHERAL, or MUSB_OTG */
+	u8		mode;
+
+	/* (HOST or OTG) switch VBUS on/off */
+	int		(*set_vbus)(struct device *dev, int is_on);
+
+	/* (HOST or OTG) mA/2 power supplied on (default = 8mA) */
+	u8		power;
+
+	/* (HOST or OTG) msec/2 after VBUS on till power good */
+	u8		potpgt;
+
+	/* TBD:  chip defaults should probably go someplace else,
+	 * e.g. number of tx/rx endpoints, etc
+	 */
+	unsigned	multipoint:1;
+
+};
+
Index: linux-2.6.10/mvl_patches/pro-0773.c
===================================================================
--- /dev/null
+++ linux-2.6.10/mvl_patches/pro-0773.c
@@ -0,0 +1,16 @@
+/*
+ * Author: MontaVista Software, Inc. <source@mvista.com>
+ *
+ * 2006 (c) MontaVista Software, Inc. This file is licensed under
+ * the terms of the GNU General Public License version 2. This program
+ * is licensed "as is" without any warranty of any kind, whether express
+ * or implied.
+ */
+#include <linux/init.h>
+#include <linux/mvl_patch.h>
+
+static __init int regpatch(void)
+{
+        return mvl_register_patch(773);
+}
+module_init(regpatch);
EOF

    rv=0
    cat /tmp/mvl_patch_$$
    if [ "$?" != "0" ]; then
	# Patch had a hard error, return 2
	rv=2
    elif grep '^Hunk' ${TMPFILE}; then
	rv=1
    fi

    rm -f ${TMPFILE}
    return $rv
}

function options() {
    echo "Options are:"
    echo "  --force-unsupported - Force the patch to be applied even if the"
    echo "      patch is out of order or the current kernel is unsupported."
    echo "      Use of this option is strongly discouraged."
    echo "  --force-apply-fuzz - If the patch has fuzz, go ahead and apply"
    echo "      it anyway.  This can occur if the patch is applied to an"
    echo "      unsupported kernel or applied out of order or if you have"
    echo "      made your own modifications to the kernel.  Use with"
    echo "      caution."
    echo "  --remove - Remove the patch"
}


function checkpatchnum() {
    local level;

    if [ ! -e ${1} ]; then
	echo "${1} does not exist, make sure you are in the kernel" 1>&2
	echo "base directory" 1>&2
	exit 1;
    fi

    # Extract the current patch number from the lsp info file.
    level=`grep '#define LSP_.*PATCH_LEVEL' ${1} | sed 's/^.*\"\\(.*\\)\".*\$/\\1/'`
    if [ "a$level" = "a" ]; then
	echo "No patch level defined in ${1}, are you sure this is" 1>&2
	echo "a valid MVL kernel LSP?" 1>&2
	exit 1;
    fi

    expr $level + 0 >/dev/null 2>&1
    isnum=$?

    # Check if the kernel is supported
    if [ "$level" = "unsupported" ]; then
	echo "**Current kernel is unsupported by MontaVista due to patches"
	echo "  begin applied out of order."
	if [ $force_unsupported == 't' ]; then
	    echo "  Application is forced, applying patch anyway"
	    unsupported=t
	    fix_patch_level=f
	else
	    echo "  Patch application aborted.  Use --force-unsupported to"
	    echo "  force the patch to be applied, but the kernel will not"
	    echo "  be supported by MontaVista."
	    exit 1;
	fi

    # Check the patch number from the lspinfo file to make sure it is
    # a valid number
    elif [ $isnum = 2 ]; then
	echo "**Patch level from ${1} was not a valid number, " 1>&2
	echo "  are you sure this is a valid MVL kernel LSP?" 1>&2
	exit 1;

    # Check that this is the right patch number to be applied.
    elif [ `expr $level $3` ${4} ${2} ]; then
	echo "**Application of this patch is out of order and will cause the"
	echo "  kernel to be unsupported by MontaVista."
	if [ $force_unsupported == 't' ]; then
	    echo "  application is forced, applying patch anyway"
	    unsupported=t
	else
	    echo "  Patch application aborted.  Please get all the patches in"
	    echo "  proper order from MontaVista Zone and apply them in order"
	    echo "  If you really want to apply this patch, use"
	    echo "  --force-unsupported to force the patch to be applied, but"
	    echo "  the kernel will not be supported by MontaVista."
	    exit 1;
	fi
    fi
}

#
# Update the patch level in the file.  Note that we use patch to do
# this.  Certain weak version control systems don't take kindly to
# arbitrary changes directly to files, but do have a special version
# of "patch" that understands this.
#
function setpatchnum() {
    sed "s/^#define LSP_\(.*\)PATCH_LEVEL[ \t*]\"[0-9]*\".*$/#define LSP_\1PATCH_LEVEL \"${2}\"/" <${1} >/tmp/$$.tmp1
    diff -u ${1} /tmp/$$.tmp1 >/tmp/$$.tmp2
    rm /tmp/$$.tmp1
    sed "s/^+++ \/tmp\/$$.tmp1/+++ include\/linux\/lsppatchlevel.h/" </tmp/$$.tmp2 >/tmp/$$.tmp1
    rm /tmp/$$.tmp2
    patch -p0 </tmp/$$.tmp1
    rm /tmp/$$.tmp1
}

force_unsupported=f
force_apply_fuzz=""
unsupported=f
fix_patch_level=t
reverse=f
common_patchnum_diff='+ 1'
common_patchnum=$PATCHNUM
patch_extraopts=''

# Extract command line parameters.
while [ $# -gt 0 ]; do
    if [ "a$1" == 'a--force-unsupported' ]; then
	force_unsupported=t
    elif [ "a$1" == 'a--force-apply-fuzz' ]; then
	force_apply_fuzz=y
    elif [ "a$1" == 'a--remove' ]; then
	reverse=t
	common_patchnum_diff=''
	common_patchnum=`expr $PATCHNUM - 1`
	patch_extraopts='--reverse'
    else
	echo "'$1' is an invalid command line parameter."
	options
	exit 1
    fi
    shift
done

echo "Checking patch level"
checkpatchnum ${LSPINFO} ${PATCHNUM} "${common_patchnum_diff}" "-ne"

if ! dopatch -p1 --dry-run --force $patch_extraopts; then
    if [ $? = 2 ]; then
	echo -n "**Patch had errors, application aborted" 1>&2
	exit 1;
    fi

    # Patch has warnings
    clean_apply=${force_apply_fuzz}
    while [ "a$clean_apply" != 'ay' -a "a$clean_apply" != 'an' ]; do
	echo -n "**Patch did not apply cleanly.  Do you still want to apply? (y/n) > "
	read clean_apply
	clean_apply=`echo "$clean_apply" | tr '[:upper:]' '[:lower:]'`
    done
    if [ $clean_apply = 'n' ]; then
	exit 1;
    fi
fi

dopatch -p1 --force $patch_extraopts

if [ $fix_patch_level = 't' ]; then 
    if [ $unsupported = 't' ]; then
	common_patchnum="unsupported"
    fi

    setpatchnum ${LSPINFO} ${common_patchnum}
fi

# Move the patch file into the mvl_patches directory if we are not reversing
if [ $reverse != 't' ]; then 
    if echo $0 | grep '/' >/dev/null; then
	# Filename is a path, either absolute or from the current directory.
	srcfile=$0
    else
	# Filename is from the path
	for i in `echo $PATH | tr ':;' '  '`; do
	    if [ -e ${i}/$0 ]; then
		srcfile=${i}/$0
	    fi
	done
    fi

    fname=`basename ${srcfile}`
    diff -uN mvl_patches/${fname} ${srcfile} | (cd mvl_patches; patch)
fi

