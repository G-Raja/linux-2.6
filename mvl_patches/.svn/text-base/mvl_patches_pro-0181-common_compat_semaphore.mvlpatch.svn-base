#! /usr/bin/env bash
# Patch: -common_compat_semaphore
# Date: Wed Dec 28 15:00:33 2005
# Source: MontaVista Software, Inc.
# MR: 13523 
# Type: Defect Fix
# Disposition: merged from Real-Time Preempt 
# Signed-off-by:  Daniel Walker <dwalker@mvista.com>
# Description:
# 
# 	This is the common part of the compat_semaphore code. It allows for the
# standard system semaphore to be exposed in PREEMPT_RT mode. This is used so that 
# some specific semaphore that aren't compatible with the new realtime semaphore
# can be allowed to use the old system semaphore. One example is all of XFS . 
# 

PATCHNUM=181
LSPINFO=include/linux/lsppatchlevel.h
TMPFILE=/tmp/mvl_patch_$$

function dopatch() {
    patch $* >${TMPFILE} 2>&1 <<"EOF"
Source: MontaVista Software, Inc.
MR: 13523 
Type: Defect Fix
Disposition: merged from Real-Time Preempt 
Signed-off-by:  Daniel Walker <dwalker@mvista.com>
Description:

	This is the common part of the compat_semaphore code. It allows for the
standard system semaphore to be exposed in PREEMPT_RT mode. This is used so that 
some specific semaphore that aren't compatible with the new realtime semaphore
can be allowed to use the old system semaphore. One example is all of XFS . 

Index: linux-2.6.10/arch/arm/Kconfig
===================================================================
--- linux-2.6.10.orig/arch/arm/Kconfig
+++ linux-2.6.10/arch/arm/Kconfig
@@ -529,12 +529,10 @@ source "lib/Kconfig.RT"
 
 config RWSEM_GENERIC_SPINLOCK
 	bool
-	depends on !PREEMPT_RT
 	default y
 
 config ASM_SEMAPHORES
 	bool
-	depends on !PREEMPT_RT
 	default y
 
 config RWSEM_XCHGADD_ALGORITHM
Index: linux-2.6.10/drivers/acpi/osl.c
===================================================================
--- linux-2.6.10.orig/drivers/acpi/osl.c
+++ linux-2.6.10/drivers/acpi/osl.c
@@ -828,16 +828,16 @@ acpi_os_create_semaphore(
 	u32		initial_units,
 	acpi_handle	*handle)
 {
-	struct semaphore	*sem = NULL;
+	struct compat_semaphore	*sem = NULL;
 
 	ACPI_FUNCTION_TRACE ("os_create_semaphore");
 
-	sem = acpi_os_allocate(sizeof(struct semaphore));
+	sem = acpi_os_allocate(sizeof(struct compat_semaphore));
 	if (!sem)
 		return_ACPI_STATUS (AE_NO_MEMORY);
-	memset(sem, 0, sizeof(struct semaphore));
+	memset(sem, 0, sizeof(struct compat_semaphore));
 
-	sema_init_nocheck(sem, initial_units);
+	sema_init(sem, initial_units);
 
 	*handle = (acpi_handle*)sem;
 
@@ -859,7 +859,7 @@ acpi_status
 acpi_os_delete_semaphore(
 	acpi_handle	handle)
 {
-	struct semaphore *sem = (struct semaphore*) handle;
+	struct compat_semaphore *sem = (struct compat_semaphore*) handle;
 
 	ACPI_FUNCTION_TRACE ("os_delete_semaphore");
 
@@ -891,7 +891,7 @@ acpi_os_wait_semaphore(
 	u16			timeout)
 {
 	acpi_status		status = AE_OK;
-	struct semaphore	*sem = (struct semaphore*)handle;
+	struct compat_semaphore	*sem = (struct compat_semaphore*)handle;
 	int			ret = 0;
 
 	ACPI_FUNCTION_TRACE ("os_wait_semaphore");
@@ -973,7 +973,7 @@ acpi_os_signal_semaphore(
     acpi_handle 	    handle,
     u32 		    units)
 {
-	struct semaphore *sem = (struct semaphore *) handle;
+	struct compat_semaphore *sem = (struct compat_semaphore *) handle;
 
 	ACPI_FUNCTION_TRACE ("os_signal_semaphore");
 
Index: linux-2.6.10/drivers/char/ipmi/ipmi_watchdog.c
===================================================================
--- linux-2.6.10.orig/drivers/char/ipmi/ipmi_watchdog.c
+++ linux-2.6.10/drivers/char/ipmi/ipmi_watchdog.c
@@ -386,7 +386,7 @@ void ipmi_delayed_shutdown(long delay, i
    when both messages are free. */
 static atomic_t heartbeat_tofree = ATOMIC_INIT(0);
 static DECLARE_MUTEX(heartbeat_lock);
-static DECLARE_MUTEX_NOCHECK(heartbeat_wait_lock);
+static DECLARE_MUTEX_LOCKED(heartbeat_wait_lock);
 static void heartbeat_free_smi(struct ipmi_smi_msg *msg)
 {
     if (atomic_dec_and_test(&heartbeat_tofree))
@@ -947,8 +947,6 @@ static int __init ipmi_wdog_init(void)
 	printk(KERN_INFO PFX "driver version "
 	       IPMI_WATCHDOG_VERSION "\n");
 
-	down(&heartbeat_wait_lock); // initialize as locked
-
 	if (strcmp(action, "reset") == 0) {
 		action_val = WDOG_TIMEOUT_RESET;
 	} else if (strcmp(action, "none") == 0) {
Index: linux-2.6.10/drivers/ieee1394/ieee1394_core.c
===================================================================
--- linux-2.6.10.orig/drivers/ieee1394/ieee1394_core.c
+++ linux-2.6.10/drivers/ieee1394/ieee1394_core.c
@@ -1003,7 +1003,7 @@ void abort_timedouts(unsigned long __opa
 static int khpsbpkt_pid = -1, khpsbpkt_kill;
 static DECLARE_COMPLETION(khpsbpkt_complete);
 struct sk_buff_head hpsbpkt_queue;
-static DECLARE_MUTEX_NOCHECK(khpsbpkt_sig);
+static DECLARE_MUTEX_LOCKED(khpsbpkt_sig);
 
 
 static void queue_packet_complete(struct hpsb_packet *packet)
@@ -1059,8 +1059,6 @@ static int __init ieee1394_init(void)
 {
 	int i, ret;
 
-	down(&khpsbpkt_sig); // initialize as locked
-
 	skb_queue_head_init(&hpsbpkt_queue);
 
 	/* non-fatal error */
Index: linux-2.6.10/drivers/ieee1394/ieee1394_types.h
===================================================================
--- linux-2.6.10.orig/drivers/ieee1394/ieee1394_types.h
+++ linux-2.6.10/drivers/ieee1394/ieee1394_types.h
@@ -19,7 +19,7 @@ struct hpsb_tlabel_pool {
 	spinlock_t lock;
 	u8 next;
 	u32 allocations;
-	struct semaphore count;
+	struct compat_semaphore count;
 };
 
 #define HPSB_TPOOL_INIT(_tp)			\
@@ -28,7 +28,7 @@ do {						\
 	spin_lock_init(&(_tp)->lock);		\
 	(_tp)->next = 0;			\
 	(_tp)->allocations = 0;			\
-	sema_init_nocheck(&(_tp)->count, 63);	\
+	sema_init(&(_tp)->count, 63);	\
 } while (0)
 
 
Index: linux-2.6.10/drivers/ieee1394/nodemgr.c
===================================================================
--- linux-2.6.10.orig/drivers/ieee1394/nodemgr.c
+++ linux-2.6.10/drivers/ieee1394/nodemgr.c
@@ -114,7 +114,7 @@ struct host_info {
 	struct hpsb_host *host;
 	struct list_head list;
 	struct completion exited;
-	struct semaphore reset_sem;
+	struct compat_semaphore reset_sem;
 	int pid;
 	char daemon_name[15];
 	int kill_me;
@@ -1664,7 +1664,7 @@ static void nodemgr_add_host(struct hpsb
 
 	hi->host = host;
 	init_completion(&hi->exited);
-        sema_init_nocheck(&hi->reset_sem, 0);
+        sema_init(&hi->reset_sem, 0);
 
 	sprintf(hi->daemon_name, "knodemgrd_%d", host->id);
 
Index: linux-2.6.10/drivers/ieee1394/raw1394.c
===================================================================
--- linux-2.6.10.orig/drivers/ieee1394/raw1394.c
+++ linux-2.6.10/drivers/ieee1394/raw1394.c
@@ -2529,7 +2529,7 @@ static int raw1394_open(struct inode *in
         fi->state = opened;
         INIT_LIST_HEAD(&fi->req_pending);
         INIT_LIST_HEAD(&fi->req_complete);
-        sema_init_nocheck(&fi->complete_sem, 0);
+        sema_init(&fi->complete_sem, 0);
         spin_lock_init(&fi->reqlists_lock);
         init_waitqueue_head(&fi->poll_wait_complete);
         INIT_LIST_HEAD(&fi->addr_list);
Index: linux-2.6.10/drivers/media/dvb/dvb-core/dvb_frontend.c
===================================================================
--- linux-2.6.10.orig/drivers/media/dvb/dvb-core/dvb_frontend.c
+++ linux-2.6.10/drivers/media/dvb/dvb-core/dvb_frontend.c
@@ -500,7 +500,7 @@ static void dvb_frontend_stop(struct dvb
 		printk("dvb_frontend_stop: thread PID %d already died\n",
 				fe->thread_pid);
 		/* make sure the mutex was not held by the thread */
-		sema_init_nocheck (&fe->sem, 1);
+		sema_init (&fe->sem, 1);
 		return;
 	}
 
@@ -831,10 +831,10 @@ int dvb_register_frontend(struct dvb_ada
 	if (down_interruptible (&frontend_mutex))
 		return -ERESTARTSYS;
 
-	sema_init_nocheck (&fe->sem, 1);
+	sema_init (&fe->sem, 1);
 	init_waitqueue_head (&fe->wait_queue);
 	init_waitqueue_head (&fe->events.wait_queue);
-	sema_init_nocheck (&fe->events.sem, 1);
+	sema_init (&fe->events.sem, 1);
 	fe->events.eventw = fe->events.eventr = 0;
 	fe->events.overflow = 0;
 	fe->dvb = dvb;
Index: linux-2.6.10/drivers/media/dvb/dvb-core/dvb_frontend.h
===================================================================
--- linux-2.6.10.orig/drivers/media/dvb/dvb-core/dvb_frontend.h
+++ linux-2.6.10/drivers/media/dvb/dvb-core/dvb_frontend.h
@@ -108,7 +108,7 @@ struct dvb_fe_events {
 	int			  eventr;
 	int			  overflow;
 	wait_queue_head_t	  wait_queue;
-	struct semaphore	  sem;
+	struct compat_semaphore	  sem;
 };
 
 struct dvb_frontend {
Index: linux-2.6.10/drivers/scsi/aha152x.c
===================================================================
--- linux-2.6.10.orig/drivers/scsi/aha152x.c
+++ linux-2.6.10/drivers/scsi/aha152x.c
@@ -1160,13 +1160,11 @@ static void timer_expired(unsigned long 
 static int aha152x_device_reset(Scsi_Cmnd * SCpnt)
 {
 	struct Scsi_Host *shpnt = SCpnt->device->host;
-	DECLARE_MUTEX_NOCHECK(sem);
+	DECLARE_MUTEX_LOCKED(sem);
 	struct timer_list timer;
 	int ret, issued, disconnected;
 	unsigned long flags;
 
-	down(&sem);
-
 #if defined(AHA152X_DEBUG)
 	if(HOSTDATA(shpnt)->debug & debug_eh) {
 		printk(INFO_LEAD "aha152x_device_reset(%p)", CMDINFO(SCpnt), SCpnt);
Index: linux-2.6.10/drivers/scsi/qla2xxx/qla_os.c
===================================================================
--- linux-2.6.10.orig/drivers/scsi/qla2xxx/qla_os.c
+++ linux-2.6.10/drivers/scsi/qla2xxx/qla_os.c
@@ -3190,7 +3190,7 @@ qla2x00_free_sp_pool( scsi_qla_host_t *h
 static int
 qla2x00_do_dpc(void *data)
 {
-	DECLARE_MUTEX_NOCHECK(sem);
+	DECLARE_MUTEX_LOCKED(sem);
 	scsi_qla_host_t *ha;
 	fc_port_t	*fcport;
 	os_lun_t        *q;
@@ -3204,8 +3204,6 @@ qla2x00_do_dpc(void *data)
 	int t;
 	os_tgt_t *tq;
 
-	down(&sem);
-
 	ha = (scsi_qla_host_t *)data;
 
 	lock_kernel();
Index: linux-2.6.10/drivers/scsi/scsi_error.c
===================================================================
--- linux-2.6.10.orig/drivers/scsi/scsi_error.c
+++ linux-2.6.10/drivers/scsi/scsi_error.c
@@ -452,12 +452,10 @@ static void scsi_eh_done(struct scsi_cmn
 static int scsi_send_eh_cmnd(struct scsi_cmnd *scmd, int timeout)
 {
 	struct Scsi_Host *host = scmd->device->host;
-	DECLARE_MUTEX_NOCHECK(sem);
+	DECLARE_MUTEX_LOCKED(sem);
 	unsigned long flags;
 	int rtn = SUCCESS;
 
-	down(&sem);
-
 	/*
 	 * we will use a queued command if possible, otherwise we will
 	 * emulate the queuing and calling of completion function ourselves.
@@ -1600,9 +1598,8 @@ int scsi_error_handler(void *data)
 {
 	struct Scsi_Host *shost = (struct Scsi_Host *) data;
 	int rtn;
-	DECLARE_MUTEX_NOCHECK(sem);
+	DECLARE_MUTEX_LOCKED(sem);
 
-	down(&sem);
 	/*
 	 *    Flush resources
 	 */
Index: linux-2.6.10/drivers/usb/storage/usb.h
===================================================================
--- linux-2.6.10.orig/drivers/usb/storage/usb.h
+++ linux-2.6.10/drivers/usb/storage/usb.h
@@ -153,7 +153,7 @@ struct us_data {
 	dma_addr_t		iobuf_dma;
 
 	/* mutual exclusion and synchronization structures */
-	struct semaphore	sema;		 /* to sleep thread on   */
+	struct compat_semaphore	sema;		 /* to sleep thread on   */
 	struct completion	notify;		 /* thread begin/end	 */
 	wait_queue_head_t	dev_reset_wait;  /* wait during reset    */
 	wait_queue_head_t	scsi_scan_wait;	 /* wait before scanning */
Index: linux-2.6.10/fs/lockd/svc.c
===================================================================
--- linux-2.6.10.orig/fs/lockd/svc.c
+++ linux-2.6.10/fs/lockd/svc.c
@@ -49,7 +49,7 @@ static pid_t			nlmsvc_pid;
 int				nlmsvc_grace_period;
 unsigned long			nlmsvc_timeout;
 
-static DECLARE_WAIT_QUEUE_HEAD(lockd_start);
+static DECLARE_MUTEX_LOCKED(lockd_start);
 static DECLARE_WAIT_QUEUE_HEAD(lockd_exit);
 
 /*
@@ -112,7 +112,7 @@ lockd(struct svc_rqst *rqstp)
 	 * Let our maker know we're running.
 	 */
 	nlmsvc_pid = current->pid;
-	wake_up(&lockd_start);
+	up(&lockd_start);
 
 	daemonize("lockd");
 
@@ -233,7 +233,6 @@ lockd_up(void)
 		printk(KERN_WARNING
 			"lockd_up: no pid, %d users??\n", nlmsvc_users);
 
-
 	error = -ENOMEM;
 	serv = svc_create(&nlmsvc_program, LOCKD_BUFSIZE);
 	if (!serv) {
@@ -262,15 +261,8 @@ lockd_up(void)
 			"lockd_up: create thread failed, error=%d\n", error);
 		goto destroy_and_out;
 	}
-	/*
-	 * Wait for the lockd process to start, but since we're holding
-	 * the lockd semaphore, we can't wait around forever ...
-	 */
-	if (wait_event_interruptible_timeout(lockd_start, 
-					     nlmsvc_pid != 0, HZ) <= 0) {
-		printk(KERN_WARNING 
-			"lockd_down: lockd failed to start\n");
-	}
+	down(&lockd_start);
+
 	/*
 	 * Note: svc_serv structures have an initial use count of 1,
 	 * so we exit through here on both success and failure.
@@ -310,12 +302,16 @@ lockd_down(void)
 	 * Wait for the lockd process to exit, but since we're holding
 	 * the lockd semaphore, we can't wait around forever ...
 	 */
-	if (wait_event_interruptible_timeout(lockd_exit, 
-					     nlmsvc_pid == 0, HZ) <= 0) {
+	clear_thread_flag(TIF_SIGPENDING);
+	interruptible_sleep_on_timeout(&lockd_exit, HZ);
+	if (nlmsvc_pid) {
 		printk(KERN_WARNING 
 			"lockd_down: lockd failed to exit, clearing pid\n");
 		nlmsvc_pid = 0;
 	}
+	spin_lock_irq(&current->sighand->siglock);
+	recalc_sigpending();
+	spin_unlock_irq(&current->sighand->siglock);
 out:
 	up(&nlmsvc_sema);
 }
Index: linux-2.6.10/fs/xfs/linux-2.6/mrlock.h
===================================================================
--- linux-2.6.10.orig/fs/xfs/linux-2.6/mrlock.h
+++ linux-2.6.10/fs/xfs/linux-2.6/mrlock.h
@@ -37,12 +37,12 @@
 enum { MR_NONE, MR_ACCESS, MR_UPDATE };
 
 typedef struct {
-	struct rw_semaphore	mr_lock;
-	int			mr_writer;
+	struct compat_rw_semaphore	mr_lock;
+	int				mr_writer;
 } mrlock_t;
 
 #define mrinit(mrp, name)	\
-	( (mrp)->mr_writer = 0, init_rwsem(&(mrp)->mr_lock) )
+	do { (mrp)->mr_writer = 0; init_rwsem(&(mrp)->mr_lock); } while (0)
 #define mrlock_init(mrp, t,n,s)	mrinit(mrp, n)
 #define mrfree(mrp)		do { } while (0)
 #define mraccess(mrp)		mraccessf(mrp, 0)
Index: linux-2.6.10/fs/xfs/linux-2.6/mutex.h
===================================================================
--- linux-2.6.10.orig/fs/xfs/linux-2.6/mutex.h
+++ linux-2.6.10/fs/xfs/linux-2.6/mutex.h
@@ -42,10 +42,10 @@
  * callers.
  */
 #define MUTEX_DEFAULT		0x0
-typedef struct semaphore	mutex_t;
+typedef struct compat_semaphore	mutex_t;
 
-#define mutex_init(lock, type, name)		sema_init_nocheck(lock, 1)
-#define mutex_destroy(lock)			sema_init_nocheck(lock, -99)
+#define mutex_init(lock, type, name)		sema_init(lock, 1)
+#define mutex_destroy(lock)			sema_init(lock, -99)
 #define mutex_lock(lock, num)			down(lock)
 #define mutex_trylock(lock)			(down_trylock(lock) ? 0 : 1)
 #define mutex_unlock(lock)			up(lock)
Index: linux-2.6.10/fs/xfs/linux-2.6/sema.h
===================================================================
--- linux-2.6.10.orig/fs/xfs/linux-2.6/sema.h
+++ linux-2.6.10/fs/xfs/linux-2.6/sema.h
@@ -41,11 +41,11 @@
  * sema_t structure just maps to struct semaphore in Linux kernel.
  */
 
-typedef struct semaphore sema_t;
+typedef struct compat_semaphore sema_t;
 
-#define init_sema(sp, val, c, d)	sema_init_nocheck(sp, val)
-#define initsema(sp, val)		sema_init_nocheck(sp, val)
-#define initnsema(sp, val, name)	sema_init_nocheck(sp, val)
+#define init_sema(sp, val, c, d)	sema_init(sp, val)
+#define initsema(sp, val)		sema_init(sp, val)
+#define initnsema(sp, val, name)	sema_init(sp, val)
 #define psema(sp, b)			down(sp)
 #define vsema(sp)			up(sp)
 #define valusema(sp)			(atomic_read(&(sp)->count))
Index: linux-2.6.10/fs/xfs/linux-2.6/xfs_buf.c
===================================================================
--- linux-2.6.10.orig/fs/xfs/linux-2.6/xfs_buf.c
+++ linux-2.6.10/fs/xfs/linux-2.6/xfs_buf.c
@@ -945,7 +945,7 @@ int
 pagebuf_lock_value(
 	xfs_buf_t		*pb)
 {
-	return(atomic_read(&pb->pb_sema.count));
+	return !sem_is_locked(&pb->pb_sema);
 }
 
 /*
Index: linux-2.6.10/fs/xfs/linux-2.6/xfs_buf.h
===================================================================
--- linux-2.6.10.orig/fs/xfs/linux-2.6/xfs_buf.h
+++ linux-2.6.10/fs/xfs/linux-2.6/xfs_buf.h
@@ -130,7 +130,7 @@ typedef int (*page_buf_bdstrat_t)(struct
 #define PB_PAGES	4
 
 typedef struct xfs_buf {
-	struct semaphore	pb_sema;	/* semaphore for lockables  */
+	struct compat_semaphore	pb_sema;	/* semaphore for lockables  */
 	unsigned long		pb_queuetime;	/* time buffer was queued   */
 	atomic_t		pb_pin_count;	/* pin count		    */
 	wait_queue_head_t	pb_waiters;	/* unpin waiters	    */
@@ -149,7 +149,7 @@ typedef struct xfs_buf {
 	page_buf_iodone_t	pb_iodone;	/* I/O completion function */
 	page_buf_relse_t	pb_relse;	/* releasing function */
 	page_buf_bdstrat_t	pb_strat;	/* pre-write function */
-	struct semaphore	pb_iodonesema;	/* Semaphore for I/O waiters */
+	struct compat_semaphore	pb_iodonesema;	/* Semaphore for I/O waiters */
 	void			*pb_fspriv;
 	void			*pb_fspriv2;
 	void			*pb_fspriv3;
Index: linux-2.6.10/fs/xfs/xfs_mount.h
===================================================================
--- linux-2.6.10.orig/fs/xfs/xfs_mount.h
+++ linux-2.6.10/fs/xfs/xfs_mount.h
@@ -339,7 +339,7 @@ typedef struct xfs_mount {
 	uint			m_bm_maxlevels[2]; /* XFS_BM_MAXLEVELS */
 	uint			m_in_maxlevels;	/* XFS_IN_MAXLEVELS */
 	struct xfs_perag	*m_perag;	/* per-ag accounting info */
-	struct rw_semaphore	m_peraglock;	/* lock for m_perag (pointer) */
+	struct compat_rw_semaphore m_peraglock;	/* lock for m_perag (pointer) */
 	sema_t			m_growlock;	/* growfs mutex */
 	int			m_fixedfsid[2];	/* unchanged for life of FS */
 	uint			m_dmevmask;	/* DMI events for this FS */
Index: linux-2.6.10/include/linux/parport.h
===================================================================
--- linux-2.6.10.orig/include/linux/parport.h
+++ linux-2.6.10/include/linux/parport.h
@@ -256,7 +256,7 @@ enum ieee1284_phase {
 struct ieee1284_info {
 	int mode;
 	volatile enum ieee1284_phase phase;
-	struct semaphore irq;
+	struct compat_semaphore irq;
 };
 
 /* A parallel port */
Index: linux-2.6.10/include/linux/rt_lock.h
===================================================================
--- linux-2.6.10.orig/include/linux/rt_lock.h
+++ linux-2.6.10/include/linux/rt_lock.h
@@ -70,7 +70,6 @@ struct rt_mutex {
 	struct task_struct	*owner;
 	int			owner_prio;
 # ifdef CONFIG_RT_DEADLOCK_DETECT
-	int			debug;
 	int			save_state;
 	struct list_head	held_list;
 	unsigned long		acquire_eip;
@@ -93,20 +92,14 @@ struct rt_mutex_waiter {
 };
 
 #ifdef CONFIG_RT_DEADLOCK_DETECT
-# define ___RT_MUTEX_INITIALIZER(lockname) \
-	.wait_lock = RAW_SPIN_LOCK_UNLOCKED, \
-	.wait_list = LIST_HEAD_INIT((lockname).wait_list), \
-	.name = #lockname, .file = __FILE__, .line = __LINE__
 # define __RT_MUTEX_INITIALIZER(lockname) \
-	{ .debug = 1, ___RT_MUTEX_INITIALIZER(lockname) }
-# define __RT_MUTEX_INITIALIZER_NOCHECK(lockname) \
-	{ .debug = 0, ___RT_MUTEX_INITIALIZER(lockname) }
+	{ .wait_lock = RAW_SPIN_LOCK_UNLOCKED, \
+	.wait_list = LIST_HEAD_INIT((lockname).wait_list), \
+	.name = #lockname, .file = __FILE__, .line = __LINE__ }
 #else
 # define __RT_MUTEX_INITIALIZER(lockname) \
 	{ .wait_lock = RAW_SPIN_LOCK_UNLOCKED, \
 	   LIST_HEAD_INIT((lockname).wait_list) }
-# define __RT_MUTEX_INITIALIZER_NOCHECK(lockname) \
-		__RT_MUTEX_INITIALIZER(lockname)
 #endif
 /*
  * RW-semaphores are an RT mutex plus a reader-depth count.
@@ -134,7 +127,7 @@ typedef struct {
 # ifdef CONFIG_RT_DEADLOCK_DETECT
 #  define __RW_LOCK_UNLOCKED \
 	.wait_lock = __RAW_SPIN_LOCK_UNLOCKED, .save_state = 1, \
-	.debug = .1, .file = __FILE__, .line = __LINE__
+	.file = __FILE__, .line = __LINE__
 #  define _RW_LOCK_UNLOCKED(lock) \
 	(rwlock_t) { { { __RW_LOCK_UNLOCKED, .name = #lock } } }
 #  define RW_LOCK_UNLOCKED \
@@ -163,7 +156,7 @@ typedef struct {
 #ifdef CONFIG_RT_DEADLOCK_DETECT
 # define __SPIN_LOCK_UNLOCKED \
 	.wait_lock = __RAW_SPIN_LOCK_UNLOCKED, \
-	.save_state = 1, .debug = 1, .file = __FILE__, .line = __LINE__
+	.save_state = 1, .file = __FILE__, .line = __LINE__
 # define _SPIN_LOCK_UNLOCKED(lock) \
 	(spinlock_t) { { __SPIN_LOCK_UNLOCKED, .name = #lock } }
 # define SPIN_LOCK_UNLOCKED \
@@ -183,16 +176,13 @@ typedef struct {
 #ifdef CONFIG_PREEMPT_RT
 
 /*
- * semaphores - an RT-mutex plus the semaphore count:
+ * Semaphores - an RT-mutex plus the semaphore count:
  */
 struct semaphore {
 	atomic_t count;
 	struct rt_mutex lock;
 };
 
-/*
- * Semaphores:
- */
 #define __MUTEX_INITIALIZER(name) \
         { .count = { 1 }, .lock = __RT_MUTEX_INITIALIZER(name.lock) }
 
@@ -200,83 +190,161 @@ struct semaphore {
 struct semaphore name = \
 	{ .count = { 1 }, .lock = __RT_MUTEX_INITIALIZER(name.lock) }
 
-#define DECLARE_MUTEX_NOCHECK(name) \
-struct semaphore name = \
-	{ .count = { 1 }, .lock = __RT_MUTEX_INITIALIZER_NOCHECK(name.lock) }
-
 /*
  * DECLARE_MUTEX_LOCKED() is deprecated: very hard to initialize properly
- * and it also often signals abuse of semaphores.
+ * and it also often signals abuse of semaphores. So we redirect it to
+ * compat semaphores:
  */
+#define DECLARE_MUTEX_LOCKED COMPAT_DECLARE_MUTEX_LOCKED
 
-extern void FASTCALL(__sema_init(struct semaphore *sem, int val, int debug, char *name, char *file, int line));
+extern void FASTCALL(__sema_init(struct semaphore *sem, int val, char *name, char *file, int line));
 
-#define sema_init(sem, val) \
-		__sema_init(sem, val, 1, #sem, __FILE__, __LINE__)
-#define sema_init_nocheck(sem, val) \
-		__sema_init(sem, val, 0, #sem, __FILE__, __LINE__)
+#define rt_sema_init(sem, val) \
+		__sema_init(sem, val, #sem, __FILE__, __LINE__)
 	
 extern void FASTCALL(__init_MUTEX(struct semaphore *sem, char *name, char *file, int line));
 extern void FASTCALL(__init_MUTEX_LOCKED(struct semaphore *sem, char *name, char *file, int line));
-#define init_MUTEX(sem) \
+#define rt_init_MUTEX(sem) \
 		__init_MUTEX(sem, #sem, __FILE__, __LINE__)
-#define init_MUTEX_LOCKED(sem) \
+#define rt_init_MUTEX_LOCKED(sem) \
 		__init_MUTEX_LOCKED(sem, #sem, __FILE__, __LINE__)
-extern void FASTCALL(down(struct semaphore * sem));
-extern int FASTCALL(down_interruptible(struct semaphore * sem));
-extern int FASTCALL(down_trylock(struct semaphore * sem));
-extern void FASTCALL(up(struct semaphore * sem));
-extern int FASTCALL(sem_is_locked(struct semaphore *sem));
-extern int FASTCALL(sema_count(struct semaphore * sem));
+extern void FASTCALL(rt_down(struct semaphore * sem));
+extern int FASTCALL(rt_down_interruptible(struct semaphore * sem));
+extern int FASTCALL(rt_down_trylock(struct semaphore * sem));
+extern void FASTCALL(rt_up(struct semaphore * sem));
+extern int FASTCALL(rt_sem_is_locked(struct semaphore *sem));
+extern int FASTCALL(rt_sema_count(struct semaphore * sem));
+
+extern int __bad_func_type(void);
+
+#undef TYPE_EQUAL
+#define TYPE_EQUAL(var, type) \
+		__builtin_types_compatible_p(typeof(var), type *)
+
+#define PICK_FUNC_1ARG(type1, type2, func1, func2, arg)			\
+do {									\
+	if (TYPE_EQUAL((arg), type1))					\
+		func1((type1 *)(arg));					\
+	else if (TYPE_EQUAL((arg), type2))				\
+		func2((type2 *)(arg));					\
+	else __bad_func_type();						\
+} while (0)
+
+#define PICK_FUNC_1ARG_RET(type1, type2, func1, func2, arg)		\
+({									\
+	int __ret;							\
+									\
+	if (TYPE_EQUAL((arg), type1))					\
+		__ret = func1((type1 *)(arg));				\
+	else if (TYPE_EQUAL((arg), type2))				\
+		__ret = func2((type2 *)(arg));				\
+	else __ret = __bad_func_type();					\
+									\
+	__ret;								\
+})
+
+#define PICK_FUNC_2ARG(type1, type2, func1, func2, arg0, arg1)		\
+do {									\
+	if (TYPE_EQUAL((arg0), type1))					\
+		func1((type1 *)(arg0), arg1);				\
+	else if (TYPE_EQUAL((arg0), type2))				\
+		func2((type2 *)(arg0), arg1);				\
+	else __bad_func_type();						\
+} while (0)
+  
+#define sema_init(sem, val) \
+	PICK_FUNC_2ARG(struct compat_semaphore, struct semaphore, \
+		compat_sema_init, rt_sema_init, sem, val)
+  
+#define init_MUTEX(sem) \
+	PICK_FUNC_1ARG(struct compat_semaphore, struct semaphore, \
+		compat_init_MUTEX, rt_init_MUTEX, sem)
+  
+#define down(sem) \
+	PICK_FUNC_1ARG(struct compat_semaphore, struct semaphore, \
+		compat_down, rt_down, sem)
+  
+#define down_interruptible(sem) \
+	PICK_FUNC_1ARG_RET(struct compat_semaphore, struct semaphore, \
+		compat_down_interruptible, rt_down_interruptible, sem)
+  
+#define down_trylock(sem) \
+	PICK_FUNC_1ARG_RET(struct compat_semaphore, struct semaphore, \
+		compat_down_trylock, rt_down_trylock, sem)
+  
+#define up(sem) \
+	PICK_FUNC_1ARG(struct compat_semaphore, struct semaphore, \
+		compat_up, rt_up, sem)
+  
+#define sem_is_locked(sem) \
+	PICK_FUNC_1ARG_RET(struct compat_semaphore, struct semaphore, \
+		compat_sem_is_locked, rt_sem_is_locked, sem)
+
+#define init_MUTEX_LOCKED(sem) \
+	PICK_FUNC_1ARG(struct compat_semaphore, struct semaphore, \
+		compat_init_MUTEX_LOCKED, rt_init_MUTEX_LOCKED, sem)
 
+ /*
+  * rwsems:
+  */
 
 #define __RWSEM_INITIALIZER(lockname) \
 	{ .lock = __RT_MUTEX_INITIALIZER(lockname.lock) }
-#define __RWSEM_INITIALIZER_NOCHECK(lockname) \
-	{ .lock = __RT_MUTEX_INITIALIZER_NOCHECK(lockname.lock) }
 
 #define DECLARE_RWSEM(lockname) \
 	struct rw_semaphore lockname = __RWSEM_INITIALIZER(lockname)
 
-extern void FASTCALL(__init_rwsem(struct rw_semaphore *rwsem, int mutex,
-				int debug, char *name, char *file, int line));
-
-#define init_rwsem(sem) __init_rwsem(sem, 0, 1, #sem, __FILE__, __LINE__)
+extern void FASTCALL(__init_rwsem(struct rw_semaphore *rwsem, int save_state,
+					char *name, char *file, int line));
 
-extern void FASTCALL(down_read(struct rw_semaphore *rwsem));
-
-/*
- * trylock for reading -- returns 1 if successful, 0 if contention
- */
-extern int FASTCALL(down_read_trylock(struct rw_semaphore *rwsem));
-
-/*
- * lock for writing
- */
-extern void FASTCALL(down_write(struct rw_semaphore *rwsem));
-extern int FASTCALL(down_write_interruptible(struct rw_semaphore *rwsem));
-
-/*
- * trylock for writing -- returns 1 if successful, 0 if contention
- */
-extern int FASTCALL(down_write_trylock(struct rw_semaphore *rwsem));
-
-/*
- * release a read lock
- */
-extern void FASTCALL(up_read(struct rw_semaphore *rwsem));
-
-/*
- * release a write lock
- */
-extern void FASTCALL(up_write(struct rw_semaphore *rwsem));
-
-/*
- * downgrade write lock to read lock
- */
-extern void FASTCALL(downgrade_write(struct rw_semaphore *rwsem));
+#define rt_init_rwsem(sem) \
+	__init_rwsem(sem, 0, #sem, __FILE__, __LINE__)
 
-extern int FASTCALL(rwsem_is_locked(struct rw_semaphore *rwsem));
+extern void FASTCALL(rt_down_read(struct rw_semaphore *rwsem));
+extern int FASTCALL(rt_down_read_trylock(struct rw_semaphore *rwsem));
+extern void FASTCALL(rt_down_write(struct rw_semaphore *rwsem));
+extern int FASTCALL(rt_down_write_interruptible(struct rw_semaphore *rwsem));
+extern int FASTCALL(rt_down_write_trylock(struct rw_semaphore *rwsem));
+extern void FASTCALL(rt_up_read(struct rw_semaphore *rwsem));
+extern void FASTCALL(rt_up_write(struct rw_semaphore *rwsem));
+extern void FASTCALL(rt_downgrade_write(struct rw_semaphore *rwsem));
+extern int FASTCALL(rt_rwsem_is_locked(struct rw_semaphore *rwsem));
+
+#define init_rwsem(rwsem) \
+	PICK_FUNC_1ARG(struct compat_rw_semaphore, struct rw_semaphore, \
+		compat_init_rwsem, rt_init_rwsem, rwsem)
+
+#define down_read(rwsem) \
+	PICK_FUNC_1ARG(struct compat_rw_semaphore, struct rw_semaphore, \
+		compat_down_read, rt_down_read, rwsem)
+
+#define down_read_trylock(rwsem) \
+	PICK_FUNC_1ARG_RET(struct compat_rw_semaphore, struct rw_semaphore, \
+		compat_down_read_trylock, rt_down_read_trylock, rwsem)
+
+#define down_write(rwsem) \
+	PICK_FUNC_1ARG(struct compat_rw_semaphore, struct rw_semaphore, \
+		compat_down_write, rt_down_write, rwsem)
+
+#define down_write_trylock(rwsem) \
+	PICK_FUNC_1ARG_RET(struct compat_rw_semaphore, struct rw_semaphore, \
+		compat_down_write_trylock, rt_down_write_trylock, rwsem)
+
+#define up_read(rwsem) \
+	PICK_FUNC_1ARG(struct compat_rw_semaphore, struct rw_semaphore, \
+		compat_up_read, rt_up_read, rwsem)
+
+#define up_write(rwsem) \
+	PICK_FUNC_1ARG(struct compat_rw_semaphore, struct rw_semaphore, \
+		compat_up_write, rt_up_write, rwsem)
+
+#define downgrade_write(rwsem) \
+	PICK_FUNC_1ARG(struct compat_rw_semaphore, struct rw_semaphore, \
+		compat_downgrade_write, rt_downgrade_write, rwsem)
+
+#define rwsem_is_locked(rwsem) \
+	PICK_FUNC_1ARG_RET(struct compat_rw_semaphore, struct rw_semaphore, \
+		compat_rwsem_is_locked, rt_rwsem_is_locked, rwsem)
 
 #endif /* CONFIG_PREEMPT_RT */
 
Index: linux-2.6.10/include/linux/rwsem-spinlock.h
===================================================================
--- linux-2.6.10.orig/include/linux/rwsem-spinlock.h
+++ linux-2.6.10/include/linux/rwsem-spinlock.h
@@ -28,7 +28,7 @@ struct rwsem_waiter;
  * - if activity is -1 then there is one active writer
  * - if wait_list is not empty, then there are processes waiting for the semaphore
  */
-struct rw_semaphore {
+struct compat_rw_semaphore {
 	__s32			activity;
 	spinlock_t		wait_lock;
 	struct list_head	wait_list;
@@ -46,20 +46,20 @@ struct rw_semaphore {
 #define __RWSEM_DEBUG_INIT	/* */
 #endif
 
-#define __RWSEM_INITIALIZER(name) \
+#define __COMPAT_RWSEM_INITIALIZER(name) \
 { 0, SPIN_LOCK_UNLOCKED, LIST_HEAD_INIT((name).wait_list) __RWSEM_DEBUG_INIT }
 
-#define DECLARE_RWSEM(name) \
-	struct rw_semaphore name = __RWSEM_INITIALIZER(name)
+#define COMPAT_DECLARE_RWSEM(name) \
+	struct rw_semaphore name = __COMPAT_RWSEM_INITIALIZER(name)
 
-extern void FASTCALL(init_rwsem(struct rw_semaphore *sem));
-extern void FASTCALL(__down_read(struct rw_semaphore *sem));
-extern int FASTCALL(__down_read_trylock(struct rw_semaphore *sem));
-extern void FASTCALL(__down_write(struct rw_semaphore *sem));
-extern int FASTCALL(__down_write_trylock(struct rw_semaphore *sem));
-extern void FASTCALL(__up_read(struct rw_semaphore *sem));
-extern void FASTCALL(__up_write(struct rw_semaphore *sem));
-extern void FASTCALL(__downgrade_write(struct rw_semaphore *sem));
+extern void FASTCALL(compat_init_rwsem(struct compat_rw_semaphore *sem));
+extern void FASTCALL(__down_read(struct compat_rw_semaphore *sem));
+extern int FASTCALL(__down_read_trylock(struct compat_rw_semaphore *sem));
+extern void FASTCALL(__down_write(struct compat_rw_semaphore *sem));
+extern int FASTCALL(__down_write_trylock(struct compat_rw_semaphore *sem));
+extern void FASTCALL(__up_read(struct compat_rw_semaphore *sem));
+extern void FASTCALL(__up_write(struct compat_rw_semaphore *sem));
+extern void FASTCALL(__downgrade_write(struct compat_rw_semaphore *sem));
 
 #endif /* __KERNEL__ */
 #endif /* _LINUX_RWSEM_SPINLOCK_H */
Index: linux-2.6.10/include/linux/rwsem.h
===================================================================
--- linux-2.6.10.orig/include/linux/rwsem.h
+++ linux-2.6.10/include/linux/rwsem.h
@@ -11,7 +11,7 @@
 
 #ifdef CONFIG_PREEMPT_RT
 # include <linux/rt_lock.h>
-#else
+#endif
 
 #define RWSEM_DEBUG 0
 
@@ -23,7 +23,14 @@
 #include <asm/system.h>
 #include <asm/atomic.h>
 
-struct rw_semaphore;
+#ifndef CONFIG_PREEMPT_RT
+/*
+ * On !PREEMPT_RT all rw-semaphores are compat:
+ */
+#define compat_rw_semaphore rw_semaphore
+#endif
+
+struct compat_rw_semaphore;
 
 #ifdef CONFIG_RWSEM_GENERIC_SPINLOCK
 #include <linux/rwsem-spinlock.h> /* use a generic implementation */
@@ -33,7 +40,7 @@ struct rw_semaphore;
 
 #ifndef rwsemtrace
 #if RWSEM_DEBUG
-extern void FASTCALL(rwsemtrace(struct rw_semaphore *sem, const char *str));
+extern void FASTCALL(rwsemtrace(struct compat_rw_semaphore *sem, const char *str));
 #else
 #define rwsemtrace(SEM,FMT)
 #endif
@@ -42,7 +49,7 @@ extern void FASTCALL(rwsemtrace(struct r
 /*
  * lock for reading
  */
-static inline void down_read(struct rw_semaphore *sem)
+static inline void compat_down_read(struct compat_rw_semaphore *sem)
 {
 	might_sleep();
 	rwsemtrace(sem,"Entering down_read");
@@ -53,7 +60,7 @@ static inline void down_read(struct rw_s
 /*
  * trylock for reading -- returns 1 if successful, 0 if contention
  */
-static inline int down_read_trylock(struct rw_semaphore *sem)
+static inline int compat_down_read_trylock(struct compat_rw_semaphore *sem)
 {
 	int ret;
 	rwsemtrace(sem,"Entering down_read_trylock");
@@ -65,7 +72,7 @@ static inline int down_read_trylock(stru
 /*
  * lock for writing
  */
-static inline void down_write(struct rw_semaphore *sem)
+static inline void compat_down_write(struct compat_rw_semaphore *sem)
 {
 	might_sleep();
 	rwsemtrace(sem,"Entering down_write");
@@ -76,7 +83,7 @@ static inline void down_write(struct rw_
 /*
  * trylock for writing -- returns 1 if successful, 0 if contention
  */
-static inline int down_write_trylock(struct rw_semaphore *sem)
+static inline int compat_down_write_trylock(struct compat_rw_semaphore *sem)
 {
 	int ret;
 	rwsemtrace(sem,"Entering down_write_trylock");
@@ -86,16 +93,9 @@ static inline int down_write_trylock(str
 }
 
 /*
- * get a write lock on the semaphore
- * - we increment the waiting count anyway to indicate an exclusive lock
- * returns -EINTR if signal arrives.
- */
-extern int FASTCALL(down_write_interruptible(struct rw_semaphore *rwsem));
-
-/*
  * release a read lock
  */
-static inline void up_read(struct rw_semaphore *sem)
+static inline void compat_up_read(struct compat_rw_semaphore *sem)
 {
 	rwsemtrace(sem,"Entering up_read");
 	__up_read(sem);
@@ -105,7 +105,7 @@ static inline void up_read(struct rw_sem
 /*
  * release a write lock
  */
-static inline void up_write(struct rw_semaphore *sem)
+static inline void compat_up_write(struct compat_rw_semaphore *sem)
 {
 	rwsemtrace(sem,"Entering up_write");
 	__up_write(sem);
@@ -115,13 +115,51 @@ static inline void up_write(struct rw_se
 /*
  * downgrade write lock to read lock
  */
-static inline void downgrade_write(struct rw_semaphore *sem)
+static inline void compat_downgrade_write(struct compat_rw_semaphore *sem)
 {
 	rwsemtrace(sem,"Entering downgrade_write");
 	__downgrade_write(sem);
 	rwsemtrace(sem,"Leaving downgrade_write");
 }
 
+#ifndef CONFIG_PREEMPT_RT
+
+#define DECLARE_RWSEM COMPAT_DECLARE_RWSEM
+#define __RWSEM_INITIALIZER __COMPAT_RWSEM_INITIALIZER
+
+static inline void init_rwsem(struct compat_rw_semaphore *rwsem)
+{
+	compat_init_rwsem(rwsem);
+}
+static inline void down_read(struct compat_rw_semaphore *rwsem)
+{
+	compat_down_read(rwsem);
+}
+static inline int down_read_trylock(struct compat_rw_semaphore *rwsem)
+{
+	return compat_down_read_trylock(rwsem);
+}
+static inline void down_write(struct compat_rw_semaphore *rwsem)
+{
+	compat_down_write(rwsem);
+}
+static inline int down_write_trylock(struct compat_rw_semaphore *rwsem)
+{
+	return compat_down_write_trylock(rwsem);
+}
+static inline void up_read(struct compat_rw_semaphore *rwsem)
+{
+	compat_up_read(rwsem);
+}
+static inline void up_write(struct compat_rw_semaphore *rwsem)
+{
+	compat_up_write(rwsem);
+}
+static inline void downgrade_write(struct compat_rw_semaphore *rwsem)
+{
+	compat_downgrade_write(rwsem);
+}
+#endif /* CONFIG_PREEMPT_RT */
+
 #endif /* __KERNEL__ */
-#endif /* PREEMPT_RT */
 #endif /* _LINUX_RWSEM_H */
Index: linux-2.6.10/include/linux/semaphore.h
===================================================================
--- /dev/null
+++ linux-2.6.10/include/linux/semaphore.h
@@ -0,0 +1,52 @@
+#ifndef _LINUX_SEMAPHORE_H
+#define _LINUX_SEMAPHORE_H
+
+#include <linux/config.h>
+
+#ifdef CONFIG_PREEMPT_RT
+# include <linux/rt_lock.h>
+#else
+
+#define DECLARE_MUTEX COMPAT_DECLARE_MUTEX
+#define DECLARE_MUTEX_LOCKED COMPAT_DECLARE_MUTEX_LOCKED
+
+static inline void sema_init(struct compat_semaphore *sem, int val)
+{
+	compat_sema_init(sem, val);
+}
+static inline void init_MUTEX(struct compat_semaphore *sem)
+{
+	compat_init_MUTEX(sem);
+}
+static inline void init_MUTEX_LOCKED(struct compat_semaphore *sem)
+{
+	compat_init_MUTEX_LOCKED(sem);
+}
+static inline void down(struct compat_semaphore *sem)
+{
+	compat_down(sem);
+}
+static inline int down_interruptible(struct compat_semaphore *sem)
+{
+	return compat_down_interruptible(sem);
+}
+static inline int down_trylock(struct compat_semaphore *sem)
+{
+	return compat_down_trylock(sem);
+}
+static inline void up(struct compat_semaphore *sem)
+{
+	compat_up(sem);
+}
+static inline int sem_is_locked(struct compat_semaphore *sem)
+{
+	return compat_sem_is_locked(sem);
+}
+static inline int sema_count(struct compat_semaphore *sem)
+{
+	return compat_sema_count(sem);
+}
+
+#endif /* CONFIG_PREEMPT_RT */
+
+#endif /* _LINUX_SEMAPHORE_H */
Index: linux-2.6.10/include/linux/spinlock.h
===================================================================
--- linux-2.6.10.orig/include/linux/spinlock.h
+++ linux-2.6.10/include/linux/spinlock.h
@@ -465,6 +465,7 @@ extern int _spin_is_locked(spinlock_t *l
 extern int atomic_dec_and_spin_lock(atomic_t *atomic, spinlock_t *lock);
 extern void _spin_lock_init(spinlock_t *lock, char *name, char *file, int line);
 
+#undef TYPE_EQUAL
 #define TYPE_EQUAL(lock, type) \
 		__builtin_types_compatible_p(typeof(lock), type *)
 
@@ -541,7 +542,7 @@ do {									\
 	if (TYPE_EQUAL((lock), type))					\
 		_raw_##optype##op((type *)(lock));			\
 	else if (TYPE_EQUAL(lock, rwlock_t))				\
-		##op((rwlock_t *)(lock));			\
+		##op((rwlock_t *)(lock));				\
 	else __bad_spinlock_type();					\
 } while (0)
 
@@ -574,7 +575,7 @@ do {									\
 	if (TYPE_EQUAL((lock), type))	  				\
 		__ret = _raw_##optype##op((type *)(lock));		\
 	else if (TYPE_EQUAL(lock, rwlock_t))				\
-		__ret = _##optype##op((rwlock_t *)(lock));	\
+		__ret = _##optype##op((rwlock_t *)(lock));		\
 	else __ret = __bad_spinlock_type();				\
 									\
 	__ret;								\
@@ -585,7 +586,7 @@ do {									\
 	if (TYPE_EQUAL((lock), type))					\
 		_raw_##optype##op((type *)(lock), flags);		\
 	else if (TYPE_EQUAL(lock, rwlock_t))				\
-		_##optype##op((rwlock_t *)(lock), flags);	\
+		_##optype##op((rwlock_t *)(lock), flags);		\
 	else __bad_spinlock_type();					\
 } while (0)
 
@@ -837,9 +838,7 @@ static inline int bit_spin_is_locked(int
 	raw_rwlock_t name __cacheline_aligned_in_smp = RAW_RW_LOCK_UNLOCKED
 
 #ifndef CONFIG_PREEMPT_RT
-# define DECLARE_MUTEX_NOCHECK DECLARE_MUTEX
-# define sema_count(sem) atomic_read(&(sem)->count)
-# define sema_init_nocheck sema_init
+# define init_rwsem_nocheck init_rwsem
 #endif
 
 /**
Index: linux-2.6.10/kernel/rt.c
===================================================================
--- linux-2.6.10.orig/kernel/rt.c
+++ linux-2.6.10/kernel/rt.c
@@ -322,7 +322,7 @@ retry:
 		read_unlock(&tasklist_lock);
 }
 
-static int check_deadlock(struct rt_mutex *lock, int recursive,
+static int check_deadlock(struct rt_mutex *lock, int depth,
 			  unsigned long eip)
 {
 	struct rt_mutex *lockblk;
@@ -344,7 +344,7 @@ static int check_deadlock(struct rt_mute
 		lockblk = task->blocked_on->lock;
 	if (current == task) {
 		TRACE_OFF();
-		if (recursive)
+		if (depth)
 			return 1;
 		printk("\n==========================================\n");
 		printk(  "[ BUG: lock recursion deadlock detected! |\n");
@@ -364,10 +364,21 @@ static int check_deadlock(struct rt_mute
 	 */
 	if (lockblk == &kernel_sem.lock)
 		return 0;
-	if (lockblk && check_deadlock(lockblk, 1, eip)) {
+	/*
+	 * Ugh, something corrupted the lock data structure?
+	 */
+	if (depth > 30) {
+		TRACE_OFF();
+		printk("\n===========================================\n");
+		printk(  "[ BUG: infinite lock dependency detected!? |\n");
+		printk(  "-------------------------------------------\n");
+		goto print_it;
+	}
+	if (lockblk && check_deadlock(lockblk, depth+1, eip)) {
 		printk("\n============================================\n");
 		printk(  "[ BUG: circular locking deadlock detected! ]\n");
 		printk(  "--------------------------------------------\n");
+print_it:
 		printk("%s/%d is deadlocking current task %s/%d\n\n",
 			task->comm, task->pid, current->comm, current->pid);
 		printk("\n1) %s/%d is trying to acquire this lock:\n",
@@ -617,8 +628,7 @@ task_blocks_on_lock(struct rt_mutex_wait
 		   struct rt_mutex *lock, unsigned long eip)
 {
 #ifdef CONFIG_RT_DEADLOCK_DETECT
-	if (lock->debug)
-		check_deadlock(lock, 0, eip);
+	check_deadlock(lock, 0, eip);
 	/* mark the current thread as blocked on the lock */
 	waiter->eip = eip;
 #endif
@@ -653,7 +663,7 @@ task_blocks_on_lock(struct rt_mutex_wait
 /*
  * initialise the lock:
  */
-static void __init_rt_mutex(struct rt_mutex *lock, int save_state, int debug,
+static void __init_rt_mutex(struct rt_mutex *lock, int save_state,
 				char *name, char *file, int line)
 {
 	lock->owner = NULL;
@@ -661,7 +671,6 @@ static void __init_rt_mutex(struct rt_mu
 	INIT_LIST_HEAD(&lock->wait_list);
 #ifdef CONFIG_RT_DEADLOCK_DETECT
 	lock->save_state = save_state;
-	lock->debug = debug;
 	INIT_LIST_HEAD(&lock->held_list);
 	lock->name = name;
 	lock->file = file;
@@ -670,9 +679,9 @@ static void __init_rt_mutex(struct rt_mu
 }
 
 void fastcall __init_rwsem(struct rw_semaphore *rwsem, int save_state,
-			int debug, char *name, char *file, int line)
+			char *name, char *file, int line)
 {
-	__init_rt_mutex(&rwsem->lock, save_state, debug, name, file, line);
+	__init_rt_mutex(&rwsem->lock, save_state, name, file, line);
 	rwsem->read_depth = 0;
 }
 EXPORT_SYMBOL(__init_rwsem);
@@ -687,10 +696,8 @@ static void set_new_owner(struct rt_mute
 	lock->owner = new_owner;
 	lock->owner_prio = new_owner->prio;
 #ifdef CONFIG_RT_DEADLOCK_DETECT
-	if (lock->debug) {
-		TRACE_WARN_ON(!list_empty(&lock->held_list));
-		list_add_tail(&lock->held_list, &held_locks);
-	}
+	TRACE_WARN_ON(!list_empty(&lock->held_list));
+	list_add_tail(&lock->held_list, &held_locks);
 	lock->acquire_eip = eip;
 #endif
 }
@@ -802,10 +809,8 @@ static void __sched __down(struct rt_mut
 	might_sleep();
 
 	nosched_flag = current->flags & PF_NOSCHED;
-#ifdef CONFIG_RT_DEADLOCK_DETECT
-	if (!lock->debug)
-#endif
-		current->flags &= ~PF_NOSCHED;
+
+	current->flags &= ~PF_NOSCHED;
 
 	/* wait to be given the lock */
 	for (;;) {
@@ -821,16 +826,16 @@ static void __sched __down(struct rt_mut
 /*
  * get a write lock on the rw-semaphore
  */
-void fastcall __sched down_write(struct rw_semaphore *rwsem)
+void fastcall __sched rt_down_write(struct rw_semaphore *rwsem)
 {
 	__down(&rwsem->lock, CALLER_ADDR0);
 }
-EXPORT_SYMBOL(down_write);
+EXPORT_SYMBOL(rt_down_write);
 
 /*
  * get a read lock on the rw-semaphore
  */
-void fastcall __sched down_read(struct rw_semaphore *rwsem)
+void fastcall __sched rt_down_read(struct rw_semaphore *rwsem)
 {
 	/*
 	 * Read locks within the write lock succeed.
@@ -841,7 +846,7 @@ void fastcall __sched down_read(struct r
 	}
 	return __down(&rwsem->lock, CALLER_ADDR0);
 }
-EXPORT_SYMBOL(down_read);
+EXPORT_SYMBOL(rt_down_read);
 
 /*
  * lock it mutex-style: this variant is very careful not to
@@ -901,10 +906,8 @@ static void __sched __down_mutex(struct 
 	 */
 
 	nosched_flag = current->flags & PF_NOSCHED;
-#ifdef CONFIG_RT_DEADLOCK_DETECT
-	if (!lock->debug)
-#endif
-		current->flags &= ~PF_NOSCHED;
+
+	current->flags &= ~PF_NOSCHED;
 
 	/* wait to be given the lock */
 	for (;;) {
@@ -1021,10 +1024,8 @@ static int __sched __down_interruptible(
 	might_sleep();
 
 	nosched_flag = current->flags & PF_NOSCHED;
-#ifdef CONFIG_RT_DEADLOCK_DETECT
-	if (!lock->debug)
-#endif
-		current->flags &= ~PF_NOSCHED;
+
+	current->flags &= ~PF_NOSCHED;
 
 	ret = 0;
 	/* wait to be given the lock */
@@ -1064,12 +1065,6 @@ static int __sched __down_interruptible(
 	return ret;
 }
 
-int fastcall __sched down_write_interruptible(struct rw_semaphore *rwsem)
-{
-	return __down_interruptible(&rwsem->lock, CALLER_ADDR0);
-}
-EXPORT_SYMBOL(down_write_interruptible);
-
 /*
  * trylock for writing -- returns 1 if successful, 0 if contention
  */
@@ -1100,16 +1095,16 @@ static int __down_trylock(struct rt_mute
 	return ret;
 }
 
-int fastcall down_write_trylock(struct rw_semaphore *rwsem)
+int fastcall rt_down_write_trylock(struct rw_semaphore *rwsem)
 {
 	return __down_trylock(&rwsem->lock, CALLER_ADDR0);
 }
-EXPORT_SYMBOL(down_write_trylock);
+EXPORT_SYMBOL(rt_down_write_trylock);
 
 /*
  * trylock for reading -- returns 1 if successful, 0 if contention
  */
-int fastcall down_read_trylock(struct rw_semaphore *rwsem)
+int fastcall rt_down_read_trylock(struct rw_semaphore *rwsem)
 {
 	/*
 	 * Read locks within the self-held write lock succeed.
@@ -1120,7 +1115,7 @@ int fastcall down_read_trylock(struct rw
 	}
 	return __down_trylock(&rwsem->lock, CALLER_ADDR0);
 }
-EXPORT_SYMBOL(down_read_trylock);
+EXPORT_SYMBOL(rt_down_read_trylock);
 
 static int down_write_trylock_mutex(struct rw_semaphore *rwsem)
 {
@@ -1158,10 +1153,8 @@ static void __up_mutex(struct rt_mutex *
 	TRACE_BUG_ON(!lock->wait_list.prev && !lock->wait_list.next);
 
 #ifdef CONFIG_RT_DEADLOCK_DETECT
-	if (lock->debug) {
-		TRACE_WARN_ON(list_empty(&lock->held_list));
-		list_del_init(&lock->held_list);
-	}
+	TRACE_WARN_ON(list_empty(&lock->held_list));
+	list_del_init(&lock->held_list);
 #endif
 	spin_lock(&pi_lock);
 
@@ -1217,13 +1210,13 @@ static void __up_mutex(struct rt_mutex *
 /*
  * Do owner check too:
  */
-void fastcall up_write(struct rw_semaphore *rwsem)
+void fastcall rt_up_write(struct rw_semaphore *rwsem)
 {
 	WARN_ON(rwsem->lock.owner != current);
 	BUG_ON(rwsem->read_depth);
 	__up_mutex(&rwsem->lock, 0, CALLER_ADDR0);
 }
-EXPORT_SYMBOL(up_write);
+EXPORT_SYMBOL(rt_up_write);
 
 static void _up_write(struct rw_semaphore *rwsem, unsigned long eip)
 {
@@ -1243,7 +1236,7 @@ void fastcall up_write_mutex(struct rw_s
 /*
  * release a read lock on the semaphore
  */
-void fastcall up_read(struct rw_semaphore *rwsem)
+void fastcall rt_up_read(struct rw_semaphore *rwsem)
 {
 	/*
 	 * Read locks within the self-held write lock succeed.
@@ -1254,7 +1247,7 @@ void fastcall up_read(struct rw_semaphor
 	}
 	return _up_write(rwsem, CALLER_ADDR0);
 }
-EXPORT_SYMBOL(up_read);
+EXPORT_SYMBOL(rt_up_read);
 
 void fastcall up_read_mutex(struct rw_semaphore *rwsem, unsigned long eip)
 {
@@ -1273,7 +1266,7 @@ void fastcall up_read_mutex(struct rw_se
  * downgrade a write lock into a read lock
  * - just wake up any readers at the front of the queue
  */
-void fastcall downgrade_write(struct rw_semaphore *rwsem)
+void fastcall rt_downgrade_write(struct rw_semaphore *rwsem)
 {
 	/*
 	 * This function is essentially a no-op in RT. This is
@@ -1286,7 +1279,7 @@ void fastcall downgrade_write(struct rw_
 	return;
 
 }
-EXPORT_SYMBOL(downgrade_write);
+EXPORT_SYMBOL(rt_downgrade_write);
 
 static int rt_mutex_is_locked(struct rt_mutex *lock)
 {
@@ -1298,11 +1291,11 @@ static int rt_mutex_is_locked(struct rt_
 	return ret;
 }
 
-int fastcall rwsem_is_locked(struct rw_semaphore *rwsem)
+int fastcall rt_rwsem_is_locked(struct rw_semaphore *rwsem)
 {
 	return rt_mutex_is_locked(&rwsem->lock);
 }
-EXPORT_SYMBOL(rwsem_is_locked);
+EXPORT_SYMBOL(rt_rwsem_is_locked);
 
 static void _down_mutex(struct rt_mutex *lock, unsigned long eip)
 {
@@ -1310,17 +1303,17 @@ static void _down_mutex(struct rt_mutex 
 	__down_mutex(lock, eip);
 }
 
-void fastcall __sema_init(struct semaphore *sem, int val, int debug,
+void fastcall __sema_init(struct semaphore *sem, int val,
 			  char *name, char *file, int line)
 {
 	atomic_set(&sem->count, val);
 	switch (val) {
 	case 0:
-		__init_rt_mutex(&sem->lock, 0, debug, name, file, line);
+		__init_rt_mutex(&sem->lock, 0, name, file, line);
 		__down(&sem->lock, CALLER_ADDR0);
 		break;
 	default:
-		__init_rt_mutex(&sem->lock, 0, debug, name, file, line);
+		__init_rt_mutex(&sem->lock, 0, name, file, line);
 		break;
 	}
 }
@@ -1329,22 +1322,10 @@ EXPORT_SYMBOL(__sema_init);
 void fastcall __init_MUTEX(struct semaphore *sem, char *name, char *file,
 			   int line)
 {
-	__sema_init(sem, 1, 1, name, file, line);
+	__sema_init(sem, 1, name, file, line);
 }
 EXPORT_SYMBOL(__init_MUTEX);
 
-/*
- * We initialize them to nodebug because mutexes that are initialized
- * locked are almost always used for completion purposes, not genuine
- * locking:
- */
-void fastcall __init_MUTEX_LOCKED(struct semaphore *sem, char *name,
-				  char *file, int line)
-{
-	__sema_init(sem, 0, 0, name, file, line);
-}
-EXPORT_SYMBOL(__init_MUTEX_LOCKED);
-
 static int down_trylock_mutex(struct rt_mutex *lock, unsigned long eip)
 {
 	TRACE_WARN_UNINITIALIZED(lock->save_state != 1);
@@ -1380,15 +1361,15 @@ static inline void __down_complete(struc
 		__up_mutex(&sem->lock, 0, eip);
 }
 
-void fastcall down(struct semaphore *sem)
+void fastcall rt_down(struct semaphore *sem)
 {
 	TRACE_WARN_UNINITIALIZED(sem->lock.save_state != 0);
 	__down(&sem->lock, CALLER_ADDR0);
 	__down_complete(sem, CALLER_ADDR0);
 }
-EXPORT_SYMBOL(down);
+EXPORT_SYMBOL(rt_down);
 
-int fastcall down_interruptible(struct semaphore *sem)
+int fastcall rt_down_interruptible(struct semaphore *sem)
 {
 	int ret;
 
@@ -1399,12 +1380,12 @@ int fastcall down_interruptible(struct s
 	__down_complete(sem, CALLER_ADDR0);
 	return 0;
 }
-EXPORT_SYMBOL(down_interruptible);
+EXPORT_SYMBOL(rt_down_interruptible);
 
 /*
  * try to down the semaphore, 0 on success and 1 on failure. (inverted)
  */
-int fastcall down_trylock(struct semaphore *sem)
+int fastcall rt_down_trylock(struct semaphore *sem)
 {
 	TRACE_WARN_UNINITIALIZED(sem->lock.save_state != 0);
 	/*
@@ -1420,9 +1401,9 @@ int fastcall down_trylock(struct semapho
 	}
 	return 1;
 }
-EXPORT_SYMBOL(down_trylock);
+EXPORT_SYMBOL(rt_down_trylock);
 
-void fastcall up(struct semaphore *sem)
+void fastcall rt_up(struct semaphore *sem)
 {
 	int count;
 
@@ -1440,21 +1421,21 @@ void fastcall up(struct semaphore *sem)
 		__up_mutex(&sem->lock, 0, CALLER_ADDR0);
 	preempt_enable();
 }
-EXPORT_SYMBOL(up);
+EXPORT_SYMBOL(rt_up);
 
-int fastcall sem_is_locked(struct semaphore *sem)
+int fastcall rt_sem_is_locked(struct semaphore *sem)
 {
 	TRACE_WARN_UNINITIALIZED(sem->lock.save_state != 0);
 	return rt_mutex_is_locked(&sem->lock);
 }
-EXPORT_SYMBOL(sem_is_locked);
+EXPORT_SYMBOL(rt_sem_is_locked);
 
-int fastcall sema_count(struct semaphore *sem)
+int fastcall rt_sema_count(struct semaphore *sem)
 {
 	TRACE_WARN_UNINITIALIZED(sem->lock.save_state != 0);
 	return atomic_read(&sem->count);
 }
-EXPORT_SYMBOL(sema_count);
+EXPORT_SYMBOL(rt_sema_count);
 
 /*
  * Spinlock wrappers:
@@ -1576,7 +1557,7 @@ EXPORT_SYMBOL(atomic_dec_and_spin_lock);
 
 void _spin_lock_init(spinlock_t *lock, char *name, char *file, int line)
 {
-	__init_rt_mutex(&lock->lock, 1, 1, name, file, line);
+	__init_rt_mutex(&lock->lock, 1, name, file, line);
 }
 EXPORT_SYMBOL(_spin_lock_init);
 
@@ -1705,13 +1686,13 @@ EXPORT_SYMBOL(_read_unlock_irqrestore);
 
 void _rwlock_init(rwlock_t *rwlock, char *name, char *file, int line)
 {
-	__init_rwsem(&rwlock->lock, 1, 1, name, file, line);
+	__init_rwsem(&rwlock->lock, 1, name, file, line);
 }
 EXPORT_SYMBOL(_rwlock_init);
 
 int _rwlock_is_locked(rwlock_t *rwlock)
 {
-	return rwsem_is_locked(&rwlock->lock);
+	return rt_rwsem_is_locked(&rwlock->lock);
 }
 EXPORT_SYMBOL(_rwlock_is_locked);
 
@@ -1720,13 +1701,13 @@ EXPORT_SYMBOL(_rwlock_is_locked);
  */
 int _read_can_lock(rwlock_t *rwlock)
 {
-	return !rwsem_is_locked(&rwlock->lock);
+	return !rt_rwsem_is_locked(&rwlock->lock);
 }
 EXPORT_SYMBOL(_read_can_lock);
 
 int _write_can_lock(rwlock_t *rwlock)
 {
-	return !rwsem_is_locked(&rwlock->lock);
+	return !rt_rwsem_is_locked(&rwlock->lock);
 }
 EXPORT_SYMBOL(_write_can_lock);
 
Index: linux-2.6.10/kernel/sched.c
===================================================================
--- linux-2.6.10.orig/kernel/sched.c
+++ linux-2.6.10/kernel/sched.c
@@ -4216,6 +4216,11 @@ __setup("voluntary-preempt=", voluntary_
  */
 void __sched yield(void)
 {
+	if (rt_task(current) && printk_ratelimit()) {
+		printk(KERN_ERR "BUG: %s:%d RT task yield()-ing!\n",
+			current->comm, current->pid);
+		dump_stack();
+	}
 	set_current_state(TASK_RUNNING);
 	sys_sched_yield();
 }
Index: linux-2.6.10/lib/rwsem-spinlock.c
===================================================================
--- linux-2.6.10.orig/lib/rwsem-spinlock.c
+++ linux-2.6.10/lib/rwsem-spinlock.c
@@ -18,7 +18,7 @@ struct rwsem_waiter {
 };
 
 #if RWSEM_DEBUG
-void rwsemtrace(struct rw_semaphore *sem, const char *str)
+void rwsemtrace(struct compat_rw_semaphore *sem, const char *str)
 {
 	if (sem->debug)
 		printk("[%d] %s({%d,%d})\n",
@@ -30,7 +30,7 @@ void rwsemtrace(struct rw_semaphore *sem
 /*
  * initialise the semaphore
  */
-void fastcall init_rwsem(struct rw_semaphore *sem)
+void fastcall compat_init_rwsem(struct compat_rw_semaphore *sem)
 {
 	sem->activity = 0;
 	spin_lock_init(&sem->wait_lock);
@@ -49,8 +49,8 @@ void fastcall init_rwsem(struct rw_semap
  * - woken process blocks are discarded from the list after having task zeroed
  * - writers are only woken if wakewrite is non-zero
  */
-static inline struct rw_semaphore *
-__rwsem_do_wake(struct rw_semaphore *sem, int wakewrite)
+static inline struct compat_rw_semaphore *
+__rwsem_do_wake(struct compat_rw_semaphore *sem, int wakewrite)
 {
 	struct rwsem_waiter *waiter;
 	struct task_struct *tsk;
@@ -111,8 +111,8 @@ __rwsem_do_wake(struct rw_semaphore *sem
 /*
  * wake a single writer
  */
-static inline struct rw_semaphore *
-__rwsem_wake_one_writer(struct rw_semaphore *sem)
+static inline struct compat_rw_semaphore *
+__rwsem_wake_one_writer(struct compat_rw_semaphore *sem)
 {
 	struct rwsem_waiter *waiter;
 	struct task_struct *tsk;
@@ -133,7 +133,7 @@ __rwsem_wake_one_writer(struct rw_semaph
 /*
  * get a read lock on the semaphore
  */
-void fastcall __sched __down_read(struct rw_semaphore *sem)
+void fastcall __sched __down_read(struct compat_rw_semaphore *sem)
 {
 	struct rwsem_waiter waiter;
 	struct task_struct *tsk;
@@ -179,7 +179,7 @@ void fastcall __sched __down_read(struct
 /*
  * trylock for reading -- returns 1 if successful, 0 if contention
  */
-int fastcall __down_read_trylock(struct rw_semaphore *sem)
+int fastcall __down_read_trylock(struct compat_rw_semaphore *sem)
 {
 	int ret = 0;
 	rwsemtrace(sem, "Entering __down_read_trylock");
@@ -202,7 +202,7 @@ int fastcall __down_read_trylock(struct 
  * get a write lock on the semaphore
  * - we increment the waiting count anyway to indicate an exclusive lock
  */
-void fastcall __sched __down_write(struct rw_semaphore *sem)
+void fastcall __sched __down_write(struct compat_rw_semaphore *sem)
 {
 	struct rwsem_waiter waiter;
 	struct task_struct *tsk;
@@ -246,69 +246,9 @@ void fastcall __sched __down_write(struc
 }
 
 /*
- * get a write lock on the semaphore
- * - we increment the waiting count anyway to indicate an exclusive lock
- * returns -EINTR if a signal arrived.
- */
-int fastcall __sched down_write_interruptible(struct rw_semaphore *sem)
-{
-	struct rwsem_waiter waiter;
-	struct task_struct *tsk;
-	int ret = 0;
-
-	rwsemtrace(sem, "Entering __down_write_interruptible");
-
-	spin_lock(&sem->wait_lock);
-
-	if (sem->activity == 0 && list_empty(&sem->wait_list)) {
-		/* granted */
-		sem->activity = -1;
-		spin_unlock(&sem->wait_lock);
-		goto out;
-	}
-
-	tsk = current;
-	set_task_state(tsk, TASK_INTERRUPTIBLE);
-
-	/* set up my own style of waitqueue */
-	waiter.task = tsk;
-	waiter.flags = RWSEM_WAITING_FOR_WRITE;
-	get_task_struct(tsk);
-
-	list_add_tail(&waiter.list, &sem->wait_list);
-
-	/* we don't need to touch the semaphore struct anymore */
-	spin_unlock(&sem->wait_lock);
-
-	/* wait to be given the lock */
-	for (;;) {
-		if (signal_pending(current)) {
-			spin_lock(&sem->wait_lock);
-			if (waiter.task) {
-				list_del_init(&waiter.list);
-				ret = -EINTR;
-			}
-			spin_unlock(&sem->wait_lock);
-			break;
-		}
-		if (!waiter.task)
-			break;
-		schedule();
-		set_task_state(tsk, TASK_INTERRUPTIBLE);
-	}
-
-	tsk->state = TASK_RUNNING;
-
- out:
-	rwsemtrace(sem, "Leaving __down_write_interruptible");
-
-	return ret;
-}
-
-/*
  * trylock for writing -- returns 1 if successful, 0 if contention
  */
-int fastcall __down_write_trylock(struct rw_semaphore *sem)
+int fastcall __down_write_trylock(struct compat_rw_semaphore *sem)
 {
 	int ret = 0;
 	rwsemtrace(sem, "Entering __down_write_trylock");
@@ -330,7 +270,7 @@ int fastcall __down_write_trylock(struct
 /*
  * release a read lock on the semaphore
  */
-void fastcall __up_read(struct rw_semaphore *sem)
+void fastcall __up_read(struct compat_rw_semaphore *sem)
 {
 	rwsemtrace(sem, "Entering __up_read");
 
@@ -347,7 +287,7 @@ void fastcall __up_read(struct rw_semaph
 /*
  * release a write lock on the semaphore
  */
-void fastcall __up_write(struct rw_semaphore *sem)
+void fastcall __up_write(struct compat_rw_semaphore *sem)
 {
 	rwsemtrace(sem, "Entering __up_write");
 
@@ -366,7 +306,7 @@ void fastcall __up_write(struct rw_semap
  * downgrade a write lock into a read lock
  * - just wake up any readers at the front of the queue
  */
-void fastcall __downgrade_write(struct rw_semaphore *sem)
+void fastcall __downgrade_write(struct compat_rw_semaphore *sem)
 {
 	rwsemtrace(sem, "Entering __downgrade_write");
 
@@ -381,7 +321,7 @@ void fastcall __downgrade_write(struct r
 	rwsemtrace(sem, "Leaving __downgrade_write");
 }
 
-EXPORT_SYMBOL(init_rwsem);
+EXPORT_SYMBOL(compat_init_rwsem);
 EXPORT_SYMBOL(__down_read);
 EXPORT_SYMBOL(__down_read_trylock);
 EXPORT_SYMBOL(__down_write);
Index: linux-2.6.10/lib/rwsem.c
===================================================================
--- linux-2.6.10.orig/lib/rwsem.c
+++ linux-2.6.10/lib/rwsem.c
@@ -140,16 +140,14 @@ __rwsem_do_wake(struct rw_semaphore *sem
 /*
  * wait for a lock to be granted
  */
-static inline int
+static inline struct rw_semaphore *
 rwsem_down_failed_common(struct rw_semaphore *sem,
-			struct rwsem_waiter *waiter, signed long adjustment,
-			unsigned long sleep_state)
+			struct rwsem_waiter *waiter, signed long adjustment)
 {
 	struct task_struct *tsk = current;
 	signed long count;
-	int ret = 0;
 
-	set_task_state(tsk, sleep_state);
+	set_task_state(tsk, TASK_UNINTERRUPTIBLE);
 
 	/* set up my own style of waitqueue */
 	spin_lock(&sem->wait_lock);
@@ -169,30 +167,15 @@ rwsem_down_failed_common(struct rw_semap
 
 	/* wait to be given the lock */
 	for (;;) {
-		unsigned long nosched_flag = current->flags & PF_NOSCHED;
-	
-		if ((sleep_state == TASK_INTERRUPTIBLE) &&
-						signal_pending(current)) {
-			spin_lock(&sem->wait_lock);
-			if (waiter->task) {
-				list_del_init(&waiter->list);
-				ret = -EINTR;
-			}
-			spin_unlock(&sem->wait_lock);
-			break;
-		}
 		if (!waiter->task)
 			break;
-
-		current->flags &= ~PF_NOSCHED;
 		schedule();
-		current->flags |= nosched_flag;
-		set_task_state(tsk, sleep_state);
+		set_task_state(tsk, TASK_UNINTERRUPTIBLE);
 	}
 
 	tsk->state = TASK_RUNNING;
 
-	return ret;
+	return sem;
 }
 
 /*
@@ -207,7 +190,7 @@ rwsem_down_read_failed(struct rw_semapho
 
 	waiter.flags = RWSEM_WAITING_FOR_READ;
 	rwsem_down_failed_common(sem, &waiter,
-		RWSEM_WAITING_BIAS - RWSEM_ACTIVE_BIAS, TASK_UNINTERRUPTIBLE);
+				RWSEM_WAITING_BIAS - RWSEM_ACTIVE_BIAS);
 
 	rwsemtrace(sem, "Leaving rwsem_down_read_failed");
 	return sem;
@@ -224,27 +207,13 @@ rwsem_down_write_failed(struct rw_semaph
 	rwsemtrace(sem, "Entering rwsem_down_write_failed");
 
 	waiter.flags = RWSEM_WAITING_FOR_WRITE;
-	rwsem_down_failed_common(sem, &waiter, -RWSEM_ACTIVE_BIAS,
-							TASK_UNINTERRUPTIBLE);
+	rwsem_down_failed_common(sem, &waiter, -RWSEM_ACTIVE_BIAS);
 
 	rwsemtrace(sem, "Leaving rwsem_down_write_failed");
 	return sem;
 }
 
 /*
- * get a write lock on the semaphore
- * - we increment the waiting count anyway to indicate an exclusive lock
- * returns -EINTR if signal arrives.
- */
-int fastcall __sched down_write_interruptible(struct rw_semaphore *sem)
-{
-	struct rwsem_waiter waiter = { flags: RWSEM_WAITING_FOR_WRITE };
-
-	return rwsem_down_failed_common(sem, &waiter, -RWSEM_ACTIVE_BIAS,
-							TASK_UNINTERRUPTIBLE);
-}
-
-/*
  * handle waking up a waiter on the semaphore
  * - up_read/up_write has decremented the active part of count if we come here
  */
Index: linux-2.6.10/mm/mmap.c
===================================================================
--- linux-2.6.10.orig/mm/mmap.c
+++ linux-2.6.10/mm/mmap.c
@@ -1771,7 +1771,7 @@ static inline void verify_mm_writelocked
 {
 #ifdef CONFIG_DEBUG_KERNEL
 # ifdef CONFIG_PREEMPT_RT
-	if (unlikely(!rwsem_is_locked(&mm->mmap_sem))) {
+	if (unlikely(!rt_rwsem_is_locked(&mm->mmap_sem))) {
 		WARN_ON(1);
 	}
 # else
Index: linux-2.6.10/mvl_patches/pro-0181.c
===================================================================
--- /dev/null
+++ linux-2.6.10/mvl_patches/pro-0181.c
@@ -0,0 +1,16 @@
+/*
+ * Author: MontaVista Software, Inc. <source@mvista.com>
+ *
+ * 2005 (c) MontaVista Software, Inc. This file is licensed under
+ * the terms of the GNU General Public License version 2. This program
+ * is licensed "as is" without any warranty of any kind, whether express
+ * or implied.
+ */
+#include <linux/init.h>
+#include <linux/mvl_patch.h>
+
+static __init int regpatch(void)
+{
+        return mvl_register_patch(181);
+}
+module_init(regpatch);
EOF

    rv=0
    cat /tmp/mvl_patch_$$
    if [ "$?" != "0" ]; then
	# Patch had a hard error, return 2
	rv=2
    elif grep '^Hunk' ${TMPFILE}; then
	rv=1
    fi

    rm -f ${TMPFILE}
    return $rv
}

function options() {
    echo "Options are:"
    echo "  --force-unsupported - Force the patch to be applied even if the"
    echo "      patch is out of order or the current kernel is unsupported."
    echo "      Use of this option is strongly discouraged."
    echo "  --force-apply-fuzz - If the patch has fuzz, go ahead and apply"
    echo "      it anyway.  This can occur if the patch is applied to an"
    echo "      unsupported kernel or applied out of order or if you have"
    echo "      made your own modifications to the kernel.  Use with"
    echo "      caution."
    echo "  --remove - Remove the patch"
}


function checkpatchnum() {
    local level;

    if [ ! -e ${1} ]; then
	echo "${1} does not exist, make sure you are in the kernel" 1>&2
	echo "base directory" 1>&2
	exit 1;
    fi

    # Extract the current patch number from the lsp info file.
    level=`grep '#define LSP_.*PATCH_LEVEL' ${1} | sed 's/^.*\"\\(.*\\)\".*\$/\\1/'`
    if [ "a$level" = "a" ]; then
	echo "No patch level defined in ${1}, are you sure this is" 1>&2
	echo "a valid MVL kernel LSP?" 1>&2
	exit 1;
    fi

    expr $level + 0 >/dev/null 2>&1
    isnum=$?

    # Check if the kernel is supported
    if [ "$level" = "unsupported" ]; then
	echo "**Current kernel is unsupported by MontaVista due to patches"
	echo "  begin applied out of order."
	if [ $force_unsupported == 't' ]; then
	    echo "  Application is forced, applying patch anyway"
	    unsupported=t
	    fix_patch_level=f
	else
	    echo "  Patch application aborted.  Use --force-unsupported to"
	    echo "  force the patch to be applied, but the kernel will not"
	    echo "  be supported by MontaVista."
	    exit 1;
	fi

    # Check the patch number from the lspinfo file to make sure it is
    # a valid number
    elif [ $isnum = 2 ]; then
	echo "**Patch level from ${1} was not a valid number, " 1>&2
	echo "  are you sure this is a valid MVL kernel LSP?" 1>&2
	exit 1;

    # Check that this is the right patch number to be applied.
    elif [ `expr $level $3` ${4} ${2} ]; then
	echo "**Application of this patch is out of order and will cause the"
	echo "  kernel to be unsupported by MontaVista."
	if [ $force_unsupported == 't' ]; then
	    echo "  application is forced, applying patch anyway"
	    unsupported=t
	else
	    echo "  Patch application aborted.  Please get all the patches in"
	    echo "  proper order from MontaVista Zone and apply them in order"
	    echo "  If you really want to apply this patch, use"
	    echo "  --force-unsupported to force the patch to be applied, but"
	    echo "  the kernel will not be supported by MontaVista."
	    exit 1;
	fi
    fi
}

#
# Update the patch level in the file.  Note that we use patch to do
# this.  Certain weak version control systems don't take kindly to
# arbitrary changes directly to files, but do have a special version
# of "patch" that understands this.
#
function setpatchnum() {
    sed "s/^#define LSP_\(.*\)PATCH_LEVEL[ \t*]\"[0-9]*\".*$/#define LSP_\1PATCH_LEVEL \"${2}\"/" <${1} >/tmp/$$.tmp1
    diff -u ${1} /tmp/$$.tmp1 >/tmp/$$.tmp2
    rm /tmp/$$.tmp1
    sed "s/^+++ \/tmp\/$$.tmp1/+++ include\/linux\/lsppatchlevel.h/" </tmp/$$.tmp2 >/tmp/$$.tmp1
    rm /tmp/$$.tmp2
    patch -p0 </tmp/$$.tmp1
    rm /tmp/$$.tmp1
}

force_unsupported=f
force_apply_fuzz=""
unsupported=f
fix_patch_level=t
reverse=f
common_patchnum_diff='+ 1'
common_patchnum=$PATCHNUM
patch_extraopts=''

# Extract command line parameters.
while [ $# -gt 0 ]; do
    if [ "a$1" == 'a--force-unsupported' ]; then
	force_unsupported=t
    elif [ "a$1" == 'a--force-apply-fuzz' ]; then
	force_apply_fuzz=y
    elif [ "a$1" == 'a--remove' ]; then
	reverse=t
	common_patchnum_diff=''
	common_patchnum=`expr $PATCHNUM - 1`
	patch_extraopts='--reverse'
    else
	echo "'$1' is an invalid command line parameter."
	options
	exit 1
    fi
    shift
done

echo "Checking patch level"
checkpatchnum ${LSPINFO} ${PATCHNUM} "${common_patchnum_diff}" "-ne"

if ! dopatch -p1 --dry-run --force $patch_extraopts; then
    if [ $? = 2 ]; then
	echo -n "**Patch had errors, application aborted" 1>&2
	exit 1;
    fi

    # Patch has warnings
    clean_apply=${force_apply_fuzz}
    while [ "a$clean_apply" != 'ay' -a "a$clean_apply" != 'an' ]; do
	echo -n "**Patch did not apply cleanly.  Do you still want to apply? (y/n) > "
	read clean_apply
	clean_apply=`echo "$clean_apply" | tr '[:upper:]' '[:lower:]'`
    done
    if [ $clean_apply = 'n' ]; then
	exit 1;
    fi
fi

dopatch -p1 --force $patch_extraopts

if [ $fix_patch_level = 't' ]; then 
    if [ $unsupported = 't' ]; then
	common_patchnum="unsupported"
    fi

    setpatchnum ${LSPINFO} ${common_patchnum}
fi

# Move the patch file into the mvl_patches directory if we are not reversing
if [ $reverse != 't' ]; then 
    if echo $0 | grep '/' >/dev/null; then
	# Filename is a path, either absolute or from the current directory.
	srcfile=$0
    else
	# Filename is from the path
	for i in `echo $PATH | tr ':;' '  '`; do
	    if [ -e ${i}/$0 ]; then
		srcfile=${i}/$0
	    fi
	done
    fi

    fname=`basename ${srcfile}`
    diff -uN mvl_patches/${fname} ${srcfile} | (cd mvl_patches; patch)
fi

