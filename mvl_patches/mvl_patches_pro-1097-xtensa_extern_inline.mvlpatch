#! /usr/bin/env bash
# Patch: -xtensa_extern_inline
# Date: Fri Feb 16 17:17:51 2007
# [PATCH] xtensa: replace 'extern inline' with 'static inline'
# 
# "extern inline" doesn't make sense.
# 
# Signed-off-by: Adrian Bunk <bunk@stusta.de>
# Signed-off-by: Chris Zankel <chris@zankel.net>
# Signed-off-by: Andrew Morton <akpm@osdl.org>
# Signed-off-by: Linus Torvalds <torvalds@osdl.org>
# 
# commit d99cf715a0751b0c819cdd8616c8870c1dd51910
# tree 7250fa334b00690e4e586d45c3eb6aa9770df17f
# parent 7ef939054139ef857cebbec07cbd12d7cf7beedd
# author Adrian Bunk <bunk@stusta.de> Sat, 03 Sep 2005 15:57:53 -0700
# committer Linus Torvalds <torvalds@evo.osdl.org> Mon, 05 Sep 2005 00:06:25 -0700
# 
#  include/asm-xtensa/atomic.h      |   12 +++++------
#  include/asm-xtensa/checksum.h    |    4 +--
#  include/asm-xtensa/delay.h       |    2 -
#  include/asm-xtensa/io.h          |   14 ++++++-------
#  include/asm-xtensa/mmu_context.h |   18 ++++++++---------
#  include/asm-xtensa/page.h        |    2 -
#  include/asm-xtensa/pci.h         |    4 +--
#  include/asm-xtensa/pgtable.h     |    6 ++---
#  include/asm-xtensa/semaphore.h   |   10 ++++-----
#  include/asm-xtensa/string.h      |    8 +++----
#  include/asm-xtensa/system.h      |   10 ++++-----
#  include/asm-xtensa/tlbflush.h    |   40 +++++++++++++++++++--------------------
#  12 files changed, 65 insertions(+), 65 deletions(-)
# 

PATCHNUM=1097
LSPINFO=include/linux/lsppatchlevel.h
TMPFILE=/tmp/mvl_patch_$$

function dopatch() {
    patch $* >${TMPFILE} 2>&1 <<"EOF"
[PATCH] xtensa: replace 'extern inline' with 'static inline'

"extern inline" doesn't make sense.

Signed-off-by: Adrian Bunk <bunk@stusta.de>
Signed-off-by: Chris Zankel <chris@zankel.net>
Signed-off-by: Andrew Morton <akpm@osdl.org>
Signed-off-by: Linus Torvalds <torvalds@osdl.org>

commit d99cf715a0751b0c819cdd8616c8870c1dd51910
tree 7250fa334b00690e4e586d45c3eb6aa9770df17f
parent 7ef939054139ef857cebbec07cbd12d7cf7beedd
author Adrian Bunk <bunk@stusta.de> Sat, 03 Sep 2005 15:57:53 -0700
committer Linus Torvalds <torvalds@evo.osdl.org> Mon, 05 Sep 2005 00:06:25 -0700

 include/asm-xtensa/atomic.h      |   12 +++++------
 include/asm-xtensa/checksum.h    |    4 +--
 include/asm-xtensa/delay.h       |    2 -
 include/asm-xtensa/io.h          |   14 ++++++-------
 include/asm-xtensa/mmu_context.h |   18 ++++++++---------
 include/asm-xtensa/page.h        |    2 -
 include/asm-xtensa/pci.h         |    4 +--
 include/asm-xtensa/pgtable.h     |    6 ++---
 include/asm-xtensa/semaphore.h   |   10 ++++-----
 include/asm-xtensa/string.h      |    8 +++----
 include/asm-xtensa/system.h      |   10 ++++-----
 include/asm-xtensa/tlbflush.h    |   40 +++++++++++++++++++--------------------
 mvl_patches/pro-1097.c           |   16 +++++++++++++++
 13 files changed, 81 insertions(+), 65 deletions(-)

diff --git a/include/asm-xtensa/atomic.h b/include/asm-xtensa/atomic.h
index d72bcb3..24f86f0 100644
Index: linux-2.6.10/include/asm-xtensa/atomic.h
===================================================================
--- linux-2.6.10.orig/include/asm-xtensa/atomic.h
+++ linux-2.6.10/include/asm-xtensa/atomic.h
@@ -66,7 +66,7 @@ typedef struct { volatile int counter; }
  *
  * Atomically adds @i to @v.
  */
-extern __inline__ void atomic_add(int i, atomic_t * v)
+static inline void atomic_add(int i, atomic_t * v)
 {
     unsigned int vval;
 
@@ -90,7 +90,7 @@ extern __inline__ void atomic_add(int i,
  *
  * Atomically subtracts @i from @v.
  */
-extern __inline__ void atomic_sub(int i, atomic_t *v)
+static inline void atomic_sub(int i, atomic_t *v)
 {
     unsigned int vval;
 
@@ -111,7 +111,7 @@ extern __inline__ void atomic_sub(int i,
  * We use atomic_{add|sub}_return to define other functions.
  */
 
-extern __inline__ int atomic_add_return(int i, atomic_t * v)
+static inline int atomic_add_return(int i, atomic_t * v)
 {
      unsigned int vval;
 
@@ -130,7 +130,7 @@ extern __inline__ int atomic_add_return(
     return vval;
 }
 
-extern __inline__ int atomic_sub_return(int i, atomic_t * v)
+static inline int atomic_sub_return(int i, atomic_t * v)
 {
     unsigned int vval;
 
@@ -224,7 +224,7 @@ extern __inline__ int atomic_sub_return(
 #define atomic_add_negative(i,v) (atomic_add_return((i),(v)) < 0)
 
 
-extern __inline__ void atomic_clear_mask(unsigned int mask, atomic_t *v)
+static inline void atomic_clear_mask(unsigned int mask, atomic_t *v)
 {
     unsigned int all_f = -1;
     unsigned int vval;
@@ -243,7 +243,7 @@ extern __inline__ void atomic_clear_mask
 	);
 }
 
-extern __inline__ void atomic_set_mask(unsigned int mask, atomic_t *v)
+static inline void atomic_set_mask(unsigned int mask, atomic_t *v)
 {
     unsigned int vval;
 
Index: linux-2.6.10/include/asm-xtensa/checksum.h
===================================================================
--- linux-2.6.10.orig/include/asm-xtensa/checksum.h
+++ linux-2.6.10/include/asm-xtensa/checksum.h
@@ -47,14 +47,14 @@ asmlinkage unsigned int csum_partial_cop
  *	If you use these functions directly please don't forget the
  *	verify_area().
  */
-extern __inline__
+static inline
 unsigned int csum_partial_copy_nocheck ( const char *src, char *dst,
 					int len, int sum)
 {
 	return csum_partial_copy_generic ( src, dst, len, sum, NULL, NULL);
 }
 
-extern __inline__
+static inline
 unsigned int csum_partial_copy_from_user ( const char *src, char *dst,
 						int len, int sum, int *err_ptr)
 {
Index: linux-2.6.10/include/asm-xtensa/delay.h
===================================================================
--- linux-2.6.10.orig/include/asm-xtensa/delay.h
+++ linux-2.6.10/include/asm-xtensa/delay.h
@@ -18,7 +18,7 @@
 
 extern unsigned long loops_per_jiffy;
 
-extern __inline__ void __delay(unsigned long loops)
+static inline void __delay(unsigned long loops)
 {
   /* 2 cycles per loop. */
   __asm__ __volatile__ ("1: addi %0, %0, -2; bgeui %0, 2, 1b"
Index: linux-2.6.10/include/asm-xtensa/io.h
===================================================================
--- linux-2.6.10.orig/include/asm-xtensa/io.h
+++ linux-2.6.10/include/asm-xtensa/io.h
@@ -41,12 +41,12 @@ static inline unsigned int _swapl (unsig
  * These are trivial on the 1:1 Linux/Xtensa mapping
  */
 
-extern inline unsigned long virt_to_phys(volatile void * address)
+static inline unsigned long virt_to_phys(volatile void * address)
 {
 	return PHYSADDR((unsigned long)address);
 }
 
-extern inline void * phys_to_virt(unsigned long address)
+static inline void * phys_to_virt(unsigned long address)
 {
 	return (void*) CACHED_ADDR(address);
 }
@@ -55,12 +55,12 @@ extern inline void * phys_to_virt(unsign
  * IO bus memory addresses are also 1:1 with the physical address
  */
 
-extern inline unsigned long virt_to_bus(volatile void * address)
+static inline unsigned long virt_to_bus(volatile void * address)
 {
 	return PHYSADDR((unsigned long)address);
 }
 
-extern inline void * bus_to_virt (unsigned long address)
+static inline void * bus_to_virt (unsigned long address)
 {
 	return (void *) CACHED_ADDR(address);
 }
@@ -69,17 +69,17 @@ extern inline void * bus_to_virt (unsign
  * Change "struct page" to physical address.
  */
 
-extern inline void *ioremap(unsigned long offset, unsigned long size)
+static inline void *ioremap(unsigned long offset, unsigned long size)
 {
         return (void *) CACHED_ADDR_IO(offset);
 }
 
-extern inline void *ioremap_nocache(unsigned long offset, unsigned long size)
+static inline void *ioremap_nocache(unsigned long offset, unsigned long size)
 {
         return (void *) BYPASS_ADDR_IO(offset);
 }
 
-extern inline void iounmap(void *addr)
+static inline void iounmap(void *addr)
 {
 }
 
Index: linux-2.6.10/include/asm-xtensa/mmu_context.h
===================================================================
--- linux-2.6.10.orig/include/asm-xtensa/mmu_context.h
+++ linux-2.6.10/include/asm-xtensa/mmu_context.h
@@ -199,13 +199,13 @@ extern pgd_t *current_pgd;
 #define ASID_FIRST_VERSION						\
 	((unsigned long)(~ASID_VERSION_MASK) + 1 + ASID_FIRST_NONRESERVED)
 
-extern inline void set_rasid_register (unsigned long val)
+static inline void set_rasid_register (unsigned long val)
 {
 	__asm__ __volatile__ (" wsr %0, "__stringify(RASID)"\n\t"
 			      " isync\n" : : "a" (val));
 }
 
-extern inline unsigned long get_rasid_register (void)
+static inline unsigned long get_rasid_register (void)
 {
 	unsigned long tmp;
 	__asm__ __volatile__ (" rsr %0, "__stringify(RASID)"\n\t" : "=a" (tmp));
@@ -215,7 +215,7 @@ extern inline unsigned long get_rasid_re
 
 #if ((XCHAL_MMU_ASID_INVALID == 0) && (XCHAL_MMU_ASID_KERNEL == 1))
 
-extern inline void
+static inline void
 get_new_mmu_context(struct mm_struct *mm, unsigned long asid)
 {
 	extern void flush_tlb_all(void);
@@ -234,7 +234,7 @@ get_new_mmu_context(struct mm_struct *mm
 /* XCHAL_MMU_ASID_INVALID == 0 and XCHAL_MMU_ASID_KERNEL ==1 are
    really the best, but if you insist... */
 
-extern inline int validate_asid (unsigned long asid)
+static inline int validate_asid (unsigned long asid)
 {
 	switch (asid) {
 	case XCHAL_MMU_ASID_INVALID:
@@ -247,7 +247,7 @@ extern inline int validate_asid (unsigne
 	return 1; /* valid */
 }
 
-extern inline void
+static inline void
 get_new_mmu_context(struct mm_struct *mm, unsigned long asid)
 {
 	extern void flush_tlb_all(void);
@@ -274,14 +274,14 @@ get_new_mmu_context(struct mm_struct *mm
  * instance.
  */
 
-extern inline int
+static inline int
 init_new_context(struct task_struct *tsk, struct mm_struct *mm)
 {
 	mm->context = NO_CONTEXT;
 	return 0;
 }
 
-extern inline void switch_mm(struct mm_struct *prev, struct mm_struct *next,
+static inline void switch_mm(struct mm_struct *prev, struct mm_struct *next,
                              struct task_struct *tsk)
 {
 	unsigned long asid = asid_cache;
@@ -301,7 +301,7 @@ extern inline void switch_mm(struct mm_s
  * Destroy context related info for an mm_struct that is about
  * to be put to rest.
  */
-extern inline void destroy_context(struct mm_struct *mm)
+static inline void destroy_context(struct mm_struct *mm)
 {
 	/* Nothing to do. */
 }
@@ -310,7 +310,7 @@ extern inline void destroy_context(struc
  * After we have set current->mm to a new value, this activates
  * the context for the new mm so we see the new mappings.
  */
-extern inline void
+static inline void
 activate_mm(struct mm_struct *prev, struct mm_struct *next)
 {
 	/* Unconditionally get a new ASID.  */
Index: linux-2.6.10/include/asm-xtensa/page.h
===================================================================
--- linux-2.6.10.orig/include/asm-xtensa/page.h
+++ linux-2.6.10/include/asm-xtensa/page.h
@@ -58,7 +58,7 @@ typedef struct { unsigned long pgprot; }
  * Pure 2^n version of get_order
  */
 
-extern __inline__ int get_order(unsigned long size)
+static inline int get_order(unsigned long size)
 {
 	int order;
 #ifndef XCHAL_HAVE_NSU
Index: linux-2.6.10/include/asm-xtensa/pci.h
===================================================================
--- linux-2.6.10.orig/include/asm-xtensa/pci.h
+++ linux-2.6.10/include/asm-xtensa/pci.h
@@ -22,12 +22,12 @@
 
 extern struct pci_controller* pcibios_alloc_controller(void);
 
-extern inline void pcibios_set_master(struct pci_dev *dev)
+static inline void pcibios_set_master(struct pci_dev *dev)
 {
 	/* No special bus mastering setup handling */
 }
 
-extern inline void pcibios_penalize_isa_irq(int irq)
+static inline void pcibios_penalize_isa_irq(int irq)
 {
 	/* We don't do dynamic PCI IRQ allocation */
 }
Index: linux-2.6.10/include/asm-xtensa/pgtable.h
===================================================================
--- linux-2.6.10.orig/include/asm-xtensa/pgtable.h
+++ linux-2.6.10/include/asm-xtensa/pgtable.h
@@ -288,7 +288,7 @@ static inline pte_t pte_mkwrite(pte_t pt
 #define pfn_pmd(pfn, prot)	__pmd(((pfn) << PAGE_SHIFT) | pgprot_val(prot))
 #define mk_pte(page, prot)	pfn_pte(page_to_pfn(page), prot)
 
-extern inline pte_t pte_modify(pte_t pte, pgprot_t newprot)
+static inline pte_t pte_modify(pte_t pte, pgprot_t newprot)
 {
 	return __pte((pte_val(pte) & _PAGE_CHG_MASK) | pgprot_val(newprot));
 }
@@ -306,14 +306,14 @@ static inline void update_pte(pte_t *pte
 #endif
 }
 
-extern inline void
+static inline void
 set_pte_at(struct mm_struct *mm, unsigned long addr, pte_t *ptep, pte_t pteval)
 {
 	update_pte(ptep, pteval);
 }
 
 
-extern inline void
+static inline void
 set_pmd(pmd_t *pmdp, pmd_t pmdval)
 {
 	*pmdp = pmdval;
Index: linux-2.6.10/include/asm-xtensa/semaphore.h
===================================================================
--- linux-2.6.10.orig/include/asm-xtensa/semaphore.h
+++ linux-2.6.10/include/asm-xtensa/semaphore.h
@@ -47,7 +47,7 @@ struct semaphore {
 #define DECLARE_MUTEX(name) __DECLARE_SEMAPHORE_GENERIC(name,1)
 #define DECLARE_MUTEX_LOCKED(name) __DECLARE_SEMAPHORE_GENERIC(name,0)
 
-extern inline void sema_init (struct semaphore *sem, int val)
+static inline void sema_init (struct semaphore *sem, int val)
 {
 /*
  *	*sem = (struct semaphore)__SEMAPHORE_INITIALIZER((*sem),val);
@@ -79,7 +79,7 @@ asmlinkage void __up(struct semaphore * 
 
 extern spinlock_t semaphore_wake_lock;
 
-extern __inline__ void down(struct semaphore * sem)
+static inline void down(struct semaphore * sem)
 {
 #if WAITQUEUE_DEBUG
 	CHECK_MAGIC(sem->__magic);
@@ -89,7 +89,7 @@ extern __inline__ void down(struct semap
 		__down(sem);
 }
 
-extern __inline__ int down_interruptible(struct semaphore * sem)
+static inline int down_interruptible(struct semaphore * sem)
 {
 	int ret = 0;
 #if WAITQUEUE_DEBUG
@@ -101,7 +101,7 @@ extern __inline__ int down_interruptible
 	return ret;
 }
 
-extern __inline__ int down_trylock(struct semaphore * sem)
+static inline int down_trylock(struct semaphore * sem)
 {
 	int ret = 0;
 #if WAITQUEUE_DEBUG
@@ -117,7 +117,7 @@ extern __inline__ int down_trylock(struc
  * Note! This is subtle. We jump to wake people up only if
  * the semaphore was negative (== somebody was waiting on it).
  */
-extern __inline__ void up(struct semaphore * sem)
+static inline void up(struct semaphore * sem)
 {
 #if WAITQUEUE_DEBUG
 	CHECK_MAGIC(sem->__magic);
Index: linux-2.6.10/include/asm-xtensa/string.h
===================================================================
--- linux-2.6.10.orig/include/asm-xtensa/string.h
+++ linux-2.6.10/include/asm-xtensa/string.h
@@ -16,7 +16,7 @@
 #define _XTENSA_STRING_H
 
 #define __HAVE_ARCH_STRCPY
-extern __inline__ char *strcpy(char *__dest, const char *__src)
+static inline char *strcpy(char *__dest, const char *__src)
 {
 	register char *__xdest = __dest;
 	unsigned long __dummy;
@@ -35,7 +35,7 @@ extern __inline__ char *strcpy(char *__d
 }
 
 #define __HAVE_ARCH_STRNCPY
-extern __inline__ char *strncpy(char *__dest, const char *__src, size_t __n)
+static inline char *strncpy(char *__dest, const char *__src, size_t __n)
 {
 	register char *__xdest = __dest;
 	unsigned long __dummy;
@@ -60,7 +60,7 @@ extern __inline__ char *strncpy(char *__
 }
 
 #define __HAVE_ARCH_STRCMP
-extern __inline__ int strcmp(const char *__cs, const char *__ct)
+static inline int strcmp(const char *__cs, const char *__ct)
 {
 	register int __res;
 	unsigned long __dummy;
@@ -82,7 +82,7 @@ extern __inline__ int strcmp(const char 
 }
 
 #define __HAVE_ARCH_STRNCMP
-extern __inline__ int strncmp(const char *__cs, const char *__ct, size_t __n)
+static inline int strncmp(const char *__cs, const char *__ct, size_t __n)
 {
 	register int __res;
 	unsigned long __dummy;
Index: linux-2.6.10/include/asm-xtensa/system.h
===================================================================
--- linux-2.6.10.orig/include/asm-xtensa/system.h
+++ linux-2.6.10/include/asm-xtensa/system.h
@@ -56,7 +56,7 @@ static inline int irqs_disabled(void)
 
 #define clear_cpenable() __clear_cpenable()
 
-extern __inline__ void __clear_cpenable(void)
+static inline void __clear_cpenable(void)
 {
 #if XCHAL_HAVE_CP
 	unsigned long i = 0;
@@ -64,7 +64,7 @@ extern __inline__ void __clear_cpenable(
 #endif
 }
 
-extern __inline__ void enable_coprocessor(int i)
+static inline void enable_coprocessor(int i)
 {
 #if XCHAL_HAVE_CP
 	int cp;
@@ -74,7 +74,7 @@ extern __inline__ void enable_coprocesso
 #endif
 }
 
-extern __inline__ void disable_coprocessor(int i)
+static inline void disable_coprocessor(int i)
 {
 #if XCHAL_HAVE_CP
 	int cp;
@@ -123,7 +123,7 @@ do {						\
  * cmpxchg
  */
 
-extern __inline__ unsigned long
+static inline unsigned long
 __cmpxchg_u32(volatile int *p, int old, int new)
 {
   __asm__ __volatile__("rsil    a15, "__stringify(LOCKLEVEL)"\n\t"
@@ -173,7 +173,7 @@ __cmpxchg(volatile void *ptr, unsigned l
  * where no register reference will cause an overflow.
  */
 
-extern __inline__ unsigned long xchg_u32(volatile int * m, unsigned long val)
+static inline unsigned long xchg_u32(volatile int * m, unsigned long val)
 {
   unsigned long tmp;
   __asm__ __volatile__("rsil    a15, "__stringify(LOCKLEVEL)"\n\t"
Index: linux-2.6.10/include/asm-xtensa/tlbflush.h
===================================================================
--- linux-2.6.10.orig/include/asm-xtensa/tlbflush.h
+++ linux-2.6.10/include/asm-xtensa/tlbflush.h
@@ -39,7 +39,7 @@ extern void flush_tlb_range(struct vm_ar
  * page-table pages.
  */
 
-extern inline void flush_tlb_pgtables(struct mm_struct *mm,
+static inline void flush_tlb_pgtables(struct mm_struct *mm,
                                       unsigned long start, unsigned long end)
 {
 }
@@ -51,26 +51,26 @@ extern inline void flush_tlb_pgtables(st
 #define ITLB_PROBE_SUCCESS  (1 << ITLB_WAYS_LOG2)
 #define DTLB_PROBE_SUCCESS  (1 << DTLB_WAYS_LOG2)
 
-extern inline unsigned long itlb_probe(unsigned long addr)
+static inline unsigned long itlb_probe(unsigned long addr)
 {
 	unsigned long tmp;
 	__asm__ __volatile__("pitlb  %0, %1\n\t" : "=a" (tmp) : "a" (addr));
 	return tmp;
 }
 
-extern inline unsigned long dtlb_probe(unsigned long addr)
+static inline unsigned long dtlb_probe(unsigned long addr)
 {
 	unsigned long tmp;
 	__asm__ __volatile__("pdtlb  %0, %1\n\t" : "=a" (tmp) : "a" (addr));
 	return tmp;
 }
 
-extern inline void invalidate_itlb_entry (unsigned long probe)
+static inline void invalidate_itlb_entry (unsigned long probe)
 {
 	__asm__ __volatile__("iitlb  %0; isync\n\t" : : "a" (probe));
 }
 
-extern inline void invalidate_dtlb_entry (unsigned long probe)
+static inline void invalidate_dtlb_entry (unsigned long probe)
 {
 	__asm__ __volatile__("idtlb  %0; dsync\n\t" : : "a" (probe));
 }
@@ -80,68 +80,68 @@ extern inline void invalidate_dtlb_entry
  * caller must follow up with an 'isync', which can be relatively
  * expensive on some Xtensa implementations.
  */
-extern inline void invalidate_itlb_entry_no_isync (unsigned entry)
+static inline void invalidate_itlb_entry_no_isync (unsigned entry)
 {
 	/* Caller must follow up with 'isync'. */
 	__asm__ __volatile__ ("iitlb  %0\n" : : "a" (entry) );
 }
 
-extern inline void invalidate_dtlb_entry_no_isync (unsigned entry)
+static inline void invalidate_dtlb_entry_no_isync (unsigned entry)
 {
 	/* Caller must follow up with 'isync'. */
 	__asm__ __volatile__ ("idtlb  %0\n" : : "a" (entry) );
 }
 
-extern inline void set_itlbcfg_register (unsigned long val)
+static inline void set_itlbcfg_register (unsigned long val)
 {
 	__asm__ __volatile__("wsr  %0, "__stringify(ITLBCFG)"\n\t" "isync\n\t"
 			     : : "a" (val));
 }
 
-extern inline void set_dtlbcfg_register (unsigned long val)
+static inline void set_dtlbcfg_register (unsigned long val)
 {
 	__asm__ __volatile__("wsr  %0, "__stringify(DTLBCFG)"; dsync\n\t"
 	    		     : : "a" (val));
 }
 
-extern inline void set_ptevaddr_register (unsigned long val)
+static inline void set_ptevaddr_register (unsigned long val)
 {
 	__asm__ __volatile__(" wsr  %0, "__stringify(PTEVADDR)"; isync\n"
 			     : : "a" (val));
 }
 
-extern inline unsigned long read_ptevaddr_register (void)
+static inline unsigned long read_ptevaddr_register (void)
 {
 	unsigned long tmp;
 	__asm__ __volatile__("rsr  %0, "__stringify(PTEVADDR)"\n\t" : "=a" (tmp));
 	return tmp;
 }
 
-extern inline void write_dtlb_entry (pte_t entry, int way)
+static inline void write_dtlb_entry (pte_t entry, int way)
 {
 	__asm__ __volatile__("wdtlb  %1, %0; dsync\n\t"
 			     : : "r" (way), "r" (entry) );
 }
 
-extern inline void write_itlb_entry (pte_t entry, int way)
+static inline void write_itlb_entry (pte_t entry, int way)
 {
 	__asm__ __volatile__("witlb  %1, %0; isync\n\t"
 	                     : : "r" (way), "r" (entry) );
 }
 
-extern inline void invalidate_page_directory (void)
+static inline void invalidate_page_directory (void)
 {
 	invalidate_dtlb_entry (DTLB_WAY_PGTABLE);
 }
 
-extern inline void invalidate_itlb_mapping (unsigned address)
+static inline void invalidate_itlb_mapping (unsigned address)
 {
 	unsigned long tlb_entry;
 	while ((tlb_entry = itlb_probe (address)) & ITLB_PROBE_SUCCESS)
 		invalidate_itlb_entry (tlb_entry);
 }
 
-extern inline void invalidate_dtlb_mapping (unsigned address)
+static inline void invalidate_dtlb_mapping (unsigned address)
 {
 	unsigned long tlb_entry;
 	while ((tlb_entry = dtlb_probe (address)) & DTLB_PROBE_SUCCESS)
@@ -165,28 +165,28 @@ extern inline void invalidate_dtlb_mappi
  *      as[07..00] contain the asid
  */
 
-extern inline unsigned long read_dtlb_virtual (int way)
+static inline unsigned long read_dtlb_virtual (int way)
 {
 	unsigned long tmp;
 	__asm__ __volatile__("rdtlb0  %0, %1\n\t" : "=a" (tmp), "+a" (way));
 	return tmp;
 }
 
-extern inline unsigned long read_dtlb_translation (int way)
+static inline unsigned long read_dtlb_translation (int way)
 {
 	unsigned long tmp;
 	__asm__ __volatile__("rdtlb1  %0, %1\n\t" : "=a" (tmp), "+a" (way));
 	return tmp;
 }
 
-extern inline unsigned long read_itlb_virtual (int way)
+static inline unsigned long read_itlb_virtual (int way)
 {
 	unsigned long tmp;
 	__asm__ __volatile__("ritlb0  %0, %1\n\t" : "=a" (tmp), "+a" (way));
 	return tmp;
 }
 
-extern inline unsigned long read_itlb_translation (int way)
+static inline unsigned long read_itlb_translation (int way)
 {
 	unsigned long tmp;
 	__asm__ __volatile__("ritlb1  %0, %1\n\t" : "=a" (tmp), "+a" (way));
Index: linux-2.6.10/mvl_patches/pro-1097.c
===================================================================
--- /dev/null
+++ linux-2.6.10/mvl_patches/pro-1097.c
@@ -0,0 +1,16 @@
+/*
+ * Author: MontaVista Software, Inc. <source@mvista.com>
+ *
+ * 2007 (c) MontaVista Software, Inc. This file is licensed under
+ * the terms of the GNU General Public License version 2. This program
+ * is licensed "as is" without any warranty of any kind, whether express
+ * or implied.
+ */
+#include <linux/init.h>
+#include <linux/mvl_patch.h>
+
+static __init int regpatch(void)
+{
+        return mvl_register_patch(1097);
+}
+module_init(regpatch);
EOF

    rv=0
    cat /tmp/mvl_patch_$$
    if [ "$?" != "0" ]; then
	# Patch had a hard error, return 2
	rv=2
    elif grep '^Hunk' ${TMPFILE}; then
	rv=1
    fi

    rm -f ${TMPFILE}
    return $rv
}

function options() {
    echo "Options are:"
    echo "  --force-unsupported - Force the patch to be applied even if the"
    echo "      patch is out of order or the current kernel is unsupported."
    echo "      Use of this option is strongly discouraged."
    echo "  --force-apply-fuzz - If the patch has fuzz, go ahead and apply"
    echo "      it anyway.  This can occur if the patch is applied to an"
    echo "      unsupported kernel or applied out of order or if you have"
    echo "      made your own modifications to the kernel.  Use with"
    echo "      caution."
    echo "  --remove - Remove the patch"
}


function checkpatchnum() {
    local level;

    if [ ! -e ${1} ]; then
	echo "${1} does not exist, make sure you are in the kernel" 1>&2
	echo "base directory" 1>&2
	exit 1;
    fi

    # Extract the current patch number from the lsp info file.
    level=`grep '#define LSP_.*PATCH_LEVEL' ${1} | sed 's/^.*\"\\(.*\\)\".*\$/\\1/'`
    if [ "a$level" = "a" ]; then
	echo "No patch level defined in ${1}, are you sure this is" 1>&2
	echo "a valid MVL kernel LSP?" 1>&2
	exit 1;
    fi

    expr $level + 0 >/dev/null 2>&1
    isnum=$?

    # Check if the kernel is supported
    if [ "$level" = "unsupported" ]; then
	echo "**Current kernel is unsupported by MontaVista due to patches"
	echo "  begin applied out of order."
	if [ $force_unsupported == 't' ]; then
	    echo "  Application is forced, applying patch anyway"
	    unsupported=t
	    fix_patch_level=f
	else
	    echo "  Patch application aborted.  Use --force-unsupported to"
	    echo "  force the patch to be applied, but the kernel will not"
	    echo "  be supported by MontaVista."
	    exit 1;
	fi

    # Check the patch number from the lspinfo file to make sure it is
    # a valid number
    elif [ $isnum = 2 ]; then
	echo "**Patch level from ${1} was not a valid number, " 1>&2
	echo "  are you sure this is a valid MVL kernel LSP?" 1>&2
	exit 1;

    # Check that this is the right patch number to be applied.
    elif [ `expr $level $3` ${4} ${2} ]; then
	echo "**Application of this patch is out of order and will cause the"
	echo "  kernel to be unsupported by MontaVista."
	if [ $force_unsupported == 't' ]; then
	    echo "  application is forced, applying patch anyway"
	    unsupported=t
	else
	    echo "  Patch application aborted.  Please get all the patches in"
	    echo "  proper order from MontaVista Zone and apply them in order"
	    echo "  If you really want to apply this patch, use"
	    echo "  --force-unsupported to force the patch to be applied, but"
	    echo "  the kernel will not be supported by MontaVista."
	    exit 1;
	fi
    fi
}

#
# Update the patch level in the file.  Note that we use patch to do
# this.  Certain weak version control systems don't take kindly to
# arbitrary changes directly to files, but do have a special version
# of "patch" that understands this.
#
function setpatchnum() {
    sed "s/^#define LSP_\(.*\)PATCH_LEVEL[ \t*]\"[0-9]*\".*$/#define LSP_\1PATCH_LEVEL \"${2}\"/" <${1} >/tmp/$$.tmp1
    diff -u ${1} /tmp/$$.tmp1 >/tmp/$$.tmp2
    rm /tmp/$$.tmp1
    sed "s/^+++ \/tmp\/$$.tmp1/+++ include\/linux\/lsppatchlevel.h/" </tmp/$$.tmp2 >/tmp/$$.tmp1
    rm /tmp/$$.tmp2
    patch -p0 </tmp/$$.tmp1
    rm /tmp/$$.tmp1
}

force_unsupported=f
force_apply_fuzz=""
unsupported=f
fix_patch_level=t
reverse=f
common_patchnum_diff='+ 1'
common_patchnum=$PATCHNUM
patch_extraopts=''

# Extract command line parameters.
while [ $# -gt 0 ]; do
    if [ "a$1" == 'a--force-unsupported' ]; then
	force_unsupported=t
    elif [ "a$1" == 'a--force-apply-fuzz' ]; then
	force_apply_fuzz=y
    elif [ "a$1" == 'a--remove' ]; then
	reverse=t
	common_patchnum_diff=''
	common_patchnum=`expr $PATCHNUM - 1`
	patch_extraopts='--reverse'
    else
	echo "'$1' is an invalid command line parameter."
	options
	exit 1
    fi
    shift
done

echo "Checking patch level"
checkpatchnum ${LSPINFO} ${PATCHNUM} "${common_patchnum_diff}" "-ne"

if ! dopatch -p1 --dry-run --force $patch_extraopts; then
    if [ $? = 2 ]; then
	echo -n "**Patch had errors, application aborted" 1>&2
	exit 1;
    fi

    # Patch has warnings
    clean_apply=${force_apply_fuzz}
    while [ "a$clean_apply" != 'ay' -a "a$clean_apply" != 'an' ]; do
	echo -n "**Patch did not apply cleanly.  Do you still want to apply? (y/n) > "
	read clean_apply
	clean_apply=`echo "$clean_apply" | tr '[:upper:]' '[:lower:]'`
    done
    if [ $clean_apply = 'n' ]; then
	exit 1;
    fi
fi

dopatch -p1 --force $patch_extraopts

if [ $fix_patch_level = 't' ]; then 
    if [ $unsupported = 't' ]; then
	common_patchnum="unsupported"
    fi

    setpatchnum ${LSPINFO} ${common_patchnum}
fi

# Move the patch file into the mvl_patches directory if we are not reversing
if [ $reverse != 't' ]; then 
    if echo $0 | grep '/' >/dev/null; then
	# Filename is a path, either absolute or from the current directory.
	srcfile=$0
    else
	# Filename is from the path
	for i in `echo $PATH | tr ':;' '  '`; do
	    if [ -e ${i}/$0 ]; then
		srcfile=${i}/$0
	    fi
	done
    fi

    fname=`basename ${srcfile}`
    diff -uN mvl_patches/${fname} ${srcfile} | (cd mvl_patches; patch)
fi

